{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DBSPh0JCaH4C"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Загрузка данных"
      ],
      "metadata": {
        "id": "6k8MIz6QaZ0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!wget https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/train.csv\n",
        "!wget https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODNLEiD3acJR",
        "outputId": "72f72168-2643-486f-ecfe-e633d73623a4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.11.12)\n",
            "--2025-12-23 00:45:10--  https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5381138 (5.1M) [text/plain]\n",
            "Saving to: ‘train.csv.3’\n",
            "\n",
            "train.csv.3         100%[===================>]   5.13M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-12-23 00:45:11 (61.4 MB/s) - ‘train.csv.3’ saved [5381138/5381138]\n",
            "\n",
            "--2025-12-23 00:45:11--  https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3567877 (3.4M) [text/plain]\n",
            "Saving to: ‘test.csv.3’\n",
            "\n",
            "test.csv.3          100%[===================>]   3.40M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-12-23 00:45:11 (42.9 MB/s) - ‘test.csv.3’ saved [3567877/3567877]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightautoml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCPiunfbIb3",
        "outputId": "35207c53-0b24-467f-9db6-76bb941bf94a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightautoml in /usr/local/lib/python3.12/dist-packages (0.4.2)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.0.45)\n",
            "Requirement already satisfied: autowoe>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.3.4)\n",
            "Requirement already satisfied: catboost>=0.26.1 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.2.8)\n",
            "Requirement already satisfied: cmaes in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.12.0)\n",
            "Requirement already satisfied: holidays in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.86)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.5.3)\n",
            "Requirement already satisfied: json2html in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.3.0)\n",
            "Requirement already satisfied: lightgbm>=2.3 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.0.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.2.2)\n",
            "Requirement already satisfied: poetry-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.9.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from lightautoml) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.16.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.13.2)\n",
            "Requirement already satisfied: statsmodels<=0.14.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.14.0)\n",
            "Requirement already satisfied: tabicl in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.1.4)\n",
            "Requirement already satisfied: tabm in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.0.3)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.67.1)\n",
            "Requirement already satisfied: xgboost<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.1.4)\n",
            "Requirement already satisfied: StrEnum<0.5.0,>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (0.4.15)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (3.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (2025.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.2.3)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (3.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2025.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->lightautoml) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (4.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (1.14.0)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost<3.0.0,>=2.0.0->lightautoml) (2.28.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->lightautoml) (3.0.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->lightautoml) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->lightautoml) (6.10.1)\n",
            "Requirement already satisfied: einops>=0.7 in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.36.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (5.9.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (4.57.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.23.1)\n",
            "Requirement already satisfied: rtdl_num_embeddings<0.1,>=0.0.12 in /usr/local/lib/python3.12/dist-packages (from tabm->lightautoml) (0.0.12)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (3.2.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->lightautoml) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->tabicl->lightautoml) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->tabicl->lightautoml) (1.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost>=0.26.1->lightautoml) (9.1.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.19.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->autowoe>=1.3.3->lightautoml) (4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (0.7.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (2.47.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->tabicl->lightautoml) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->tabicl->lightautoml) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "from src.dataset import get_target, calc_features\n",
        "\n",
        "delimiter = \"\\n\" + \"-\"*10"
      ],
      "metadata": {
        "id": "sMcfyU7_ad9u"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xSLVv2x7ahdl",
        "outputId": "201eef88-db13-416b-dbc0-cdcfda5f335e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   time  condition  epoch         C3         Cz         C4        Fp1  \\\n",
              "0     0          1      0  -5.885714  -2.533107   9.866895   7.962973   \n",
              "1     1          1      0  -7.999715 -16.916729 -11.924855  17.955477   \n",
              "2     2          1      0  -6.727283 -15.979567 -11.114195  17.183478   \n",
              "3     3          1      0   6.819390  -0.204905  10.090124  20.265222   \n",
              "4     4          1      0  13.129486  -5.817193   5.040633  19.462210   \n",
              "\n",
              "        Fp2         F7         F3  ...         F8         T7        T8  \\\n",
              "0  5.694433  23.638605  27.899784  ...  23.588723  12.178548  0.685809   \n",
              "1  8.526994  56.635981  28.508435  ...   1.045533  14.656061 -4.119778   \n",
              "2  4.497028  43.914130  10.079754  ... -14.741630  14.793562 -6.624813   \n",
              "3  7.843006  36.250611  13.291199  ...  -7.135541  21.723418 -2.276825   \n",
              "4  9.634234  42.311729  20.641012  ...   0.015602  19.703190  3.739076   \n",
              "\n",
              "         P7         P3         Pz         P4         P8         O1        O2  \n",
              "0 -4.887397 -10.646985 -14.735646  -8.729323  -0.562578 -17.055458 -3.616732  \n",
              "1 -4.632381 -17.980657 -23.456960 -12.960684  -9.639784 -20.233549 -1.229811  \n",
              "2 -3.402757 -10.269473 -18.736144  -3.579046  -0.045658 -14.089755  2.453398  \n",
              "3  2.066859   4.325365  -2.803322   8.835114  13.878945  -5.772410  7.657873  \n",
              "4  2.714350   3.251047  -3.631448   3.212956   4.635574  -5.045448  5.086024  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f463f617-bd55-4b51-82fd-2184cc489989\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>condition</th>\n",
              "      <th>epoch</th>\n",
              "      <th>C3</th>\n",
              "      <th>Cz</th>\n",
              "      <th>C4</th>\n",
              "      <th>Fp1</th>\n",
              "      <th>Fp2</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>...</th>\n",
              "      <th>F8</th>\n",
              "      <th>T7</th>\n",
              "      <th>T8</th>\n",
              "      <th>P7</th>\n",
              "      <th>P3</th>\n",
              "      <th>Pz</th>\n",
              "      <th>P4</th>\n",
              "      <th>P8</th>\n",
              "      <th>O1</th>\n",
              "      <th>O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.885714</td>\n",
              "      <td>-2.533107</td>\n",
              "      <td>9.866895</td>\n",
              "      <td>7.962973</td>\n",
              "      <td>5.694433</td>\n",
              "      <td>23.638605</td>\n",
              "      <td>27.899784</td>\n",
              "      <td>...</td>\n",
              "      <td>23.588723</td>\n",
              "      <td>12.178548</td>\n",
              "      <td>0.685809</td>\n",
              "      <td>-4.887397</td>\n",
              "      <td>-10.646985</td>\n",
              "      <td>-14.735646</td>\n",
              "      <td>-8.729323</td>\n",
              "      <td>-0.562578</td>\n",
              "      <td>-17.055458</td>\n",
              "      <td>-3.616732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-7.999715</td>\n",
              "      <td>-16.916729</td>\n",
              "      <td>-11.924855</td>\n",
              "      <td>17.955477</td>\n",
              "      <td>8.526994</td>\n",
              "      <td>56.635981</td>\n",
              "      <td>28.508435</td>\n",
              "      <td>...</td>\n",
              "      <td>1.045533</td>\n",
              "      <td>14.656061</td>\n",
              "      <td>-4.119778</td>\n",
              "      <td>-4.632381</td>\n",
              "      <td>-17.980657</td>\n",
              "      <td>-23.456960</td>\n",
              "      <td>-12.960684</td>\n",
              "      <td>-9.639784</td>\n",
              "      <td>-20.233549</td>\n",
              "      <td>-1.229811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.727283</td>\n",
              "      <td>-15.979567</td>\n",
              "      <td>-11.114195</td>\n",
              "      <td>17.183478</td>\n",
              "      <td>4.497028</td>\n",
              "      <td>43.914130</td>\n",
              "      <td>10.079754</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.741630</td>\n",
              "      <td>14.793562</td>\n",
              "      <td>-6.624813</td>\n",
              "      <td>-3.402757</td>\n",
              "      <td>-10.269473</td>\n",
              "      <td>-18.736144</td>\n",
              "      <td>-3.579046</td>\n",
              "      <td>-0.045658</td>\n",
              "      <td>-14.089755</td>\n",
              "      <td>2.453398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.819390</td>\n",
              "      <td>-0.204905</td>\n",
              "      <td>10.090124</td>\n",
              "      <td>20.265222</td>\n",
              "      <td>7.843006</td>\n",
              "      <td>36.250611</td>\n",
              "      <td>13.291199</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.135541</td>\n",
              "      <td>21.723418</td>\n",
              "      <td>-2.276825</td>\n",
              "      <td>2.066859</td>\n",
              "      <td>4.325365</td>\n",
              "      <td>-2.803322</td>\n",
              "      <td>8.835114</td>\n",
              "      <td>13.878945</td>\n",
              "      <td>-5.772410</td>\n",
              "      <td>7.657873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13.129486</td>\n",
              "      <td>-5.817193</td>\n",
              "      <td>5.040633</td>\n",
              "      <td>19.462210</td>\n",
              "      <td>9.634234</td>\n",
              "      <td>42.311729</td>\n",
              "      <td>20.641012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015602</td>\n",
              "      <td>19.703190</td>\n",
              "      <td>3.739076</td>\n",
              "      <td>2.714350</td>\n",
              "      <td>3.251047</td>\n",
              "      <td>-3.631448</td>\n",
              "      <td>3.212956</td>\n",
              "      <td>4.635574</td>\n",
              "      <td>-5.045448</td>\n",
              "      <td>5.086024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f463f617-bd55-4b51-82fd-2184cc489989')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f463f617-bd55-4b51-82fd-2184cc489989 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f463f617-bd55-4b51-82fd-2184cc489989');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8b41ca7a-abfe-485b-919e-aa7b421fcde5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8b41ca7a-abfe-485b-919e-aa7b421fcde5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8b41ca7a-abfe-485b-919e-aa7b421fcde5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_eeg = ['time', 'condition', 'epoch', 'target']\n",
        "channels = [ch for ch in df_train.columns if ch not in non_eeg]"
      ],
      "metadata": {
        "id": "lQoNvQJej_QN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = get_target(df_train)\n",
        "X = X.merge(calc_features(df_train, channels), on='epoch')\n",
        "y = X['condition'].apply(lambda x: 0 if x == 1 else 1)\n",
        "\n",
        "X = X.drop(['epoch', 'condition'], axis=1)\n",
        "y = y.astype(int)\n",
        "y.name = 'target'\n",
        "X = X.reset_index(drop=True)\n",
        "y = y.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "20MD4kEla1Wo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Моделирование (максимум 3.5 балла)\n",
        "[0.25] Обоснование стратегии разделения данных (train-test split)\n",
        "Особое внимание уделить предотвращению утечки данных\n",
        "\n",
        "[0.25] LAMA бейзлайн:\n",
        "- Минимум 2 различные конфигурации\n",
        "- Выбор лучшего решения\n",
        "\n",
        "[3.0] Собственное решение (если не удалось побить LLama baseline: 3 x 1.0 балл за различные пайплайны/попытки):\n",
        "- Выбор модели\n",
        "- Построение пайплайна (препроцессинг, обработка пропусков, генерация признаков, отбор признаков, финальная модель/ансамбль)\n",
        "- Оптимизация гиперпараметров"
      ],
      "metadata": {
        "id": "3wrlxECraw8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cтратегии разделения данных:\n",
        "# В соответствием с выводами из файла EDA (part 1) делаем корректный train-test split по данным, предварительно подготовленным по эпохам\n",
        "npr = np.random.RandomState(42)\n",
        "epoch_list = X.index\n",
        "train_idx, test_idx = train_test_split(epoch_list, test_size=0.33, random_state=42) ### делаем разбиение по эпохам как независимым объектам, чтобы избежать утечки между зависимыми наблюдениями, поскольку эпохи коррелированы внутри себя\n",
        "\n",
        "X_train = X.iloc[train_idx]\n",
        "X_test = X.iloc[test_idx]\n",
        "y_train = y.iloc[train_idx]\n",
        "y_test = y.iloc[test_idx]\n"
      ],
      "metadata": {
        "id": "4AscAZe7kZPi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим данные для конфигураций\n",
        "roles = {'target': 'target'}\n",
        "task = Task('binary')\n",
        "\n",
        "train_LAMA = X_train.copy()\n",
        "train_LAMA['target'] = y_train.values\n",
        "\n",
        "test_LAMA = X_test.copy()\n",
        "test_LAMA['target'] = y_test.values"
      ],
      "metadata": {
        "id": "RHBrprJMn5bm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Конфигурация 1 - Классический LAMA (default)\n",
        "Стандартная конфигурация - подбор лучших моделей (LGB, CatBoost и др.) с автотюнингом. Используем пресеты \"по умолчанию\"."
      ],
      "metadata": {
        "id": "6aT6E80FntZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl1 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        ")\n",
        "oof_pred1 = automl1.fit_predict(train_LAMA, roles=roles, verbose=2)\n",
        "test_pred1 = automl1.predict(test_LAMA)\n",
        "\n",
        "auc1 = roc_auc_score(y_test, test_pred1.data[:, 0])\n",
        "f1_1 = f1_score(y_test, test_pred1.data[:, 0] > 0.5)\n",
        "print(f\"[LAMA Default] ROC-AUC: {auc1:.4f} F1: {f1_1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mme0xL9slg9L",
        "outputId": "73e2d43e-ec40-4c29-ffc2-c7a8c876eb6b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightautoml.utils.timer:Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:31] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:48] Layer \u001b[1m1\u001b[0m train process start. Time left 582.14 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 582.14 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:49] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0, 1], 'embed_sizes': array([11, 11], dtype=int32), 'data_size': 27}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:49] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.5694444444444444\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.5763888888888888\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.5694444444444444\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.5694444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:50] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7062937062937064\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7062937062937064\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7062937062937064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:50] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8041958041958042\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8041958041958042\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8041958041958042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:50] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.4755244755244755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.4755244755244755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.4755244755244755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:50] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.951048951048951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428572\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428572\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] Time left 579.92 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 579.92 secs\n",
            "\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:51] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[198]\tvalid's auc: 0.576389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:52] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.734266\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.800699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:52] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.797203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.811189\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.825175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:53] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[4]\tvalid's auc: 0.65035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:53] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.86014\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.867133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:53] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:45:53] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 115.44 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 115.44 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-82bd636c-d49a-4497-b684-b2a56b5ea16a\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[62]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5277777777777779 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.5277777777777779.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.5277777777777779 in 0:00:00.334975\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<00:44,  2.26it/s, best_trial=0, best_value=0.528]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[184]\tvalid's auc: 0.541667\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.5416666666666667 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 1 with value: 0.5416666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.5416666666666667 in 0:00:02.860130\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:03<03:06,  1.88s/it, best_trial=1, best_value=0.542]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 2 with value: 0.5833333333333333.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored 0.5833333333333333 in 0:00:00.338129\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:03<01:57,  1.19s/it, best_trial=2, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[311]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: 0.5833333333333333.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored 0.5486111111111112 in 0:00:00.452201\n",
            "Optimization Progress:   4%|▍         | 4/101 [00:04<01:28,  1.10it/s, best_trial=2, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored 0.5902777777777778 in 0:00:00.188913\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:04<01:03,  1.50it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.524306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[31]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.517361111111111 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored 0.517361111111111 in 0:00:00.171625\n",
            "Optimization Progress:   6%|▌         | 6/101 [00:04<00:48,  1.94it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[102]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored 0.5486111111111112 in 0:00:00.261120\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:04<00:41,  2.26it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[19]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.5625 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored 0.5625 in 0:00:00.101051\n",
            "Optimization Progress:   8%|▊         | 8/101 [00:05<00:31,  2.94it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[438]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored 0.5486111111111112 in 0:00:00.405774\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:05<00:34,  2.70it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored 0.5902777777777778 in 0:00:00.144363\n",
            "Optimization Progress:  10%|▉         | 10/101 [00:05<00:28,  3.24it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196177, 'reg_lambda': 2.2311398834761413e-08}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196177, 'reg_lambda': 2.2311398834761413e-08} scored 0.5833333333333334 in 0:00:00.155462\n",
            "Optimization Progress:  11%|█         | 11/101 [00:05<00:24,  3.69it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.8469126656582232, 'num_leaves': 169, 'bagging_fraction': 0.519289733032828, 'min_sum_hessian_in_leaf': 0.0010742716082928, 'reg_alpha': 0.002611279023867545, 'reg_lambda': 1.2039880553605616e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.8469126656582232, 'num_leaves': 169, 'bagging_fraction': 0.519289733032828, 'min_sum_hessian_in_leaf': 0.0010742716082928, 'reg_alpha': 0.002611279023867545, 'reg_lambda': 1.2039880553605616e-06} scored 0.6145833333333334 in 0:00:00.235903\n",
            "Optimization Progress:  12%|█▏        | 12/101 [00:06<00:23,  3.71it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8658978481302979, 'num_leaves': 153, 'bagging_fraction': 0.6830184529242326, 'min_sum_hessian_in_leaf': 0.001202733529302086, 'reg_alpha': 0.004235211413864064, 'reg_lambda': 1.2326376711599453e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.8658978481302979, 'num_leaves': 153, 'bagging_fraction': 0.6830184529242326, 'min_sum_hessian_in_leaf': 0.001202733529302086, 'reg_alpha': 0.004235211413864064, 'reg_lambda': 1.2326376711599453e-08} scored 0.5902777777777778 in 0:00:00.237544\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:06<00:23,  3.74it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[372]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.6257630446746575, 'num_leaves': 187, 'bagging_fraction': 0.5326590026895619, 'min_sum_hessian_in_leaf': 0.022305423901154794, 'reg_alpha': 0.0006936640966924947, 'reg_lambda': 8.739363284316351e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6257630446746575, 'num_leaves': 187, 'bagging_fraction': 0.5326590026895619, 'min_sum_hessian_in_leaf': 0.022305423901154794, 'reg_alpha': 0.0006936640966924947, 'reg_lambda': 8.739363284316351e-07} scored 0.5902777777777778 in 0:00:00.190135\n",
            "Optimization Progress:  14%|█▍        | 14/101 [00:06<00:21,  3.96it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[121]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.8528943199501071, 'num_leaves': 115, 'bagging_fraction': 0.501737064356651, 'min_sum_hessian_in_leaf': 0.015569757430144106, 'reg_alpha': 0.06472842457094885, 'reg_lambda': 2.5237953668110687e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8528943199501071, 'num_leaves': 115, 'bagging_fraction': 0.501737064356651, 'min_sum_hessian_in_leaf': 0.015569757430144106, 'reg_alpha': 0.06472842457094885, 'reg_lambda': 2.5237953668110687e-07} scored 0.5763888888888888 in 0:00:00.259686\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:06<00:22,  3.78it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.9996812193207756, 'num_leaves': 194, 'bagging_fraction': 0.622344146322471, 'min_sum_hessian_in_leaf': 0.15801126222075507, 'reg_alpha': 0.0001319721127943001, 'reg_lambda': 6.170708682186709e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 194, 'bagging_fraction': 0.622344146322471, 'min_sum_hessian_in_leaf': 0.15801126222075507, 'reg_alpha': 0.0001319721127943001, 'reg_lambda': 6.170708682186709e-06} scored 0.5798611111111112 in 0:00:00.232576\n",
            "Optimization Progress:  16%|█▌        | 16/101 [00:07<00:22,  3.76it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.559028\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5590277777777778 and parameters: {'feature_fraction': 0.5921106718245519, 'num_leaves': 134, 'bagging_fraction': 0.7100199146543272, 'min_sum_hessian_in_leaf': 0.0010292076269383125, 'reg_alpha': 0.18433207025107978, 'reg_lambda': 0.0072619186476958935}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5921106718245519, 'num_leaves': 134, 'bagging_fraction': 0.7100199146543272, 'min_sum_hessian_in_leaf': 0.0010292076269383125, 'reg_alpha': 0.18433207025107978, 'reg_lambda': 0.0072619186476958935} scored 0.5590277777777778 in 0:00:00.402640\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:07<00:26,  3.18it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[85]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7347827814876735, 'num_leaves': 207, 'bagging_fraction': 0.6005597633103007, 'min_sum_hessian_in_leaf': 2.688837274792938, 'reg_alpha': 4.993406319402674e-05, 'reg_lambda': 9.057479064075203e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.7347827814876735, 'num_leaves': 207, 'bagging_fraction': 0.6005597633103007, 'min_sum_hessian_in_leaf': 2.688837274792938, 'reg_alpha': 4.993406319402674e-05, 'reg_lambda': 9.057479064075203e-08} scored 0.5972222222222222 in 0:00:00.287973\n",
            "Optimization Progress:  18%|█▊        | 18/101 [00:07<00:26,  3.11it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.503472\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.447917\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[41]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.4479166666666667 and parameters: {'feature_fraction': 0.858919856983951, 'num_leaves': 154, 'bagging_fraction': 0.5798160663037338, 'min_sum_hessian_in_leaf': 8.27374948552204, 'reg_alpha': 1.13634012677488e-05, 'reg_lambda': 9.391747423110572e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.858919856983951, 'num_leaves': 154, 'bagging_fraction': 0.5798160663037338, 'min_sum_hessian_in_leaf': 8.27374948552204, 'reg_alpha': 1.13634012677488e-05, 'reg_lambda': 9.391747423110572e-07} scored 0.4479166666666667 in 0:00:00.281905\n",
            "Optimization Progress:  19%|█▉        | 19/101 [00:08<00:26,  3.06it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[173]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.9312856915263297, 'num_leaves': 116, 'bagging_fraction': 0.7423578866620045, 'min_sum_hessian_in_leaf': 2.2094860255768407, 'reg_alpha': 6.425073507898103e-05, 'reg_lambda': 2.1216144115076414e-05}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.9312856915263297, 'num_leaves': 116, 'bagging_fraction': 0.7423578866620045, 'min_sum_hessian_in_leaf': 2.2094860255768407, 'reg_alpha': 6.425073507898103e-05, 'reg_lambda': 2.1216144115076414e-05} scored 0.5763888888888888 in 0:00:00.242482\n",
            "Optimization Progress:  20%|█▉        | 20/101 [00:08<00:25,  3.18it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[63]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.5902777777777779 and parameters: {'feature_fraction': 0.8285726521637807, 'num_leaves': 163, 'bagging_fraction': 0.6567290912374351, 'min_sum_hessian_in_leaf': 2.291093257748377, 'reg_alpha': 0.04506957328221599, 'reg_lambda': 1.330641472132417e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.8285726521637807, 'num_leaves': 163, 'bagging_fraction': 0.6567290912374351, 'min_sum_hessian_in_leaf': 2.291093257748377, 'reg_alpha': 0.04506957328221599, 'reg_lambda': 1.330641472132417e-07} scored 0.5902777777777779 in 0:00:01.006187\n",
            "Optimization Progress:  21%|██        | 21/101 [00:09<00:42,  1.89it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8132466062529451, 'num_leaves': 166, 'bagging_fraction': 0.6637452938214106, 'min_sum_hessian_in_leaf': 1.8029132161525185, 'reg_alpha': 0.13261505382331965, 'reg_lambda': 1.3403992245220467e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.8132466062529451, 'num_leaves': 166, 'bagging_fraction': 0.6637452938214106, 'min_sum_hessian_in_leaf': 1.8029132161525185, 'reg_alpha': 0.13261505382331965, 'reg_lambda': 1.3403992245220467e-07} scored 0.5972222222222222 in 0:00:00.120133\n",
            "Optimization Progress:  22%|██▏       | 22/101 [00:09<00:32,  2.40it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[320]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7562001274743712, 'num_leaves': 207, 'bagging_fraction': 0.5675287464945606, 'min_sum_hessian_in_leaf': 4.07970344156614, 'reg_alpha': 0.4554200086220865, 'reg_lambda': 2.2436304140611774e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.7562001274743712, 'num_leaves': 207, 'bagging_fraction': 0.5675287464945606, 'min_sum_hessian_in_leaf': 4.07970344156614, 'reg_alpha': 0.4554200086220865, 'reg_lambda': 2.2436304140611774e-06} scored 0.5972222222222222 in 0:00:00.263207\n",
            "Optimization Progress:  23%|██▎       | 23/101 [00:10<00:29,  2.62it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[147]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9093784190410645, 'num_leaves': 176, 'bagging_fraction': 0.6476974120699914, 'min_sum_hessian_in_leaf': 0.8386729634138481, 'reg_alpha': 0.0007735053268340218, 'reg_lambda': 8.951936883000952e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.9093784190410645, 'num_leaves': 176, 'bagging_fraction': 0.6476974120699914, 'min_sum_hessian_in_leaf': 0.8386729634138481, 'reg_alpha': 0.0007735053268340218, 'reg_lambda': 8.951936883000952e-08} scored 0.5833333333333333 in 0:00:00.344851\n",
            "Optimization Progress:  24%|██▍       | 24/101 [00:10<00:29,  2.59it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.69062900978545, 'num_leaves': 216, 'bagging_fraction': 0.5018953531678593, 'min_sum_hessian_in_leaf': 0.3392513394576354, 'reg_alpha': 0.02784960091864702, 'reg_lambda': 0.0001143222482423875}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.69062900978545, 'num_leaves': 216, 'bagging_fraction': 0.5018953531678593, 'min_sum_hessian_in_leaf': 0.3392513394576354, 'reg_alpha': 0.02784960091864702, 'reg_lambda': 0.0001143222482423875} scored 0.5833333333333334 in 0:00:00.199142\n",
            "Optimization Progress:  25%|██▍       | 25/101 [00:10<00:26,  2.92it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[50]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.7973736500379813, 'num_leaves': 134, 'bagging_fraction': 0.7253961123667921, 'min_sum_hessian_in_leaf': 2.2830933022303608, 'reg_alpha': 4.340290398807059e-05, 'reg_lambda': 6.470627713514866e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.7973736500379813, 'num_leaves': 134, 'bagging_fraction': 0.7253961123667921, 'min_sum_hessian_in_leaf': 2.2830933022303608, 'reg_alpha': 4.340290398807059e-05, 'reg_lambda': 6.470627713514866e-08} scored 0.5763888888888888 in 0:00:00.276533\n",
            "Optimization Progress:  26%|██▌       | 26/101 [00:10<00:25,  2.99it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8814726721906899, 'num_leaves': 102, 'bagging_fraction': 0.5629483833276161, 'min_sum_hessian_in_leaf': 1.2615751233429964, 'reg_alpha': 0.0037547703608254456, 'reg_lambda': 7.945708557969849e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.8814726721906899, 'num_leaves': 102, 'bagging_fraction': 0.5629483833276161, 'min_sum_hessian_in_leaf': 1.2615751233429964, 'reg_alpha': 0.0037547703608254456, 'reg_lambda': 7.945708557969849e-07} scored 0.6006944444444444 in 0:00:00.256520\n",
            "Optimization Progress:  27%|██▋       | 27/101 [00:11<00:23,  3.10it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9019507906380755, 'num_leaves': 101, 'bagging_fraction': 0.563296715484897, 'min_sum_hessian_in_leaf': 3.910319441183966, 'reg_alpha': 0.00023179479805717014, 'reg_lambda': 0.009316730154012064}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.9019507906380755, 'num_leaves': 101, 'bagging_fraction': 0.563296715484897, 'min_sum_hessian_in_leaf': 3.910319441183966, 'reg_alpha': 0.00023179479805717014, 'reg_lambda': 0.009316730154012064} scored 0.6006944444444444 in 0:00:00.110533\n",
            "Optimization Progress:  28%|██▊       | 28/101 [00:11<00:19,  3.75it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1]\tvalid's auc: 0.5\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.5 and parameters: {'feature_fraction': 0.8883264334731107, 'num_leaves': 94, 'bagging_fraction': 0.5560058607786, 'min_sum_hessian_in_leaf': 9.074966324558195, 'reg_alpha': 0.00030718283897620977, 'reg_lambda': 0.003005978370436641}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.8883264334731107, 'num_leaves': 94, 'bagging_fraction': 0.5560058607786, 'min_sum_hessian_in_leaf': 9.074966324558195, 'reg_alpha': 0.00030718283897620977, 'reg_lambda': 0.003005978370436641} scored 0.5 in 0:00:00.165214\n",
            "Optimization Progress:  29%|██▊       | 29/101 [00:11<00:17,  4.03it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[95]\tvalid's auc: 0.520833\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5208333333333334 and parameters: {'feature_fraction': 0.9475842266303223, 'num_leaves': 255, 'bagging_fraction': 0.9313235884212914, 'min_sum_hessian_in_leaf': 0.20434587069222476, 'reg_alpha': 0.005817966286343741, 'reg_lambda': 0.02712150854591092}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.9475842266303223, 'num_leaves': 255, 'bagging_fraction': 0.9313235884212914, 'min_sum_hessian_in_leaf': 0.20434587069222476, 'reg_alpha': 0.005817966286343741, 'reg_lambda': 0.02712150854591092} scored 0.5208333333333334 in 0:00:00.284918\n",
            "Optimization Progress:  30%|██▉       | 30/101 [00:11<00:18,  3.76it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[124]\tvalid's auc: 0.555556\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5555555555555556 and parameters: {'feature_fraction': 0.8819428594209011, 'num_leaves': 105, 'bagging_fraction': 0.7703076770846052, 'min_sum_hessian_in_leaf': 0.7955110174517752, 'reg_alpha': 5.988099602010475e-07, 'reg_lambda': 0.05751673949831533}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.8819428594209011, 'num_leaves': 105, 'bagging_fraction': 0.7703076770846052, 'min_sum_hessian_in_leaf': 0.7955110174517752, 'reg_alpha': 5.988099602010475e-07, 'reg_lambda': 0.05751673949831533} scored 0.5555555555555556 in 0:00:00.164664\n",
            "Optimization Progress:  31%|███       | 31/101 [00:12<00:17,  4.08it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[43]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8373200013550088, 'num_leaves': 20, 'bagging_fraction': 0.6090712604865073, 'min_sum_hessian_in_leaf': 4.697771309000721, 'reg_alpha': 0.0012441773808045456, 'reg_lambda': 6.647131592608324e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.8373200013550088, 'num_leaves': 20, 'bagging_fraction': 0.6090712604865073, 'min_sum_hessian_in_leaf': 4.697771309000721, 'reg_alpha': 0.0012441773808045456, 'reg_lambda': 6.647131592608324e-07} scored 0.5902777777777778 in 0:00:00.159070\n",
            "Optimization Progress:  32%|███▏      | 32/101 [00:12<00:16,  4.22it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[427]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7701444315301456, 'num_leaves': 80, 'bagging_fraction': 0.5158465280916995, 'min_sum_hessian_in_leaf': 3.732189197494083, 'reg_alpha': 0.00016293127214441923, 'reg_lambda': 4.839057629056056e-05}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7701444315301456, 'num_leaves': 80, 'bagging_fraction': 0.5158465280916995, 'min_sum_hessian_in_leaf': 3.732189197494083, 'reg_alpha': 0.00016293127214441923, 'reg_lambda': 4.839057629056056e-05} scored 0.5902777777777778 in 0:00:00.401722\n",
            "Optimization Progress:  33%|███▎      | 33/101 [00:12<00:20,  3.38it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8998892026135179, 'num_leaves': 121, 'bagging_fraction': 0.5725101999084058, 'min_sum_hessian_in_leaf': 1.1598630173023619, 'reg_alpha': 0.010879463816978246, 'reg_lambda': 0.002475670094665481}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.8998892026135179, 'num_leaves': 121, 'bagging_fraction': 0.5725101999084058, 'min_sum_hessian_in_leaf': 1.1598630173023619, 'reg_alpha': 0.010879463816978246, 'reg_lambda': 0.002475670094665481} scored 0.5902777777777778 in 0:00:00.188129\n",
            "Optimization Progress:  34%|███▎      | 34/101 [00:13<00:18,  3.63it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9654252765746477, 'num_leaves': 143, 'bagging_fraction': 0.5932025272310425, 'min_sum_hessian_in_leaf': 0.37200808980947503, 'reg_alpha': 3.66942589306389e-05, 'reg_lambda': 2.717924248159728e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.9654252765746477, 'num_leaves': 143, 'bagging_fraction': 0.5932025272310425, 'min_sum_hessian_in_leaf': 0.37200808980947503, 'reg_alpha': 3.66942589306389e-05, 'reg_lambda': 2.717924248159728e-06} scored 0.5833333333333333 in 0:00:00.582772\n",
            "Optimization Progress:  35%|███▍      | 35/101 [00:13<00:26,  2.52it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[284]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7248321173006003, 'num_leaves': 104, 'bagging_fraction': 0.5432143389065669, 'min_sum_hessian_in_leaf': 3.9340389173283947, 'reg_alpha': 1.3145174842777787e-06, 'reg_lambda': 5.616819190232959e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.7248321173006003, 'num_leaves': 104, 'bagging_fraction': 0.5432143389065669, 'min_sum_hessian_in_leaf': 3.9340389173283947, 'reg_alpha': 1.3145174842777787e-06, 'reg_lambda': 5.616819190232959e-07} scored 0.5902777777777778 in 0:00:00.483421\n",
            "Optimization Progress:  36%|███▌      | 36/101 [00:14<00:28,  2.26it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[39]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.6878781041902726, 'num_leaves': 89, 'bagging_fraction': 0.6050917464966283, 'min_sum_hessian_in_leaf': 0.5498900487995599, 'reg_alpha': 1.675870158978661e-05, 'reg_lambda': 0.7498650945882449}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6878781041902726, 'num_leaves': 89, 'bagging_fraction': 0.6050917464966283, 'min_sum_hessian_in_leaf': 0.5498900487995599, 'reg_alpha': 1.675870158978661e-05, 'reg_lambda': 0.7498650945882449} scored 0.5833333333333334 in 0:00:01.550939\n",
            "Optimization Progress:  37%|███▋      | 37/101 [00:15<00:51,  1.24it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9305029406741796, 'num_leaves': 73, 'bagging_fraction': 0.5253735472681968, 'min_sum_hessian_in_leaf': 0.001865553436196919, 'reg_alpha': 0.0022925756154773165, 'reg_lambda': 3.49629701653122e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.9305029406741796, 'num_leaves': 73, 'bagging_fraction': 0.5253735472681968, 'min_sum_hessian_in_leaf': 0.001865553436196919, 'reg_alpha': 0.0022925756154773165, 'reg_lambda': 3.49629701653122e-08} scored 0.6145833333333334 in 0:00:00.393890\n",
            "Optimization Progress:  38%|███▊      | 38/101 [00:16<00:44,  1.42it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9348560286191232, 'num_leaves': 68, 'bagging_fraction': 0.5257896500798322, 'min_sum_hessian_in_leaf': 0.0036573955142991618, 'reg_alpha': 0.0027541643540566975, 'reg_lambda': 2.9936787073789606e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.9348560286191232, 'num_leaves': 68, 'bagging_fraction': 0.5257896500798322, 'min_sum_hessian_in_leaf': 0.0036573955142991618, 'reg_alpha': 0.0027541643540566975, 'reg_lambda': 2.9936787073789606e-08} scored 0.6145833333333334 in 0:00:00.619289\n",
            "Optimization Progress:  39%|███▊      | 39/101 [00:16<00:42,  1.46it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9298305964756634, 'num_leaves': 45, 'bagging_fraction': 0.5226187215047378, 'min_sum_hessian_in_leaf': 0.0021336467619059167, 'reg_alpha': 0.002483771553959457, 'reg_lambda': 1.0886808766009548e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9298305964756634, 'num_leaves': 45, 'bagging_fraction': 0.5226187215047378, 'min_sum_hessian_in_leaf': 0.0021336467619059167, 'reg_alpha': 0.002483771553959457, 'reg_lambda': 1.0886808766009548e-08} scored 0.6145833333333334 in 0:00:00.066222\n",
            "Optimization Progress:  39%|███▊      | 39/101 [00:17<00:42,  1.46it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9439516136817188, 'num_leaves': 46, 'bagging_fraction': 0.5188991470819592, 'min_sum_hessian_in_leaf': 0.0021833719503143965, 'reg_alpha': 0.015722265406419748, 'reg_lambda': 1.2401629119014302e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.9439516136817188, 'num_leaves': 46, 'bagging_fraction': 0.5188991470819592, 'min_sum_hessian_in_leaf': 0.0021833719503143965, 'reg_alpha': 0.015722265406419748, 'reg_lambda': 1.2401629119014302e-08} scored 0.6145833333333334 in 0:00:00.067831\n",
            "Optimization Progress:  41%|████      | 41/101 [00:17<00:24,  2.44it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9321547889188007, 'num_leaves': 42, 'bagging_fraction': 0.5249342350802126, 'min_sum_hessian_in_leaf': 0.00212406210118282, 'reg_alpha': 0.023840676572282605, 'reg_lambda': 1.4645318441974015e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.9321547889188007, 'num_leaves': 42, 'bagging_fraction': 0.5249342350802126, 'min_sum_hessian_in_leaf': 0.00212406210118282, 'reg_alpha': 0.023840676572282605, 'reg_lambda': 1.4645318441974015e-08} scored 0.6145833333333334 in 0:00:00.075924\n",
            "Optimization Progress:  42%|████▏     | 42/101 [00:17<00:19,  3.00it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9814215540872783, 'num_leaves': 44, 'bagging_fraction': 0.5220389995601281, 'min_sum_hessian_in_leaf': 0.0037540431174034666, 'reg_alpha': 0.0015511968509139195, 'reg_lambda': 3.900266780665591e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.9814215540872783, 'num_leaves': 44, 'bagging_fraction': 0.5220389995601281, 'min_sum_hessian_in_leaf': 0.0037540431174034666, 'reg_alpha': 0.0015511968509139195, 'reg_lambda': 3.900266780665591e-08} scored 0.6145833333333334 in 0:00:00.075267\n",
            "Optimization Progress:  43%|████▎     | 43/101 [00:17<00:15,  3.66it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9296283008613073, 'num_leaves': 73, 'bagging_fraction': 0.5020782119359475, 'min_sum_hessian_in_leaf': 0.0019445430619787387, 'reg_alpha': 0.4703638334823923, 'reg_lambda': 1.1274007310170726e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.9296283008613073, 'num_leaves': 73, 'bagging_fraction': 0.5020782119359475, 'min_sum_hessian_in_leaf': 0.0019445430619787387, 'reg_alpha': 0.4703638334823923, 'reg_lambda': 1.1274007310170726e-08} scored 0.5902777777777778 in 0:00:00.068008\n",
            "Optimization Progress:  43%|████▎     | 43/101 [00:17<00:15,  3.66it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9547049024573764, 'num_leaves': 17, 'bagging_fraction': 0.5352683951575656, 'min_sum_hessian_in_leaf': 0.008999381191359188, 'reg_alpha': 0.01373820457217814, 'reg_lambda': 3.803166599544116e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.9547049024573764, 'num_leaves': 17, 'bagging_fraction': 0.5352683951575656, 'min_sum_hessian_in_leaf': 0.008999381191359188, 'reg_alpha': 0.01373820457217814, 'reg_lambda': 3.803166599544116e-08} scored 0.6006944444444444 in 0:00:00.063212\n",
            "Optimization Progress:  45%|████▍     | 45/101 [00:17<00:10,  5.15it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9430501937358311, 'num_leaves': 55, 'bagging_fraction': 0.5485045541315566, 'min_sum_hessian_in_leaf': 0.0019785093202409816, 'reg_alpha': 0.0032801608768030397, 'reg_lambda': 2.1110223829532783e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.9430501937358311, 'num_leaves': 55, 'bagging_fraction': 0.5485045541315566, 'min_sum_hessian_in_leaf': 0.0019785093202409816, 'reg_alpha': 0.0032801608768030397, 'reg_lambda': 2.1110223829532783e-07} scored 0.6006944444444444 in 0:00:00.077447\n",
            "Optimization Progress:  45%|████▍     | 45/101 [00:17<00:10,  5.15it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[31]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9949782255858528, 'num_leaves': 69, 'bagging_fraction': 0.5863154693031444, 'min_sum_hessian_in_leaf': 0.0035660563069327346, 'reg_alpha': 0.000620780207931044, 'reg_lambda': 2.8581421713504514e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.9949782255858528, 'num_leaves': 69, 'bagging_fraction': 0.5863154693031444, 'min_sum_hessian_in_leaf': 0.0035660563069327346, 'reg_alpha': 0.000620780207931044, 'reg_lambda': 2.8581421713504514e-08} scored 0.5902777777777778 in 0:00:00.074156\n",
            "Optimization Progress:  47%|████▋     | 47/101 [00:17<00:08,  6.31it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[207]\tvalid's auc: 0.534722\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.5347222222222222 and parameters: {'feature_fraction': 0.9148750585485912, 'num_leaves': 53, 'bagging_fraction': 0.8723363300656801, 'min_sum_hessian_in_leaf': 0.008510587795946187, 'reg_alpha': 0.0017258849462186373, 'reg_lambda': 1.1639351371999156e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.9148750585485912, 'num_leaves': 53, 'bagging_fraction': 0.8723363300656801, 'min_sum_hessian_in_leaf': 0.008510587795946187, 'reg_alpha': 0.0017258849462186373, 'reg_lambda': 1.1639351371999156e-08} scored 0.5347222222222222 in 0:00:00.104263\n",
            "Optimization Progress:  48%|████▊     | 48/101 [00:17<00:08,  6.57it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.635417\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.6354166666666667 and parameters: {'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07} scored 0.6354166666666667 in 0:00:00.063105\n",
            "Optimization Progress:  49%|████▊     | 49/101 [00:17<00:07,  7.04it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[11]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.9781728906553796, 'num_leaves': 28, 'bagging_fraction': 0.6406089351880103, 'min_sum_hessian_in_leaf': 0.001355782027617838, 'reg_alpha': 0.0006150736030054262, 'reg_lambda': 3.619751378990793e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.9781728906553796, 'num_leaves': 28, 'bagging_fraction': 0.6406089351880103, 'min_sum_hessian_in_leaf': 0.001355782027617838, 'reg_alpha': 0.0006150736030054262, 'reg_lambda': 3.619751378990793e-07} scored 0.5763888888888888 in 0:00:00.074066\n",
            "Optimization Progress:  49%|████▊     | 49/101 [00:18<00:07,  7.04it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.8610135129763458, 'num_leaves': 32, 'bagging_fraction': 0.6190859463934587, 'min_sum_hessian_in_leaf': 0.003394751000828341, 'reg_alpha': 0.006039538582936169, 'reg_lambda': 1.859722874626421e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.8610135129763458, 'num_leaves': 32, 'bagging_fraction': 0.6190859463934587, 'min_sum_hessian_in_leaf': 0.003394751000828341, 'reg_alpha': 0.006039538582936169, 'reg_lambda': 1.859722874626421e-06} scored 0.5798611111111112 in 0:00:00.064191\n",
            "Optimization Progress:  50%|█████     | 51/101 [00:18<00:06,  8.24it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[303]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9588296285728293, 'num_leaves': 48, 'bagging_fraction': 0.5182778865659797, 'min_sum_hessian_in_leaf': 0.0014688315766160013, 'reg_alpha': 0.08393142968705078, 'reg_lambda': 5.051889327547736e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.9588296285728293, 'num_leaves': 48, 'bagging_fraction': 0.5182778865659797, 'min_sum_hessian_in_leaf': 0.0014688315766160013, 'reg_alpha': 0.08393142968705078, 'reg_lambda': 5.051889327547736e-08} scored 0.5972222222222222 in 0:00:00.120774\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [00:18<00:06,  7.87it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9260615235749264, 'num_leaves': 62, 'bagging_fraction': 0.5470752862825393, 'min_sum_hessian_in_leaf': 0.0027811625535005343, 'reg_alpha': 0.020917598579091822, 'reg_lambda': 2.678210282593266e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.9260615235749264, 'num_leaves': 62, 'bagging_fraction': 0.5470752862825393, 'min_sum_hessian_in_leaf': 0.0027811625535005343, 'reg_alpha': 0.020917598579091822, 'reg_lambda': 2.678210282593266e-07} scored 0.6006944444444444 in 0:00:00.073127\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [00:18<00:06,  7.87it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[85]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.5536369471561253, 'num_leaves': 33, 'bagging_fraction': 0.5001221095785936, 'min_sum_hessian_in_leaf': 0.006661094351731153, 'reg_alpha': 0.006167175479320771, 'reg_lambda': 2.6809880407566107e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5536369471561253, 'num_leaves': 33, 'bagging_fraction': 0.5001221095785936, 'min_sum_hessian_in_leaf': 0.006661094351731153, 'reg_alpha': 0.006167175479320771, 'reg_lambda': 2.6809880407566107e-08} scored 0.5694444444444444 in 0:00:00.079755\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [00:18<00:05,  8.65it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9861255992544901, 'num_leaves': 71, 'bagging_fraction': 0.5310990238874806, 'min_sum_hessian_in_leaf': 0.013977499969107719, 'reg_alpha': 0.321084826790021, 'reg_lambda': 1.0545467042157705e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.9861255992544901, 'num_leaves': 71, 'bagging_fraction': 0.5310990238874806, 'min_sum_hessian_in_leaf': 0.013977499969107719, 'reg_alpha': 0.321084826790021, 'reg_lambda': 1.0545467042157705e-07} scored 0.6006944444444444 in 0:00:00.078752\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [00:18<00:05,  8.65it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[114]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9664636907261881, 'num_leaves': 80, 'bagging_fraction': 0.5788594495905532, 'min_sum_hessian_in_leaf': 0.0010114577180297046, 'reg_alpha': 2.264855375773613, 'reg_lambda': 2.1998774208462416e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.9664636907261881, 'num_leaves': 80, 'bagging_fraction': 0.5788594495905532, 'min_sum_hessian_in_leaf': 0.0010114577180297046, 'reg_alpha': 2.264855375773613, 'reg_lambda': 2.1998774208462416e-08} scored 0.5833333333333333 in 0:00:00.081554\n",
            "Optimization Progress:  55%|█████▌    | 56/101 [00:18<00:04,  9.10it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.874960577327053, 'num_leaves': 25, 'bagging_fraction': 0.5171331804115998, 'min_sum_hessian_in_leaf': 0.005181021933481765, 'reg_alpha': 0.0017284792234297539, 'reg_lambda': 8.20025939464645e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.874960577327053, 'num_leaves': 25, 'bagging_fraction': 0.5171331804115998, 'min_sum_hessian_in_leaf': 0.005181021933481765, 'reg_alpha': 0.0017284792234297539, 'reg_lambda': 8.20025939464645e-06} scored 0.5902777777777778 in 0:00:00.116997\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [00:18<00:05,  8.60it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8461247801196913, 'num_leaves': 38, 'bagging_fraction': 0.548819565094987, 'min_sum_hessian_in_leaf': 0.0025905903628920274, 'reg_alpha': 0.03801329737935307, 'reg_lambda': 1.5952379848718482e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.8461247801196913, 'num_leaves': 38, 'bagging_fraction': 0.548819565094987, 'min_sum_hessian_in_leaf': 0.0025905903628920274, 'reg_alpha': 0.03801329737935307, 'reg_lambda': 1.5952379848718482e-07} scored 0.6006944444444444 in 0:00:00.073151\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [00:18<00:05,  8.60it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[68]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.5625 and parameters: {'feature_fraction': 0.9389604032165146, 'num_leaves': 60, 'bagging_fraction': 0.8501399083840085, 'min_sum_hessian_in_leaf': 0.0015019835762393385, 'reg_alpha': 0.00038357823116459927, 'reg_lambda': 5.611792859757472e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.9389604032165146, 'num_leaves': 60, 'bagging_fraction': 0.8501399083840085, 'min_sum_hessian_in_leaf': 0.0015019835762393385, 'reg_alpha': 0.00038357823116459927, 'reg_lambda': 5.611792859757472e-08} scored 0.5625 in 0:00:00.114011\n",
            "Optimization Progress:  58%|█████▊    | 59/101 [00:19<00:04,  8.59it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9015211937609844, 'num_leaves': 49, 'bagging_fraction': 0.5838540248328894, 'min_sum_hessian_in_leaf': 0.004751676808119229, 'reg_alpha': 0.00010101264393424657, 'reg_lambda': 3.4864450028997447e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.9015211937609844, 'num_leaves': 49, 'bagging_fraction': 0.5838540248328894, 'min_sum_hessian_in_leaf': 0.004751676808119229, 'reg_alpha': 0.00010101264393424657, 'reg_lambda': 3.4864450028997447e-07} scored 0.5902777777777778 in 0:00:00.081008\n",
            "Optimization Progress:  59%|█████▉    | 60/101 [00:19<00:04,  8.75it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.586806\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.5868055555555555 and parameters: {'feature_fraction': 0.9168882630274567, 'num_leaves': 36, 'bagging_fraction': 0.6766643899084799, 'min_sum_hessian_in_leaf': 0.027686018660877165, 'reg_alpha': 0.009573816859155837, 'reg_lambda': 3.600155987170549e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.9168882630274567, 'num_leaves': 36, 'bagging_fraction': 0.6766643899084799, 'min_sum_hessian_in_leaf': 0.027686018660877165, 'reg_alpha': 0.009573816859155837, 'reg_lambda': 3.600155987170549e-06} scored 0.5868055555555555 in 0:00:00.070480\n",
            "Optimization Progress:  60%|██████    | 61/101 [00:19<00:04,  8.97it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.942430502919107, 'num_leaves': 42, 'bagging_fraction': 0.5288418704965183, 'min_sum_hessian_in_leaf': 0.0020368206282585666, 'reg_alpha': 0.02133359262103408, 'reg_lambda': 1.1406661630425062e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.942430502919107, 'num_leaves': 42, 'bagging_fraction': 0.5288418704965183, 'min_sum_hessian_in_leaf': 0.0020368206282585666, 'reg_alpha': 0.02133359262103408, 'reg_lambda': 1.1406661630425062e-08} scored 0.6215277777777778 in 0:00:00.075584\n",
            "Optimization Progress:  60%|██████    | 61/101 [00:19<00:04,  8.97it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9546334031595289, 'num_leaves': 25, 'bagging_fraction': 0.5378254715562456, 'min_sum_hessian_in_leaf': 0.0017377622282538896, 'reg_alpha': 0.0031223938236882532, 'reg_lambda': 1.8161103314700847e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.9546334031595289, 'num_leaves': 25, 'bagging_fraction': 0.5378254715562456, 'min_sum_hessian_in_leaf': 0.0017377622282538896, 'reg_alpha': 0.0031223938236882532, 'reg_lambda': 1.8161103314700847e-08} scored 0.6006944444444444 in 0:00:00.070862\n",
            "Optimization Progress:  62%|██████▏   | 63/101 [00:19<00:03,  9.51it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[69]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.9994875400251846, 'num_leaves': 61, 'bagging_fraction': 0.5623789247220361, 'min_sum_hessian_in_leaf': 0.0024969359098993495, 'reg_alpha': 0.07987259377379487, 'reg_lambda': 1.0719750722881284e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.9994875400251846, 'num_leaves': 61, 'bagging_fraction': 0.5623789247220361, 'min_sum_hessian_in_leaf': 0.0024969359098993495, 'reg_alpha': 0.07987259377379487, 'reg_lambda': 1.0719750722881284e-08} scored 0.6041666666666667 in 0:00:00.099027\n",
            "Optimization Progress:  63%|██████▎   | 64/101 [00:19<00:04,  9.21it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[252]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8909389962411892, 'num_leaves': 45, 'bagging_fraction': 0.511337245778791, 'min_sum_hessian_in_leaf': 0.0011908527737786567, 'reg_alpha': 0.0009750541837771642, 'reg_lambda': 6.147168849923748e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.8909389962411892, 'num_leaves': 45, 'bagging_fraction': 0.511337245778791, 'min_sum_hessian_in_leaf': 0.0011908527737786567, 'reg_alpha': 0.0009750541837771642, 'reg_lambda': 6.147168849923748e-08} scored 0.5972222222222222 in 0:00:00.110883\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [00:19<00:04,  8.60it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9179895581633201, 'num_leaves': 55, 'bagging_fraction': 0.5351088886151683, 'min_sum_hessian_in_leaf': 0.003968455887013349, 'reg_alpha': 0.014453234264072013, 'reg_lambda': 9.597134543399738}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.9179895581633201, 'num_leaves': 55, 'bagging_fraction': 0.5351088886151683, 'min_sum_hessian_in_leaf': 0.003968455887013349, 'reg_alpha': 0.014453234264072013, 'reg_lambda': 9.597134543399738} scored 0.6006944444444444 in 0:00:00.071431\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [00:19<00:04,  8.60it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[265]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8137550995736841, 'num_leaves': 181, 'bagging_fraction': 0.5598382882064329, 'min_sum_hessian_in_leaf': 0.002812553344915786, 'reg_alpha': 0.0025026271820271003, 'reg_lambda': 1.2081422918076064e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.8137550995736841, 'num_leaves': 181, 'bagging_fraction': 0.5598382882064329, 'min_sum_hessian_in_leaf': 0.002812553344915786, 'reg_alpha': 0.0025026271820271003, 'reg_lambda': 1.2081422918076064e-06} scored 0.5902777777777778 in 0:00:00.099936\n",
            "Optimization Progress:  66%|██████▋   | 67/101 [00:19<00:03,  8.75it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[163]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.5277777777777778 and parameters: {'feature_fraction': 0.9714045688078509, 'num_leaves': 84, 'bagging_fraction': 0.9804396137360377, 'min_sum_hessian_in_leaf': 0.006976333241859699, 'reg_alpha': 0.006378905337391348, 'reg_lambda': 1.0304944804596318e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.9714045688078509, 'num_leaves': 84, 'bagging_fraction': 0.9804396137360377, 'min_sum_hessian_in_leaf': 0.006976333241859699, 'reg_alpha': 0.006378905337391348, 'reg_lambda': 1.0304944804596318e-07} scored 0.5277777777777778 in 0:00:00.138343\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [00:20<00:04,  7.86it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[21]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.59375 and parameters: {'feature_fraction': 0.8694462898154652, 'num_leaves': 76, 'bagging_fraction': 0.7944393537734248, 'min_sum_hessian_in_leaf': 0.0010173893074085687, 'reg_alpha': 0.03709224196564614, 'reg_lambda': 2.521720902722272e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.8694462898154652, 'num_leaves': 76, 'bagging_fraction': 0.7944393537734248, 'min_sum_hessian_in_leaf': 0.0010173893074085687, 'reg_alpha': 0.03709224196564614, 'reg_lambda': 2.521720902722272e-08} scored 0.59375 in 0:00:00.074502\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [00:20<00:04,  7.86it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[346]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9438134524424316, 'num_leaves': 66, 'bagging_fraction': 0.514885526300983, 'min_sum_hessian_in_leaf': 0.051743092098014296, 'reg_alpha': 0.00046139415626740744, 'reg_lambda': 2.034068874554477e-05}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.9438134524424316, 'num_leaves': 66, 'bagging_fraction': 0.514885526300983, 'min_sum_hessian_in_leaf': 0.051743092098014296, 'reg_alpha': 0.00046139415626740744, 'reg_lambda': 2.034068874554477e-05} scored 0.5972222222222222 in 0:00:00.136929\n",
            "Optimization Progress:  69%|██████▉   | 70/101 [00:20<00:04,  7.74it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9043907657333571, 'num_leaves': 16, 'bagging_fraction': 0.5723640035663995, 'min_sum_hessian_in_leaf': 0.0016657419924648385, 'reg_alpha': 0.14695132685031148, 'reg_lambda': 1.7472296198492442e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.9043907657333571, 'num_leaves': 16, 'bagging_fraction': 0.5723640035663995, 'min_sum_hessian_in_leaf': 0.0016657419924648385, 'reg_alpha': 0.14695132685031148, 'reg_lambda': 1.7472296198492442e-07} scored 0.5902777777777778 in 0:00:00.079425\n",
            "Optimization Progress:  70%|███████   | 71/101 [00:20<00:03,  8.11it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9223939820020292, 'num_leaves': 41, 'bagging_fraction': 0.5238031840395967, 'min_sum_hessian_in_leaf': 0.0022966254514410343, 'reg_alpha': 0.01914089897415708, 'reg_lambda': 1.0293995286934194e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.9223939820020292, 'num_leaves': 41, 'bagging_fraction': 0.5238031840395967, 'min_sum_hessian_in_leaf': 0.0022966254514410343, 'reg_alpha': 0.01914089897415708, 'reg_lambda': 1.0293995286934194e-08} scored 0.6145833333333334 in 0:00:00.088750\n",
            "Optimization Progress:  71%|███████▏  | 72/101 [00:20<00:03,  8.26it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.930110134436058, 'num_leaves': 195, 'bagging_fraction': 0.5017032762241742, 'min_sum_hessian_in_leaf': 0.004793847940535511, 'reg_alpha': 0.026639853757879348, 'reg_lambda': 1.7211612899526624e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.930110134436058, 'num_leaves': 195, 'bagging_fraction': 0.5017032762241742, 'min_sum_hessian_in_leaf': 0.004793847940535511, 'reg_alpha': 0.026639853757879348, 'reg_lambda': 1.7211612899526624e-08} scored 0.5902777777777778 in 0:00:00.084892\n",
            "Optimization Progress:  72%|███████▏  | 73/101 [00:20<00:03,  8.48it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9463803858965383, 'num_leaves': 40, 'bagging_fraction': 0.528580130179981, 'min_sum_hessian_in_leaf': 0.0021333652397747646, 'reg_alpha': 0.009163765208397304, 'reg_lambda': 4.2453943104280346e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.9463803858965383, 'num_leaves': 40, 'bagging_fraction': 0.528580130179981, 'min_sum_hessian_in_leaf': 0.0021333652397747646, 'reg_alpha': 0.009163765208397304, 'reg_lambda': 4.2453943104280346e-08} scored 0.6215277777777778 in 0:00:00.090247\n",
            "Optimization Progress:  73%|███████▎  | 74/101 [00:20<00:03,  8.56it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9523746302288224, 'num_leaves': 31, 'bagging_fraction': 0.5541009340787182, 'min_sum_hessian_in_leaf': 0.001463941386349567, 'reg_alpha': 0.010610967187865254, 'reg_lambda': 4.293279366228622e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.9523746302288224, 'num_leaves': 31, 'bagging_fraction': 0.5541009340787182, 'min_sum_hessian_in_leaf': 0.001463941386349567, 'reg_alpha': 0.010610967187865254, 'reg_lambda': 4.293279366228622e-08} scored 0.6006944444444444 in 0:00:00.085763\n",
            "Optimization Progress:  74%|███████▍  | 75/101 [00:20<00:02,  8.70it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9836983526827456, 'num_leaves': 49, 'bagging_fraction': 0.5314065839402676, 'min_sum_hessian_in_leaf': 0.08157616343286032, 'reg_alpha': 0.00420710452536068, 'reg_lambda': 8.261280993326804e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.9836983526827456, 'num_leaves': 49, 'bagging_fraction': 0.5314065839402676, 'min_sum_hessian_in_leaf': 0.08157616343286032, 'reg_alpha': 0.00420710452536068, 'reg_lambda': 8.261280993326804e-08} scored 0.6006944444444444 in 0:00:00.082042\n",
            "Optimization Progress:  75%|███████▌  | 76/101 [00:21<00:02,  8.83it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[71]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8927985592983662, 'num_leaves': 124, 'bagging_fraction': 0.6006676657576917, 'min_sum_hessian_in_leaf': 0.002869782684867002, 'reg_alpha': 4.118195884803171e-08, 'reg_lambda': 3.5523210592233605e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.8927985592983662, 'num_leaves': 124, 'bagging_fraction': 0.6006676657576917, 'min_sum_hessian_in_leaf': 0.002869782684867002, 'reg_alpha': 4.118195884803171e-08, 'reg_lambda': 3.5523210592233605e-08} scored 0.5972222222222222 in 0:00:00.117091\n",
            "Optimization Progress:  76%|███████▌  | 77/101 [00:21<00:02,  8.09it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9706182911986332, 'num_leaves': 23, 'bagging_fraction': 0.5413937799210031, 'min_sum_hessian_in_leaf': 0.0019408669178434855, 'reg_alpha': 0.0491465176383278, 'reg_lambda': 3.998752495266748e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.9706182911986332, 'num_leaves': 23, 'bagging_fraction': 0.5413937799210031, 'min_sum_hessian_in_leaf': 0.0019408669178434855, 'reg_alpha': 0.0491465176383278, 'reg_lambda': 3.998752495266748e-07} scored 0.6006944444444444 in 0:00:00.079208\n",
            "Optimization Progress:  77%|███████▋  | 78/101 [00:21<00:02,  8.45it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[324]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.945389974352393, 'num_leaves': 165, 'bagging_fraction': 0.5113466356700372, 'min_sum_hessian_in_leaf': 0.001271870421737334, 'reg_alpha': 0.0013313968472653493, 'reg_lambda': 7.49583050219547e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.945389974352393, 'num_leaves': 165, 'bagging_fraction': 0.5113466356700372, 'min_sum_hessian_in_leaf': 0.001271870421737334, 'reg_alpha': 0.0013313968472653493, 'reg_lambda': 7.49583050219547e-08} scored 0.5902777777777778 in 0:00:00.150558\n",
            "Optimization Progress:  78%|███████▊  | 79/101 [00:21<00:02,  7.37it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.913410970286741, 'num_leaves': 141, 'bagging_fraction': 0.5667622874976119, 'min_sum_hessian_in_leaf': 0.011228745248082067, 'reg_alpha': 0.00247792984101857, 'reg_lambda': 2.0403344409315574e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.913410970286741, 'num_leaves': 141, 'bagging_fraction': 0.5667622874976119, 'min_sum_hessian_in_leaf': 0.011228745248082067, 'reg_alpha': 0.00247792984101857, 'reg_lambda': 2.0403344409315574e-08} scored 0.6041666666666667 in 0:00:00.094762\n",
            "Optimization Progress:  79%|███████▉  | 80/101 [00:21<00:02,  7.61it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9592676737274902, 'num_leaves': 91, 'bagging_fraction': 0.5283153111198535, 'min_sum_hessian_in_leaf': 0.0033558493912850687, 'reg_alpha': 0.00024953070456939597, 'reg_lambda': 1.4659672381457417e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.9592676737274902, 'num_leaves': 91, 'bagging_fraction': 0.5283153111198535, 'min_sum_hessian_in_leaf': 0.0033558493912850687, 'reg_alpha': 0.00024953070456939597, 'reg_lambda': 1.4659672381457417e-07} scored 0.6215277777777778 in 0:00:00.083027\n",
            "Optimization Progress:  80%|████████  | 81/101 [00:21<00:02,  8.08it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9371237156469211, 'num_leaves': 95, 'bagging_fraction': 0.5281036990805675, 'min_sum_hessian_in_leaf': 0.0033393128578611056, 'reg_alpha': 0.00017968669251903086, 'reg_lambda': 1.8568558219010845e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.9371237156469211, 'num_leaves': 95, 'bagging_fraction': 0.5281036990805675, 'min_sum_hessian_in_leaf': 0.0033393128578611056, 'reg_alpha': 0.00017968669251903086, 'reg_lambda': 1.8568558219010845e-07} scored 0.6215277777777778 in 0:00:00.093532\n",
            "Optimization Progress:  81%|████████  | 82/101 [00:21<00:02,  8.18it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9633252749020128, 'num_leaves': 94, 'bagging_fraction': 0.5510917175616286, 'min_sum_hessian_in_leaf': 0.0033304622254419405, 'reg_alpha': 0.0002938417822631321, 'reg_lambda': 1.9700292851303042e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.9633252749020128, 'num_leaves': 94, 'bagging_fraction': 0.5510917175616286, 'min_sum_hessian_in_leaf': 0.0033304622254419405, 'reg_alpha': 0.0002938417822631321, 'reg_lambda': 1.9700292851303042e-07} scored 0.6006944444444444 in 0:00:00.091364\n",
            "Optimization Progress:  82%|████████▏ | 83/101 [00:21<00:02,  8.31it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9898551514967519, 'num_leaves': 85, 'bagging_fraction': 0.5348885469337178, 'min_sum_hessian_in_leaf': 0.004373236968203782, 'reg_alpha': 8.798945140831016e-05, 'reg_lambda': 7.942273087771848e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.9898551514967519, 'num_leaves': 85, 'bagging_fraction': 0.5348885469337178, 'min_sum_hessian_in_leaf': 0.004373236968203782, 'reg_alpha': 8.798945140831016e-05, 'reg_lambda': 7.942273087771848e-07} scored 0.6006944444444444 in 0:00:00.087191\n",
            "Optimization Progress:  83%|████████▎ | 84/101 [00:22<00:02,  8.43it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9324712100253683, 'num_leaves': 96, 'bagging_fraction': 0.5257873469563064, 'min_sum_hessian_in_leaf': 0.005844050033759311, 'reg_alpha': 1.9708508146627605e-05, 'reg_lambda': 1.1924168194065236e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.9324712100253683, 'num_leaves': 96, 'bagging_fraction': 0.5257873469563064, 'min_sum_hessian_in_leaf': 0.005844050033759311, 'reg_alpha': 1.9708508146627605e-05, 'reg_lambda': 1.1924168194065236e-07} scored 0.6145833333333334 in 0:00:00.085509\n",
            "Optimization Progress:  84%|████████▍ | 85/101 [00:22<00:01,  8.66it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9571715365804392, 'num_leaves': 108, 'bagging_fraction': 0.5923862490090328, 'min_sum_hessian_in_leaf': 0.02070490074736979, 'reg_alpha': 0.00023849141121796614, 'reg_lambda': 4.5071919267358234e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.9571715365804392, 'num_leaves': 108, 'bagging_fraction': 0.5923862490090328, 'min_sum_hessian_in_leaf': 0.02070490074736979, 'reg_alpha': 0.00023849141121796614, 'reg_lambda': 4.5071919267358234e-07} scored 0.5833333333333333 in 0:00:00.128416\n",
            "Optimization Progress:  85%|████████▌ | 86/101 [00:22<00:01,  7.70it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[707]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.640870391490566, 'num_leaves': 76, 'bagging_fraction': 0.5077697109470044, 'min_sum_hessian_in_leaf': 0.0017534301451742412, 'reg_alpha': 0.00015496410650405544, 'reg_lambda': 1.3804641058807206e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.640870391490566, 'num_leaves': 76, 'bagging_fraction': 0.5077697109470044, 'min_sum_hessian_in_leaf': 0.0017534301451742412, 'reg_alpha': 0.00015496410650405544, 'reg_lambda': 1.3804641058807206e-06} scored 0.5972222222222222 in 0:00:00.201758\n",
            "Optimization Progress:  86%|████████▌ | 87/101 [00:22<00:02,  6.23it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.565972\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.5659722222222222 and parameters: {'feature_fraction': 0.9752774312869913, 'num_leaves': 156, 'bagging_fraction': 0.6154222090873193, 'min_sum_hessian_in_leaf': 0.001234022825554857, 'reg_alpha': 0.0009175332741032825, 'reg_lambda': 0.00012355755173482785}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.9752774312869913, 'num_leaves': 156, 'bagging_fraction': 0.6154222090873193, 'min_sum_hessian_in_leaf': 0.001234022825554857, 'reg_alpha': 0.0009175332741032825, 'reg_lambda': 0.00012355755173482785} scored 0.5659722222222222 in 0:00:00.085343\n",
            "Optimization Progress:  87%|████████▋ | 88/101 [00:22<00:01,  6.76it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8766602592079092, 'num_leaves': 66, 'bagging_fraction': 0.5739923713881478, 'min_sum_hessian_in_leaf': 0.003309515360306084, 'reg_alpha': 0.008041428753565174, 'reg_lambda': 5.273651462582435e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.8766602592079092, 'num_leaves': 66, 'bagging_fraction': 0.5739923713881478, 'min_sum_hessian_in_leaf': 0.003309515360306084, 'reg_alpha': 0.008041428753565174, 'reg_lambda': 5.273651462582435e-08} scored 0.5902777777777778 in 0:00:00.084129\n",
            "Optimization Progress:  88%|████████▊ | 89/101 [00:22<00:01,  7.31it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7815025327406322, 'num_leaves': 111, 'bagging_fraction': 0.5434682648204652, 'min_sum_hessian_in_leaf': 0.0023097941653223908, 'reg_alpha': 0.00047839433801774627, 'reg_lambda': 2.4457203156475713e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.7815025327406322, 'num_leaves': 111, 'bagging_fraction': 0.5434682648204652, 'min_sum_hessian_in_leaf': 0.0023097941653223908, 'reg_alpha': 0.00047839433801774627, 'reg_lambda': 2.4457203156475713e-07} scored 0.5902777777777778 in 0:00:00.122161\n",
            "Optimization Progress:  89%|████████▉ | 90/101 [00:22<00:01,  7.00it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[26]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9371005410548527, 'num_leaves': 127, 'bagging_fraction': 0.7023250606090462, 'min_sum_hessian_in_leaf': 0.0016716894099636506, 'reg_alpha': 0.004041638788933821, 'reg_lambda': 0.0009541486170814684}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.9371005410548527, 'num_leaves': 127, 'bagging_fraction': 0.7023250606090462, 'min_sum_hessian_in_leaf': 0.0016716894099636506, 'reg_alpha': 0.004041638788933821, 'reg_lambda': 0.0009541486170814684} scored 0.6006944444444444 in 0:00:00.102503\n",
            "Optimization Progress:  90%|█████████ | 91/101 [00:23<00:01,  7.12it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.944462844474678, 'num_leaves': 52, 'bagging_fraction': 0.5194569941235613, 'min_sum_hessian_in_leaf': 0.0020946306766425754, 'reg_alpha': 0.0017019134546921357, 'reg_lambda': 3.0201335726195324e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.944462844474678, 'num_leaves': 52, 'bagging_fraction': 0.5194569941235613, 'min_sum_hessian_in_leaf': 0.0020946306766425754, 'reg_alpha': 0.0017019134546921357, 'reg_lambda': 3.0201335726195324e-08} scored 0.6145833333333334 in 0:00:00.086898\n",
            "Optimization Progress:  91%|█████████ | 92/101 [00:23<00:01,  7.54it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.59375 and parameters: {'feature_fraction': 0.702954339705586, 'num_leaves': 39, 'bagging_fraction': 0.526315239321956, 'min_sum_hessian_in_leaf': 0.0029917223481043505, 'reg_alpha': 0.013721165447761667, 'reg_lambda': 1.6777799726070884e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.702954339705586, 'num_leaves': 39, 'bagging_fraction': 0.526315239321956, 'min_sum_hessian_in_leaf': 0.0029917223481043505, 'reg_alpha': 0.013721165447761667, 'reg_lambda': 1.6777799726070884e-08} scored 0.59375 in 0:00:00.131134\n",
            "Optimization Progress:  92%|█████████▏| 93/101 [00:23<00:01,  7.02it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.90836909876906, 'num_leaves': 58, 'bagging_fraction': 0.5550612247859568, 'min_sum_hessian_in_leaf': 0.0038316916744653567, 'reg_alpha': 0.0009737653075463701, 'reg_lambda': 1.3573127242658214e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.90836909876906, 'num_leaves': 58, 'bagging_fraction': 0.5550612247859568, 'min_sum_hessian_in_leaf': 0.0038316916744653567, 'reg_alpha': 0.0009737653075463701, 'reg_lambda': 1.3573127242658214e-07} scored 0.6006944444444444 in 0:00:00.085235\n",
            "Optimization Progress:  93%|█████████▎| 94/101 [00:23<00:00,  7.46it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9252262400640299, 'num_leaves': 44, 'bagging_fraction': 0.5101889351496826, 'min_sum_hessian_in_leaf': 0.002365064175976263, 'reg_alpha': 0.003135326524899884, 'reg_lambda': 3.796636602720537e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.9252262400640299, 'num_leaves': 44, 'bagging_fraction': 0.5101889351496826, 'min_sum_hessian_in_leaf': 0.002365064175976263, 'reg_alpha': 0.003135326524899884, 'reg_lambda': 3.796636602720537e-08} scored 0.6145833333333334 in 0:00:00.095961\n",
            "Optimization Progress:  94%|█████████▍| 95/101 [00:23<00:00,  7.68it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9603893859149825, 'num_leaves': 35, 'bagging_fraction': 0.5412820810145341, 'min_sum_hessian_in_leaf': 0.00797922127451075, 'reg_alpha': 0.0051155887344284615, 'reg_lambda': 3.886912476716241e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.9603893859149825, 'num_leaves': 35, 'bagging_fraction': 0.5412820810145341, 'min_sum_hessian_in_leaf': 0.00797922127451075, 'reg_alpha': 0.0051155887344284615, 'reg_lambda': 3.886912476716241e-06} scored 0.6006944444444444 in 0:00:00.097906\n",
            "Optimization Progress:  95%|█████████▌| 96/101 [00:23<00:00,  7.80it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9783072886814193, 'num_leaves': 66, 'bagging_fraction': 0.5243614787929631, 'min_sum_hessian_in_leaf': 0.0012065503756931789, 'reg_alpha': 0.0007046500438769085, 'reg_lambda': 1.7490647622902465e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.9783072886814193, 'num_leaves': 66, 'bagging_fraction': 0.5243614787929631, 'min_sum_hessian_in_leaf': 0.0012065503756931789, 'reg_alpha': 0.0007046500438769085, 'reg_lambda': 1.7490647622902465e-08} scored 0.6145833333333334 in 0:00:00.086352\n",
            "Optimization Progress:  96%|█████████▌| 97/101 [00:23<00:00,  7.94it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9495759378997074, 'num_leaves': 71, 'bagging_fraction': 0.5018907652901287, 'min_sum_hessian_in_leaf': 0.036543678834212404, 'reg_alpha': 0.0023107681838588088, 'reg_lambda': 6.010592314516021e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.9495759378997074, 'num_leaves': 71, 'bagging_fraction': 0.5018907652901287, 'min_sum_hessian_in_leaf': 0.036543678834212404, 'reg_alpha': 0.0023107681838588088, 'reg_lambda': 6.010592314516021e-08} scored 0.5902777777777778 in 0:00:00.097727\n",
            "Optimization Progress:  97%|█████████▋| 98/101 [00:24<00:00,  7.55it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8904873465890221, 'num_leaves': 229, 'bagging_fraction': 0.5589816170342593, 'min_sum_hessian_in_leaf': 0.005309180061201301, 'reg_alpha': 3.2466106147812156e-05, 'reg_lambda': 1.0466334183290597e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.8904873465890221, 'num_leaves': 229, 'bagging_fraction': 0.5589816170342593, 'min_sum_hessian_in_leaf': 0.005309180061201301, 'reg_alpha': 3.2466106147812156e-05, 'reg_lambda': 1.0466334183290597e-08} scored 0.6006944444444444 in 0:00:00.136122\n",
            "Optimization Progress:  98%|█████████▊| 99/101 [00:24<00:00,  7.05it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.8519441714971006, 'num_leaves': 29, 'bagging_fraction': 0.5804686031843174, 'min_sum_hessian_in_leaf': 0.0019493389917361035, 'reg_alpha': 0.008152758094642087, 'reg_lambda': 5.956298187510907e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.8519441714971006, 'num_leaves': 29, 'bagging_fraction': 0.5804686031843174, 'min_sum_hessian_in_leaf': 0.0019493389917361035, 'reg_alpha': 0.008152758094642087, 'reg_lambda': 5.956298187510907e-07} scored 0.5833333333333333 in 0:00:00.105699\n",
            "Optimization Progress:  99%|█████████▉| 100/101 [00:24<00:00,  7.05it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 100 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9394873719724268, 'num_leaves': 90, 'bagging_fraction': 0.5312411477171192, 'min_sum_hessian_in_leaf': 0.0010055766458709951, 'reg_alpha': 0.00019069390776600405, 'reg_lambda': 8.574897361064482e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.9394873719724268, 'num_leaves': 90, 'bagging_fraction': 0.5312411477171192, 'min_sum_hessian_in_leaf': 0.0010055766458709951, 'reg_alpha': 0.00019069390776600405, 'reg_lambda': 8.574897361064482e-08} scored 0.6006944444444444 in 0:00:00.112778\n",
            "Optimization Progress: 100%|██████████| 101/101 [00:24<00:00,  4.13it/s, best_trial=48, best_value=0.635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] The set of hyperparameters \u001b[1m{'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}\u001b[0m\n",
            " achieve 0.6354 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}\u001b[0m\n",
            " achieve 0.6354 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 28, 'feature_fraction': 0.9713386595732587, 'bagging_fraction': 0.5263780042015709, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.0014715560349285325}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.566434\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.706294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.863636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.65035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.867133\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.93007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6961495535714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6961495535714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 48.2ms\tremaining: 24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5347222 (84)\ttotal: 118ms\tremaining: 468ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 84\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 85 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5174825\tbest: 0.5174825 (0)\ttotal: 1.15ms\tremaining: 571ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6713287\tbest: 0.7062937 (49)\ttotal: 71.2ms\tremaining: 281ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7062937063\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 49\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 50 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7762238\tbest: 0.7762238 (0)\ttotal: 991us\tremaining: 495ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8111888\tbest: 0.8951049 (8)\ttotal: 70ms\tremaining: 277ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8951048951\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 8\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:18] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6503497\tbest: 0.6503497 (0)\ttotal: 820us\tremaining: 410ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6083916\tbest: 0.6608392 (2)\ttotal: 73.2ms\tremaining: 289ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6608391608\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:19] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5944056\tbest: 0.5944056 (0)\ttotal: 5.06ms\tremaining: 2.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8881119\tbest: 0.8951049 (10)\ttotal: 87.8ms\tremaining: 347ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8321678\tbest: 0.9020979 (101)\ttotal: 167ms\tremaining: 248ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9020979021\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 101\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 102 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6544363839285715\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6544363839285715\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:19] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-b947ecd2-a200-4d31-90c8-4820d75dd55f\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4548611\tbest: 0.4548611 (0)\ttotal: 1.16ms\tremaining: 578ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5486111 (64)\ttotal: 65.6ms\tremaining: 259ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.5486111111111112 in 0:00:00.158591\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<00:17,  5.69it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.01ms\tremaining: 504ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4305556\tbest: 0.4791667 (45)\ttotal: 72.2ms\tremaining: 285ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4791666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 45\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 46 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.47916666666666663 and parameters: {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4} scored 0.47916666666666663 in 0:00:00.149100\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:00<00:16,  5.94it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 950us\tremaining: 474ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5416667 (99)\ttotal: 51.3ms\tremaining: 203ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5486111 (110)\ttotal: 103ms\tremaining: 154ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13} scored 0.5486111111111112 in 0:00:00.156947\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:00<00:16,  5.84it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.31ms\tremaining: 657ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5208333 (87)\ttotal: 89.8ms\tremaining: 355ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5347222 (121)\ttotal: 185ms\tremaining: 275ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 121\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 122 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5347222222222222 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20} scored 0.5347222222222222 in 0:00:00.272059\n",
            "Optimization Progress:   4%|▍         | 4/101 [00:00<00:21,  4.59it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 4.37ms\tremaining: 2.18s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5763889 (5)\ttotal: 127ms\tremaining: 502ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.576388888888889 in 0:00:00.206686\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:01<00:21,  4.54it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 859us\tremaining: 429ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.4861111 (75)\ttotal: 49.7ms\tremaining: 196ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5138889 (155)\ttotal: 98.5ms\tremaining: 147ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.4722222\tbest: 0.5208333 (221)\ttotal: 150ms\tremaining: 98.9ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 221\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 222 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.5208333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11} scored 0.5208333333333334 in 0:00:00.214914\n",
            "Optimization Progress:   6%|▌         | 6/101 [00:01<00:21,  4.45it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.1ms\tremaining: 548ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5416667 (77)\ttotal: 137ms\tremaining: 541ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5416666666666667 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13} scored 0.5416666666666667 in 0:00:00.353156\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:01<00:25,  3.63it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 5.93ms\tremaining: 2.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.6111111 (39)\ttotal: 148ms\tremaining: 585ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5555556\tbest: 0.6180556 (105)\ttotal: 271ms\tremaining: 403ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 105\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 106 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.6180555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8} scored 0.6180555555555556 in 0:00:00.377581\n",
            "Optimization Progress:   8%|▊         | 8/101 [00:02<00:29,  3.18it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 2.8ms\tremaining: 1.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4305556\tbest: 0.4861111 (57)\ttotal: 203ms\tremaining: 803ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4861111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.48611111111111116 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4} scored 0.48611111111111116 in 0:00:00.332753\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:02<00:30,  3.03it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.21ms\tremaining: 603ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5138889 (98)\ttotal: 99.1ms\tremaining: 392ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4791667\tbest: 0.5347222 (108)\ttotal: 291ms\tremaining: 433ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 108\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 109 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5347222222222222 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.5347222222222222 in 0:00:00.398115\n",
            "Optimization Progress:  10%|▉         | 10/101 [00:02<00:32,  2.80it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 904us\tremaining: 451ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5486111 (100)\ttotal: 140ms\tremaining: 551ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5902778 (175)\ttotal: 274ms\tremaining: 408ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 175\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 176 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5902777777777778 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0001819474163917752, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0001819474163917752, 'min_data_in_leaf': 8} scored 0.5902777777777778 in 0:00:00.449692\n",
            "Optimization Progress:  11%|█         | 11/101 [00:03<00:35,  2.56it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.25ms\tremaining: 1.12s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5486111 (73)\ttotal: 121ms\tremaining: 480ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 73\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 74 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00046833878978964417, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00046833878978964417, 'min_data_in_leaf': 8} scored 0.5486111111111112 in 0:00:00.292502\n",
            "Optimization Progress:  12%|█▏        | 12/101 [00:03<00:32,  2.71it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.01ms\tremaining: 505ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4722222\tbest: 0.5347222 (19)\ttotal: 176ms\tremaining: 696ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 19\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 20 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5347222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.717362889366975e-05, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.717362889366975e-05, 'min_data_in_leaf': 8} scored 0.5347222222222222 in 0:00:00.299010\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:03<00:31,  2.80it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 969us\tremaining: 484ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5625000 (76)\ttotal: 116ms\tremaining: 459ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5694444 (130)\ttotal: 278ms\tremaining: 413ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5277778\tbest: 0.5763889 (215)\ttotal: 463ms\tremaining: 306ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 215\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 216 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5763888888888888 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.01829657623099352, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.01829657623099352, 'min_data_in_leaf': 8} scored 0.5763888888888888 in 0:00:00.590392\n",
            "Optimization Progress:  14%|█▍        | 14/101 [00:04<00:37,  2.31it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 915us\tremaining: 457ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4930556\tbest: 0.5694444 (63)\ttotal: 55.6ms\tremaining: 220ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 63\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 64 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 8.113466471626518e-05, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 8.113466471626518e-05, 'min_data_in_leaf': 7} scored 0.5694444444444444 in 0:00:00.148073\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:04<00:30,  2.83it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 731us\tremaining: 365ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5763889 (99)\ttotal: 65.9ms\tremaining: 260ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5833333 (117)\ttotal: 124ms\tremaining: 185ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 117\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 118 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232927, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232927, 'min_data_in_leaf': 17} scored 0.5833333333333334 in 0:00:00.194059\n",
            "Optimization Progress:  16%|█▌        | 16/101 [00:04<00:26,  3.24it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 841us\tremaining: 420ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5694444 (96)\ttotal: 55.5ms\tremaining: 219ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 96\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 97 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.048696351475407e-08, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.048696351475407e-08, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.177029\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:05<00:23,  3.65it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 4.04ms\tremaining: 2.01s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (99)\ttotal: 102ms\tremaining: 404ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5416667 (115)\ttotal: 197ms\tremaining: 293ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 115\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 116 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5416666666666667 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.957760880550027e-05, 'min_data_in_leaf': 6}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.957760880550027e-05, 'min_data_in_leaf': 6} scored 0.5416666666666667 in 0:00:00.285927\n",
            "Optimization Progress:  18%|█▊        | 18/101 [00:05<00:23,  3.53it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 804us\tremaining: 402ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (73)\ttotal: 59.1ms\tremaining: 234ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 73\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 74 iterations.\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.2067858697356172e-07, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.2067858697356172e-07, 'min_data_in_leaf': 1} scored 0.5486111111111112 in 0:00:00.164917\n",
            "Optimization Progress:  19%|█▉        | 19/101 [00:05<00:20,  3.96it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 774us\tremaining: 386ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (70)\ttotal: 56.1ms\tremaining: 222ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5069444\tbest: 0.5277778 (160)\ttotal: 109ms\tremaining: 163ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5069444\tbest: 0.5486111 (250)\ttotal: 164ms\tremaining: 109ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 250\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 251 iterations.\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.548611111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0004246257320120182, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0004246257320120182, 'min_data_in_leaf': 10} scored 0.548611111111111 in 0:00:00.255140\n",
            "Optimization Progress:  20%|█▉        | 20/101 [00:05<00:20,  3.87it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 1.84ms\tremaining: 917ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5763889 (5)\ttotal: 136ms\tremaining: 539ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 6.624697002635038e-06, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 6.624697002635038e-06, 'min_data_in_leaf': 10} scored 0.576388888888889 in 0:00:00.202142\n",
            "Optimization Progress:  21%|██        | 21/101 [00:06<00:19,  4.05it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 916us\tremaining: 457ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5486111 (76)\ttotal: 70.9ms\tremaining: 280ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5763889\tbest: 0.5902778 (194)\ttotal: 144ms\tremaining: 214ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5902777777777777 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.004449106483560384, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.004449106483560384, 'min_data_in_leaf': 18} scored 0.5902777777777777 in 0:00:00.272949\n",
            "Optimization Progress:  22%|██▏       | 22/101 [00:06<00:20,  3.85it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 701us\tremaining: 350ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5625000 (76)\ttotal: 60.4ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.019640160099654747, 'min_data_in_leaf': 19}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.019640160099654747, 'min_data_in_leaf': 19} scored 0.5625 in 0:00:00.159402\n",
            "Optimization Progress:  23%|██▎       | 23/101 [00:06<00:18,  4.26it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.01ms\tremaining: 507ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5972222 (79)\ttotal: 56.2ms\tremaining: 222ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 79\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 80 iterations.\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5972222222222223 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.002072889876972783, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.002072889876972783, 'min_data_in_leaf': 14} scored 0.5972222222222223 in 0:00:00.168062\n",
            "Optimization Progress:  24%|██▍       | 24/101 [00:06<00:17,  4.51it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 666us\tremaining: 332ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5625000 (39)\ttotal: 56.3ms\tremaining: 222ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5625 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00016848413978965784, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00016848413978965784, 'min_data_in_leaf': 14} scored 0.5625 in 0:00:00.145662\n",
            "Optimization Progress:  25%|██▍       | 25/101 [00:06<00:15,  4.87it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 957us\tremaining: 478ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6180556 (96)\ttotal: 53.6ms\tremaining: 212ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 96\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 97 iterations.\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.6180555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.6440799271560485e-05, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.6440799271560485e-05, 'min_data_in_leaf': 15} scored 0.6180555555555556 in 0:00:00.164425\n",
            "Optimization Progress:  26%|██▌       | 26/101 [00:07<00:14,  5.02it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 757us\tremaining: 378ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4444444\tbest: 0.4791667 (20)\ttotal: 54.2ms\tremaining: 214ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4791666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.4791666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0515463208746777e-06, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0515463208746777e-06, 'min_data_in_leaf': 15} scored 0.4791666666666667 in 0:00:00.122261\n",
            "Optimization Progress:  27%|██▋       | 27/101 [00:07<00:13,  5.49it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 4.57ms\tremaining: 2.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5277778 (49)\ttotal: 101ms\tremaining: 399ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5277777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 49\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 50 iterations.\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.5277777777777778 and parameters: {'max_depth': 6, 'l2_leaf_reg': 3.064331282043019e-05, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 3.064331282043019e-05, 'min_data_in_leaf': 16} scored 0.5277777777777778 in 0:00:00.220963\n",
            "Optimization Progress:  28%|██▊       | 28/101 [00:07<00:14,  5.02it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 808us\tremaining: 403ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6180556 (85)\ttotal: 62.4ms\tremaining: 247ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 85\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 86 iterations.\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.0763729858585045e-07, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.0763729858585045e-07, 'min_data_in_leaf': 12} scored 0.6180555555555556 in 0:00:00.179909\n",
            "Optimization Progress:  29%|██▊       | 29/101 [00:07<00:14,  5.00it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 722us\tremaining: 361ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5625000 (42)\ttotal: 120ms\tremaining: 474ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5347222\tbest: 0.5833333 (183)\ttotal: 183ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 183\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 184 iterations.\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.165310982087637e-08, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.165310982087637e-08, 'min_data_in_leaf': 12} scored 0.5833333333333333 in 0:00:00.300672\n",
            "Optimization Progress:  30%|██▉       | 30/101 [00:08<00:16,  4.25it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 715us\tremaining: 357ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.5833333 (97)\ttotal: 59.4ms\tremaining: 235ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.5902778 (154)\ttotal: 124ms\tremaining: 184ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 154\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 155 iterations.\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.028612442618824e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.028612442618824e-07, 'min_data_in_leaf': 16} scored 0.5902777777777778 in 0:00:00.220745\n",
            "Optimization Progress:  31%|███       | 31/101 [00:08<00:16,  4.21it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 747us\tremaining: 373ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5486111 (54)\ttotal: 73.7ms\tremaining: 291ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.83050845790229e-08, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.83050845790229e-08, 'min_data_in_leaf': 14} scored 0.5486111111111112 in 0:00:00.160347\n",
            "Optimization Progress:  32%|███▏      | 32/101 [00:08<00:15,  4.53it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 676us\tremaining: 337ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5833333 (63)\ttotal: 56.8ms\tremaining: 225ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 63\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 64 iterations.\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5833333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.3787541364024313e-05, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.3787541364024313e-05, 'min_data_in_leaf': 12} scored 0.5833333333333334 in 0:00:00.199451\n",
            "Optimization Progress:  33%|███▎      | 33/101 [00:08<00:15,  4.53it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 1.13ms\tremaining: 566ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5416667 (62)\ttotal: 64.9ms\tremaining: 256ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5486111 (145)\ttotal: 127ms\tremaining: 189ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 145\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 146 iterations.\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 6.943442953080223, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 6.943442953080223, 'min_data_in_leaf': 15} scored 0.5486111111111112 in 0:00:00.224107\n",
            "Optimization Progress:  34%|███▎      | 34/101 [00:08<00:15,  4.39it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 791us\tremaining: 395ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4375000\tbest: 0.5069444 (25)\ttotal: 57.9ms\tremaining: 229ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5069444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3803087778760937e-06, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3803087778760937e-06, 'min_data_in_leaf': 13} scored 0.5069444444444444 in 0:00:00.132949\n",
            "Optimization Progress:  35%|███▍      | 35/101 [00:09<00:13,  4.88it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.62ms\tremaining: 809ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5000000 (74)\ttotal: 75.3ms\tremaining: 297ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 74\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 75 iterations.\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.9082786134291037e-07, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.9082786134291037e-07, 'min_data_in_leaf': 17} scored 0.5 in 0:00:00.192068\n",
            "Optimization Progress:  36%|███▌      | 36/101 [00:09<00:13,  4.83it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 993us\tremaining: 496ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5486111 (71)\ttotal: 58.4ms\tremaining: 231ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 71\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 72 iterations.\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.479872737032061e-08, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.479872737032061e-08, 'min_data_in_leaf': 9} scored 0.5486111111111112 in 0:00:00.172778\n",
            "Optimization Progress:  37%|███▋      | 37/101 [00:09<00:13,  4.89it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4548611\tbest: 0.4548611 (0)\ttotal: 880us\tremaining: 439ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5625000 (64)\ttotal: 63.6ms\tremaining: 251ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.2153025282029422, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.2153025282029422, 'min_data_in_leaf': 12} scored 0.5625 in 0:00:00.172214\n",
            "Optimization Progress:  38%|███▊      | 38/101 [00:09<00:12,  4.94it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 792us\tremaining: 395ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5590278 (5)\ttotal: 59.7ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5590277778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.5590277777777777 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.060664273160767e-05, 'min_data_in_leaf': 5}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.060664273160767e-05, 'min_data_in_leaf': 5} scored 0.5590277777777777 in 0:00:00.128345\n",
            "Optimization Progress:  39%|███▊      | 39/101 [00:09<00:11,  5.32it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1ms\tremaining: 501ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5277778 (100)\ttotal: 81.6ms\tremaining: 322ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5625000 (165)\ttotal: 159ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 165\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 166 iterations.\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.5625 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0008487932279426703, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0008487932279426703, 'min_data_in_leaf': 14} scored 0.5625 in 0:00:00.287013\n",
            "Optimization Progress:  40%|███▉      | 40/101 [00:10<00:13,  4.47it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.14ms\tremaining: 569ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4375000\tbest: 0.4722222 (32)\ttotal: 53.6ms\tremaining: 212ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4722222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 32\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 33 iterations.\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.4722222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.1478050215294242e-08, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.1478050215294242e-08, 'min_data_in_leaf': 20} scored 0.4722222222222222 in 0:00:00.132082\n",
            "Optimization Progress:  41%|████      | 41/101 [00:10<00:12,  4.93it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 849us\tremaining: 424ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5416667 (17)\ttotal: 53.2ms\tremaining: 210ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 17\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 18 iterations.\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.5416666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00013386206224969417, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00013386206224969417, 'min_data_in_leaf': 9} scored 0.5416666666666667 in 0:00:00.124084\n",
            "Optimization Progress:  42%|████▏     | 42/101 [00:10<00:10,  5.40it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 695us\tremaining: 347ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4930556\tbest: 0.5208333 (91)\ttotal: 71.7ms\tremaining: 283ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5694444 (125)\ttotal: 126ms\tremaining: 187ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 125\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 126 iterations.\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.304546294989926e-06, 'min_data_in_leaf': 6}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.304546294989926e-06, 'min_data_in_leaf': 6} scored 0.5694444444444444 in 0:00:00.211605\n",
            "Optimization Progress:  43%|████▎     | 43/101 [00:10<00:11,  5.03it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 892us\tremaining: 445ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5555556 (80)\ttotal: 53.4ms\tremaining: 211ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.5694444 (117)\ttotal: 109ms\tremaining: 162ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 117\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 118 iterations.\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.014504522003259024, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.014504522003259024, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.185119\n",
            "Optimization Progress:  44%|████▎     | 44/101 [00:10<00:11,  4.98it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.18ms\tremaining: 591ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5347222 (55)\ttotal: 66ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 55\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 56 iterations.\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.5347222222222223 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.001098252087462213, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.001098252087462213, 'min_data_in_leaf': 9} scored 0.5347222222222223 in 0:00:00.182154\n",
            "Optimization Progress:  45%|████▍     | 45/101 [00:11<00:11,  4.95it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 786us\tremaining: 392ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (73)\ttotal: 56.4ms\tremaining: 223ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5694444 (128)\ttotal: 110ms\tremaining: 164ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 128\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 129 iterations.\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.1115690888055284, 'min_data_in_leaf': 3}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.1115690888055284, 'min_data_in_leaf': 3} scored 0.5694444444444444 in 0:00:00.188732\n",
            "Optimization Progress:  46%|████▌     | 46/101 [00:11<00:11,  4.92it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 811us\tremaining: 405ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5347222 (60)\ttotal: 64.2ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 60\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 61 iterations.\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5347222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0002693040540675074, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0002693040540675074, 'min_data_in_leaf': 7} scored 0.5347222222222222 in 0:00:00.163747\n",
            "Optimization Progress:  47%|████▋     | 47/101 [00:11<00:10,  5.03it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 883us\tremaining: 441ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5486111 (55)\ttotal: 89.9ms\tremaining: 355ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 55\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 56 iterations.\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.736840856541598e-05, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.736840856541598e-05, 'min_data_in_leaf': 10} scored 0.5486111111111112 in 0:00:00.191341\n",
            "Optimization Progress:  48%|████▊     | 48/101 [00:11<00:10,  4.87it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 722us\tremaining: 360ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5069444 (89)\ttotal: 54ms\tremaining: 213ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5208333 (105)\ttotal: 111ms\tremaining: 165ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 105\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 106 iterations.\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.5208333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8856689692767433e-05, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8856689692767433e-05, 'min_data_in_leaf': 13} scored 0.5208333333333334 in 0:00:00.183350\n",
            "Optimization Progress:  49%|████▊     | 49/101 [00:11<00:10,  4.87it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.31ms\tremaining: 654ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (70)\ttotal: 64.3ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 70\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 71 iterations.\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.4566674497558887e-06, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.4566674497558887e-06, 'min_data_in_leaf': 7} scored 0.5694444444444444 in 0:00:00.165122\n",
            "Optimization Progress:  50%|████▉     | 50/101 [00:12<00:10,  5.00it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 787us\tremaining: 393ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (97)\ttotal: 56.8ms\tremaining: 224ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 97\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 98 iterations.\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.5763888888888888 and parameters: {'max_depth': 3, 'l2_leaf_reg': 9.359397200734437e-05, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 9.359397200734437e-05, 'min_data_in_leaf': 11} scored 0.5763888888888888 in 0:00:00.168792\n",
            "Optimization Progress:  50%|█████     | 51/101 [00:12<00:09,  5.08it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.02ms\tremaining: 509ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (98)\ttotal: 62.1ms\tremaining: 245ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5694444\tbest: 0.5833333 (195)\ttotal: 122ms\tremaining: 182ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 195\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 196 iterations.\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.239744273560434e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.239744273560434e-07, 'min_data_in_leaf': 16} scored 0.5833333333333334 in 0:00:00.252193\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [00:12<00:10,  4.54it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.05ms\tremaining: 526ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4166667\tbest: 0.4652778 (28)\ttotal: 108ms\tremaining: 426ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4652777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 28\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 29 iterations.\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.4652777777777778 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.223069487676115e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.223069487676115e-07, 'min_data_in_leaf': 16} scored 0.4652777777777778 in 0:00:00.188981\n",
            "Optimization Progress:  52%|█████▏    | 53/101 [00:12<00:10,  4.59it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 1.23ms\tremaining: 615ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5833333 (72)\ttotal: 61.9ms\tremaining: 245ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.251254490699665e-08, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.251254490699665e-08, 'min_data_in_leaf': 17} scored 0.5833333333333333 in 0:00:00.187804\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [00:12<00:10,  4.64it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 784us\tremaining: 391ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5486111 (76)\ttotal: 55.1ms\tremaining: 218ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.548611111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.3717575614526088e-07, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.3717575614526088e-07, 'min_data_in_leaf': 13} scored 0.548611111111111 in 0:00:00.162324\n",
            "Optimization Progress:  54%|█████▍    | 55/101 [00:13<00:09,  4.82it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 715us\tremaining: 357ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6180556 (64)\ttotal: 63.1ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.6207037946608346e-06, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.6207037946608346e-06, 'min_data_in_leaf': 18} scored 0.6180555555555556 in 0:00:00.160922\n",
            "Optimization Progress:  55%|█████▌    | 56/101 [00:13<00:09,  4.98it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.16ms\tremaining: 578ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.4930556 (58)\ttotal: 76.8ms\tremaining: 303ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4722222\tbest: 0.5069444 (126)\ttotal: 154ms\tremaining: 229ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 126\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 127 iterations.\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.5069444444444444 and parameters: {'max_depth': 5, 'l2_leaf_reg': 7.4657927614131616e-06, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 7.4657927614131616e-06, 'min_data_in_leaf': 18} scored 0.5069444444444444 in 0:00:00.252049\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [00:13<00:09,  4.45it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 3.11ms\tremaining: 1.55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5555556 (35)\ttotal: 77.9ms\tremaining: 308ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5555555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 35\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 36 iterations.\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.5555555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.006336199757406834, 'min_data_in_leaf': 19}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.006336199757406834, 'min_data_in_leaf': 19} scored 0.5555555555555556 in 0:00:00.171159\n",
            "Optimization Progress:  57%|█████▋    | 58/101 [00:13<00:09,  4.61it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.26ms\tremaining: 629ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5555556\tbest: 0.5763889 (95)\ttotal: 99.8ms\tremaining: 394ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.5763888888888888 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.8637224103840083e-05, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.8637224103840083e-05, 'min_data_in_leaf': 8} scored 0.5763888888888888 in 0:00:00.257744\n",
            "Optimization Progress:  58%|█████▊    | 59/101 [00:14<00:09,  4.22it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 885us\tremaining: 442ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.5069444 (23)\ttotal: 59.1ms\tremaining: 233ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 23\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 24 iterations.\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.5069444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.642994664261131e-06, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.642994664261131e-06, 'min_data_in_leaf': 15} scored 0.5069444444444444 in 0:00:00.133138\n",
            "Optimization Progress:  59%|█████▉    | 60/101 [00:14<00:08,  4.68it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 850us\tremaining: 424ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5000000 (98)\ttotal: 63.1ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5208333 (189)\ttotal: 125ms\tremaining: 186ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.5208333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0008387488569813798, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0008387488569813798, 'min_data_in_leaf': 14} scored 0.5208333333333333 in 0:00:00.256559\n",
            "Optimization Progress:  60%|██████    | 61/101 [00:14<00:09,  4.25it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 782us\tremaining: 391ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5625000 (92)\ttotal: 140ms\tremaining: 554ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5833333 (114)\ttotal: 282ms\tremaining: 420ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 114\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 115 iterations.\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.317363648396127e-07, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.317363648396127e-07, 'min_data_in_leaf': 18} scored 0.5833333333333333 in 0:00:00.406282\n",
            "Optimization Progress:  61%|██████▏   | 62/101 [00:14<00:11,  3.35it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 2.08ms\tremaining: 1.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5416667 (42)\ttotal: 178ms\tremaining: 704ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5486111 (129)\ttotal: 344ms\tremaining: 512ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 129\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 130 iterations.\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.548611111111111 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.6361639172041583e-07, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.6361639172041583e-07, 'min_data_in_leaf': 15} scored 0.548611111111111 in 0:00:00.476221\n",
            "Optimization Progress:  62%|██████▏   | 63/101 [00:15<00:13,  2.78it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 922us\tremaining: 460ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5277778 (97)\ttotal: 165ms\tremaining: 653ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6180556\tbest: 0.6250000 (196)\ttotal: 337ms\tremaining: 501ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 196\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 197 iterations.\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12} scored 0.625 in 0:00:00.564680\n",
            "Optimization Progress:  63%|██████▎   | 64/101 [00:16<00:16,  2.30it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 5.29ms\tremaining: 2.64s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5763889 (5)\ttotal: 281ms\tremaining: 1.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 6.1637636876381684e-06, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 6.1637636876381684e-06, 'min_data_in_leaf': 12} scored 0.576388888888889 in 0:00:00.397830\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [00:16<00:15,  2.32it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 3.36ms\tremaining: 1.68s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4652778\tbest: 0.4861111 (49)\ttotal: 228ms\tremaining: 901ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5138889 (148)\ttotal: 437ms\tremaining: 650ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5138888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.5138888888888888 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.00027545242428155925, 'min_data_in_leaf': 10}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.00027545242428155925, 'min_data_in_leaf': 10} scored 0.5138888888888888 in 0:00:00.632152\n",
            "Optimization Progress:  65%|██████▌   | 66/101 [00:17<00:17,  1.99it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 3ms\tremaining: 1.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (84)\ttotal: 122ms\tremaining: 483ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 84\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 85 iterations.\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.5347222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.001566845101489e-05, 'min_data_in_leaf': 11}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.001566845101489e-05, 'min_data_in_leaf': 11} scored 0.5347222222222222 in 0:00:00.294047\n",
            "Optimization Progress:  66%|██████▋   | 67/101 [00:17<00:15,  2.22it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 3.17ms\tremaining: 1.58s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (89)\ttotal: 162ms\tremaining: 639ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 89\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 90 iterations.\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.844924355846328e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.844924355846328e-06, 'min_data_in_leaf': 13} scored 0.5694444444444444 in 0:00:00.333491\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [00:17<00:13,  2.36it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 827us\tremaining: 413ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5729167 (9)\ttotal: 99.3ms\tremaining: 392ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5729166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 9\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 10 iterations.\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.5729166666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.34064337539196e-05, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.34064337539196e-05, 'min_data_in_leaf': 12} scored 0.5729166666666667 in 0:00:00.208084\n",
            "Optimization Progress:  68%|██████▊   | 69/101 [00:18<00:11,  2.69it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 898us\tremaining: 449ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (47)\ttotal: 56.1ms\tremaining: 221ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.7171647319410317e-06, 'min_data_in_leaf': 9}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.7171647319410317e-06, 'min_data_in_leaf': 9} scored 0.5486111111111112 in 0:00:00.146886\n",
            "Optimization Progress:  69%|██████▉   | 70/101 [00:18<00:09,  3.19it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 693us\tremaining: 346ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4652778\tbest: 0.5069444 (44)\ttotal: 60.7ms\tremaining: 240ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 44\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 45 iterations.\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.5069444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.002400027668327387, 'min_data_in_leaf': 7}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.002400027668327387, 'min_data_in_leaf': 7} scored 0.5069444444444444 in 0:00:00.156113\n",
            "Optimization Progress:  70%|███████   | 71/101 [00:18<00:08,  3.64it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 861us\tremaining: 430ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6111111 (90)\ttotal: 61.8ms\tremaining: 244ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6111111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 90\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 91 iterations.\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.6111111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 6.805150867029861e-07, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 6.805150867029861e-07, 'min_data_in_leaf': 16} scored 0.6111111111111112 in 0:00:00.186453\n",
            "Optimization Progress:  71%|███████▏  | 72/101 [00:18<00:07,  3.91it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 941us\tremaining: 470ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.5902778 (72)\ttotal: 64.9ms\tremaining: 256ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.667701988822335e-07, 'min_data_in_leaf': 19}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.667701988822335e-07, 'min_data_in_leaf': 19} scored 0.5902777777777778 in 0:00:00.184468\n",
            "Optimization Progress:  72%|███████▏  | 73/101 [00:18<00:06,  4.11it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 737us\tremaining: 368ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5694444 (75)\ttotal: 66.2ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.6180556 (128)\ttotal: 136ms\tremaining: 203ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 128\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 129 iterations.\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.1441050927438204e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.1441050927438204e-08, 'min_data_in_leaf': 16} scored 0.6180555555555556 in 0:00:00.241385\n",
            "Optimization Progress:  73%|███████▎  | 74/101 [00:19<00:06,  3.97it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 990us\tremaining: 494ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5555556 (42)\ttotal: 77.4ms\tremaining: 306ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5833333 (136)\ttotal: 139ms\tremaining: 207ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 136\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 137 iterations.\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.8421318339824555e-08, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.8421318339824555e-08, 'min_data_in_leaf': 17} scored 0.5833333333333333 in 0:00:00.233821\n",
            "Optimization Progress:  74%|███████▍  | 75/101 [00:19<00:06,  3.88it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 730us\tremaining: 364ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5972222 (82)\ttotal: 63.4ms\tremaining: 251ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 82\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 83 iterations.\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.116920803564204e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.116920803564204e-08, 'min_data_in_leaf': 14} scored 0.5972222222222222 in 0:00:00.192186\n",
            "Optimization Progress:  75%|███████▌  | 76/101 [00:19<00:06,  4.04it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.01ms\tremaining: 506ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5208333 (95)\ttotal: 86ms\tremaining: 340ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5555556 (189)\ttotal: 165ms\tremaining: 245ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5555555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.5555555555555556 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.1697279504247739e-07, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.1697279504247739e-07, 'min_data_in_leaf': 17} scored 0.5555555555555556 in 0:00:00.307244\n",
            "Optimization Progress:  76%|███████▌  | 77/101 [00:20<00:06,  3.66it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 3.23ms\tremaining: 1.61s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.5833333 (87)\ttotal: 71.2ms\tremaining: 281ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 87\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 88 iterations.\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.977701255482796e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.977701255482796e-07, 'min_data_in_leaf': 15} scored 0.5833333333333334 in 0:00:00.225911\n",
            "Optimization Progress:  77%|███████▋  | 78/101 [00:20<00:06,  3.72it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 769us\tremaining: 384ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5694444 (82)\ttotal: 64.3ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5902778 (156)\ttotal: 129ms\tremaining: 192ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5625000\tbest: 0.5972222 (209)\ttotal: 196ms\tremaining: 130ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 209\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 210 iterations.\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.448373772204557e-06, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.448373772204557e-06, 'min_data_in_leaf': 16} scored 0.5972222222222222 in 0:00:00.287528\n",
            "Optimization Progress:  78%|███████▊  | 79/101 [00:20<00:06,  3.54it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 726us\tremaining: 363ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5902778 (78)\ttotal: 67ms\tremaining: 265ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 78\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 79 iterations.\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.8199845684305906e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.8199845684305906e-08, 'min_data_in_leaf': 14} scored 0.5902777777777778 in 0:00:00.178100\n",
            "Optimization Progress:  79%|███████▉  | 80/101 [00:20<00:05,  3.85it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.13ms\tremaining: 563ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4236111\tbest: 0.4722222 (86)\ttotal: 87.5ms\tremaining: 346ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4722222\tbest: 0.5277778 (143)\ttotal: 167ms\tremaining: 248ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5277777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 143\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 144 iterations.\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.5277777777777778 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.6803933477827973e-07, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.6803933477827973e-07, 'min_data_in_leaf': 16} scored 0.5277777777777778 in 0:00:00.271869\n",
            "Optimization Progress:  80%|████████  | 81/101 [00:21<00:05,  3.66it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.21ms\tremaining: 601ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5625000 (42)\ttotal: 68.8ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5555556\tbest: 0.5763889 (181)\ttotal: 147ms\tremaining: 218ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 181\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 182 iterations.\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.5763888888888888 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.1128499596008148e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.1128499596008148e-08, 'min_data_in_leaf': 14} scored 0.5763888888888888 in 0:00:00.274391\n",
            "Optimization Progress:  81%|████████  | 82/101 [00:21<00:05,  3.56it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 913us\tremaining: 456ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6041667 (87)\ttotal: 68.7ms\tremaining: 271ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5972222\tbest: 0.6180556 (141)\ttotal: 135ms\tremaining: 201ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 141\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 142 iterations.\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.574068519593644e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.574068519593644e-08, 'min_data_in_leaf': 15} scored 0.6180555555555556 in 0:00:00.232091\n",
            "Optimization Progress:  82%|████████▏ | 83/101 [00:21<00:04,  3.62it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 2.71ms\tremaining: 1.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5902778 (78)\ttotal: 71.7ms\tremaining: 283ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 78\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 79 iterations.\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 7.437174719026668e-08, 'min_data_in_leaf': 18}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 7.437174719026668e-08, 'min_data_in_leaf': 18} scored 0.5902777777777778 in 0:00:00.189278\n",
            "Optimization Progress:  83%|████████▎ | 84/101 [00:21<00:04,  3.87it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 972us\tremaining: 485ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5833333\tbest: 0.6041667 (91)\ttotal: 66.5ms\tremaining: 263ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6041666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 91\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 92 iterations.\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.6041666666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.1476176404251933e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.1476176404251933e-08, 'min_data_in_leaf': 15} scored 0.6041666666666667 in 0:00:00.190993\n",
            "Optimization Progress:  84%|████████▍ | 85/101 [00:22<00:03,  4.04it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.07ms\tremaining: 1.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6111111 (82)\ttotal: 79ms\tremaining: 312ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6111111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 82\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 83 iterations.\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.6111111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.2999033009059871e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.2999033009059871e-08, 'min_data_in_leaf': 15} scored 0.6111111111111112 in 0:00:00.208176\n",
            "Optimization Progress:  85%|████████▌ | 86/101 [00:22<00:03,  4.05it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 3.01ms\tremaining: 1.5s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5833333\tbest: 0.6041667 (91)\ttotal: 79.4ms\tremaining: 314ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6041666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 91\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 92 iterations.\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.6041666666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.744686386739921e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.744686386739921e-08, 'min_data_in_leaf': 16} scored 0.6041666666666667 in 0:00:00.210061\n",
            "Optimization Progress:  86%|████████▌ | 87/101 [00:22<00:03,  4.10it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.07ms\tremaining: 533ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5694444 (50)\ttotal: 68.4ms\tremaining: 270ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 50\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 51 iterations.\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.8060535383640392e-08, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.8060535383640392e-08, 'min_data_in_leaf': 17} scored 0.5694444444444444 in 0:00:00.169769\n",
            "Optimization Progress:  87%|████████▋ | 88/101 [00:22<00:02,  4.34it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.86ms\tremaining: 928ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (99)\ttotal: 101ms\tremaining: 401ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 99\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 100 iterations.\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.5208333333333334 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.0740346901859193e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.0740346901859193e-07, 'min_data_in_leaf': 15} scored 0.5208333333333334 in 0:00:00.271330\n",
            "Optimization Progress:  88%|████████▊ | 89/101 [00:23<00:03,  3.97it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.08ms\tremaining: 539ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5694444 (42)\ttotal: 67.4ms\tremaining: 266ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.0479205155504866e-08, 'min_data_in_leaf': 18}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.0479205155504866e-08, 'min_data_in_leaf': 18} scored 0.5694444444444444 in 0:00:00.160962\n",
            "Optimization Progress:  89%|████████▉ | 90/101 [00:23<00:02,  4.30it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.68ms\tremaining: 839ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (50)\ttotal: 107ms\tremaining: 425ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 50\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 51 iterations.\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.5347222222222222 and parameters: {'max_depth': 5, 'l2_leaf_reg': 5.649228140702103e-07, 'min_data_in_leaf': 20}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 5.649228140702103e-07, 'min_data_in_leaf': 20} scored 0.5347222222222222 in 0:00:00.215313\n",
            "Optimization Progress:  90%|█████████ | 91/101 [00:23<00:02,  4.22it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.1ms\tremaining: 549ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6041667\tbest: 0.6180556 (85)\ttotal: 64.4ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.6250000 (119)\ttotal: 130ms\tremaining: 193ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 119\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 120 iterations.\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.8885898763563533e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.8885898763563533e-08, 'min_data_in_leaf': 15} scored 0.625 in 0:00:00.204704\n",
            "Optimization Progress:  91%|█████████ | 92/101 [00:23<00:02,  4.28it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.46ms\tremaining: 1.23s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5763889 (99)\ttotal: 82.1ms\tremaining: 324ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5833333\tbest: 0.5972222 (172)\ttotal: 155ms\tremaining: 231ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 172\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 173 iterations.\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.480675299713325e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.480675299713325e-08, 'min_data_in_leaf': 16} scored 0.5972222222222222 in 0:00:00.274975\n",
            "Optimization Progress:  92%|█████████▏| 93/101 [00:24<00:02,  3.93it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 880us\tremaining: 439ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5694444 (42)\ttotal: 66.9ms\tremaining: 264ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5069444\tbest: 0.5972222 (136)\ttotal: 133ms\tremaining: 198ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 136\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 137 iterations.\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.10820206142718e-08, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.10820206142718e-08, 'min_data_in_leaf': 13} scored 0.5972222222222222 in 0:00:00.224640\n",
            "Optimization Progress:  93%|█████████▎| 94/101 [00:24<00:01,  3.90it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 914us\tremaining: 456ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5625000 (76)\ttotal: 93.2ms\tremaining: 368ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.2143622277119386e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.2143622277119386e-07, 'min_data_in_leaf': 15} scored 0.5625 in 0:00:00.212304\n",
            "Optimization Progress:  94%|█████████▍| 95/101 [00:24<00:01,  3.96it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.21ms\tremaining: 1.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (88)\ttotal: 71.3ms\tremaining: 282ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.576388888888889 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.901833163080404e-07, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.901833163080404e-07, 'min_data_in_leaf': 17} scored 0.576388888888889 in 0:00:00.199582\n",
            "Optimization Progress:  95%|█████████▌| 96/101 [00:24<00:01,  4.04it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 792us\tremaining: 396ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5625000 (61)\ttotal: 64ms\tremaining: 253ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 61\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 62 iterations.\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.5216990754596996e-08, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.5216990754596996e-08, 'min_data_in_leaf': 12} scored 0.5625 in 0:00:00.167616\n",
            "Optimization Progress:  96%|█████████▌| 97/101 [00:24<00:00,  4.29it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 2.91ms\tremaining: 1.45s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6041667\tbest: 0.6180556 (75)\ttotal: 65.5ms\tremaining: 259ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 75\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 76 iterations.\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.6151948215737286e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.6151948215737286e-06, 'min_data_in_leaf': 13} scored 0.6180555555555556 in 0:00:00.186506\n",
            "Optimization Progress:  97%|█████████▋| 98/101 [00:25<00:00,  4.36it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 773us\tremaining: 386ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.5104167 (2)\ttotal: 71.9ms\tremaining: 284ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5104166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.5104166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.854786417113306e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.854786417113306e-06, 'min_data_in_leaf': 13} scored 0.5104166666666666 in 0:00:00.141473\n",
            "Optimization Progress:  98%|█████████▊| 99/101 [00:25<00:00,  4.69it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.38ms\tremaining: 690ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (51)\ttotal: 98.9ms\tremaining: 391ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 51\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 52 iterations.\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.5694444444444444 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.3114310738937567e-06, 'min_data_in_leaf': 11}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.3114310738937567e-06, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.215059\n",
            "Optimization Progress:  99%|█████████▉| 100/101 [00:25<00:00,  4.48it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 991us\tremaining: 495ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (64)\ttotal: 66ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5694444 (155)\ttotal: 131ms\tremaining: 195ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 155\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 156 iterations.\n",
            "INFO:optuna.study.study:Trial 100 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.969115740725118e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.969115740725118e-06, 'min_data_in_leaf': 13} scored 0.5694444444444444 in 0:00:00.242462\n",
            "Optimization Progress: 100%|██████████| 101/101 [00:25<00:00,  3.90it/s, best_trial=63, best_value=0.625]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] The set of hyperparameters \u001b[1m{'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}\u001b[0m\n",
            " achieve 0.6250 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}\u001b[0m\n",
            " achieve 0.6250 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 5.347108898782771e-06, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 12, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 857us\tremaining: 2.57s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5972222 (77)\ttotal: 79.9ms\tremaining: 2.29s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5104895\tbest: 0.5104895 (0)\ttotal: 771us\tremaining: 2.31s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7202797\tbest: 0.8741259 (33)\ttotal: 61.2ms\tremaining: 1.76s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8741258741\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 33\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 34 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8006993\tbest: 0.8006993 (0)\ttotal: 958us\tremaining: 2.87s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7622378\tbest: 0.8321678 (5)\ttotal: 67.8ms\tremaining: 1.95s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8321678322\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6503497\tbest: 0.6503497 (0)\ttotal: 1.98ms\tremaining: 5.93s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6433566\tbest: 0.7202797 (3)\ttotal: 63.3ms\tremaining: 1.82s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7202797203\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 3\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 4 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:45] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6013986\tbest: 0.6013986 (0)\ttotal: 2.37ms\tremaining: 7.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8461538\tbest: 0.8741259 (73)\ttotal: 98.6ms\tremaining: 2.83s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8461538\tbest: 0.8951049 (169)\ttotal: 164ms\tremaining: 2.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8951048951\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 169\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 170 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7366071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7366071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Time left 525.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 525.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: optimization starts with equal weights. Score = \u001b[1m0.7123326\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.7123326\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7385603\u001b[0m, weights = \u001b[1m[0.41398153 0.06656854 0.14960875 0.         0.3698412 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7385603\u001b[0m, weights = \u001b[1m[0.41398153 0.06656854 0.14960875 0.         0.3698412 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7424665\u001b[0m, weights = \u001b[1m[0.46047238 0.         0.15539142 0.         0.38413626]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7424665\u001b[0m, weights = \u001b[1m[0.46047238 0.         0.15539142 0.         0.38413626]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7430246\u001b[0m, weights = \u001b[1m[0.5419463  0.         0.09016994 0.         0.36788374]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7430246\u001b[0m, weights = \u001b[1m[0.5419463  0.         0.09016994 0.         0.36788374]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7449777\u001b[0m, weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7449777\u001b[0m, weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Blending: best score = \u001b[1m0.7449777\u001b[0m, best weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.7449777\u001b[0m, best weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] \u001b[1mAutoml preset training completed in 75.35 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 75.35 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.61633 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07663 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.30704 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.61633 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07663 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.30704 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA Default] ROC-AUC: 0.7217 F1: 0.6557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конфигурация 2 — FAST, только lgbm\n",
        "Используем только быстрый LightGBM."
      ],
      "metadata": {
        "id": "k4VBQjtooR7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl2 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=300,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['lgb']]\n",
        "    }\n",
        ")\n",
        "oof_pred2 = automl2.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred2 = automl2.predict(test_LAMA)\n",
        "\n",
        "auc2 = roc_auc_score(y_test, test_pred2.data[:, 0])\n",
        "f1_2 = f1_score(y_test, test_pred2.data[:, 0] > 0.5)\n",
        "print(f'[LAMA FAST (lgb only)] ROC-AUC: {auc2:.4f}  F1: {f1_2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZBHF2-6mOe0",
        "outputId": "2aeb4ae3-d59f-48ae-ffe7-2c0d5968a26b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] - time: 300.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 300.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Layer \u001b[1m1\u001b[0m train process start. Time left 299.86 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 299.86 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[198]\tvalid's auc: 0.576389\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.734266\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.800699\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.797203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.811189\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.825175\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[4]\tvalid's auc: 0.65035\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.86014\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.867133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Time left 299.48 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 299.48 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] \u001b[1mAutoml preset training completed in 0.53 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 0.53 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA FAST (lgb only)] ROC-AUC: 0.7138  F1: 0.6552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конфигурация 3 - расширенный набор моделей и мощный автотюнинг\n",
        "\n",
        "Включаем сразу несколько ансамблей (XGB, LGBM с тюнингом, CatBoost с тюнингом, MLP нейросеть) + используем продвинутую кросс-валидацию, автотюнинг с разными алгоритмами"
      ],
      "metadata": {
        "id": "5J50gDVcpMiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl3 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['xgb', 'lgb_tuned', 'cb_tuned'], ['mlp']],  # Много моделей\n",
        "    },\n",
        "    reader_params={\n",
        "        'n_jobs': 2,\n",
        "        'cv': 5,\n",
        "        'random_state': 84,\n",
        "        'advanced_roles': True,\n",
        "    },\n",
        "    tuning_params={'max_tuning_iter': \"auto\", 'max_tuning_time': 300},\n",
        "    selection_params={'mode': 1}\n",
        ")\n",
        "\n",
        "oof_pred3 = automl3.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred3 = automl3.predict(test_LAMA)\n",
        "\n",
        "auc3 = roc_auc_score(y_test, test_pred3.data[:, 0])\n",
        "f1_3 = f1_score(y_test, test_pred3.data[:, 0] > 0.5)\n",
        "print(f'[LAMA Advanced] ROC-AUC: {auc3:.4f}  F1: {f1_3:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD1_Hxw4pKrr",
        "outputId": "b8c764b1-86f6-475a-ac6b-b4d8c4e22a5a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Layer \u001b[1m1\u001b[0m train process start. Time left 599.85 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 599.85 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.784722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.784722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:47] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 84.26 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 84.26 secs\n",
            "Optimization Progress:   0%|          | 0/100 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-b7fbf2ba-65b9-4edd-80b0-6b462232f72b\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125}. Best is trial 0 with value: 0.7916666666666666.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125} scored 0.7916666666666666 in 0:00:00.110874\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:13,  7.32it/s, best_trial=0, best_value=0.792]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.708333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.805556\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.8055555555555556 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547} scored 0.8055555555555556 in 0:00:00.064203\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:13,  7.32it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.680556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.680556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[211]\tvalid's auc: 0.680556\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.6805555555555556 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009} scored 0.6805555555555556 in 0:00:00.108407\n",
            "Optimization Progress:   3%|▎         | 3/100 [00:00<00:11,  8.50it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[7]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.7777777777777778 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254} scored 0.7777777777777778 in 0:00:00.141611\n",
            "Optimization Progress:   4%|▍         | 4/100 [00:00<00:13,  7.28it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.7777777777777777 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957} scored 0.7777777777777777 in 0:00:00.068770\n",
            "Optimization Progress:   4%|▍         | 4/100 [00:00<00:13,  7.28it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112} scored 0.7847222222222223 in 0:00:00.080105\n",
            "Optimization Progress:   6%|▌         | 6/100 [00:00<00:10,  8.68it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[27]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326} scored 0.7743055555555556 in 0:00:00.086268\n",
            "Optimization Progress:   7%|▋         | 7/100 [00:00<00:10,  8.95it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.7743055555555555 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573} scored 0.7743055555555555 in 0:00:00.527112\n",
            "Optimization Progress:   8%|▊         | 8/100 [00:01<00:21,  4.37it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988}. Best is trial 8 with value: 0.8680555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988} scored 0.8680555555555556 in 0:00:00.542225\n",
            "Optimization Progress:   9%|▉         | 9/100 [00:01<00:29,  3.08it/s, best_trial=8, best_value=0.868]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.826389\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.8263888888888891 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026}. Best is trial 8 with value: 0.8680555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026} scored 0.8263888888888891 in 0:00:00.085425\n",
            "Optimization Progress:  10%|█         | 10/100 [00:02<00:23,  3.80it/s, best_trial=8, best_value=0.868]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655} scored 0.8784722222222222 in 0:00:00.172109\n",
            "Optimization Progress:  11%|█         | 11/100 [00:02<00:21,  4.12it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5072704375811822, 'num_leaves': 112, 'bagging_fraction': 0.993551055264076, 'min_sum_hessian_in_leaf': 1.1073203961638332}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5072704375811822, 'num_leaves': 112, 'bagging_fraction': 0.993551055264076, 'min_sum_hessian_in_leaf': 1.1073203961638332} scored 0.8784722222222222 in 0:00:00.144552\n",
            "Optimization Progress:  12%|█▏        | 12/100 [00:02<00:19,  4.56it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.5171787317943728, 'num_leaves': 107, 'bagging_fraction': 0.9979227931587143, 'min_sum_hessian_in_leaf': 0.5223599678552181}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5171787317943728, 'num_leaves': 107, 'bagging_fraction': 0.9979227931587143, 'min_sum_hessian_in_leaf': 0.5223599678552181} scored 0.8645833333333334 in 0:00:00.300587\n",
            "Optimization Progress:  13%|█▎        | 13/100 [00:02<00:21,  3.98it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[86]\tvalid's auc: 0.826389\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.8263888888888888 and parameters: {'feature_fraction': 0.5877549579666643, 'num_leaves': 115, 'bagging_fraction': 0.9289315257325599, 'min_sum_hessian_in_leaf': 0.7984384465398439}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.5877549579666643, 'num_leaves': 115, 'bagging_fraction': 0.9289315257325599, 'min_sum_hessian_in_leaf': 0.7984384465398439} scored 0.8263888888888888 in 0:00:00.104254\n",
            "Optimization Progress:  14%|█▍        | 14/100 [00:02<00:18,  4.68it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.784722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5054066048641503, 'num_leaves': 154, 'bagging_fraction': 0.9162640577515773, 'min_sum_hessian_in_leaf': 5.6029779996253355}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5054066048641503, 'num_leaves': 154, 'bagging_fraction': 0.9162640577515773, 'min_sum_hessian_in_leaf': 5.6029779996253355} scored 0.8194444444444444 in 0:00:00.089685\n",
            "Optimization Progress:  15%|█▌        | 15/100 [00:02<00:15,  5.44it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.84375\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.84375 and parameters: {'feature_fraction': 0.9559583616089686, 'num_leaves': 88, 'bagging_fraction': 0.7587239087930508, 'min_sum_hessian_in_leaf': 0.40806072881474936}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9559583616089686, 'num_leaves': 88, 'bagging_fraction': 0.7587239087930508, 'min_sum_hessian_in_leaf': 0.40806072881474936} scored 0.84375 in 0:00:00.172018\n",
            "Optimization Progress:  16%|█▌        | 16/100 [00:03<00:15,  5.42it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[88]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5913239750713354, 'num_leaves': 158, 'bagging_fraction': 0.926364376824244, 'min_sum_hessian_in_leaf': 1.5599854273107514}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5913239750713354, 'num_leaves': 158, 'bagging_fraction': 0.926364376824244, 'min_sum_hessian_in_leaf': 1.5599854273107514} scored 0.8194444444444444 in 0:00:00.064794\n",
            "Optimization Progress:  16%|█▌        | 16/100 [00:03<00:15,  5.42it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5662238736103287, 'num_leaves': 89, 'bagging_fraction': 0.9996812193207756, 'min_sum_hessian_in_leaf': 0.163517101800661}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.5662238736103287, 'num_leaves': 89, 'bagging_fraction': 0.9996812193207756, 'min_sum_hessian_in_leaf': 0.163517101800661} scored 0.8715277777777778 in 0:00:00.055312\n",
            "Optimization Progress:  18%|█▊        | 18/100 [00:03<00:10,  7.46it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[76]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.798611111111111 and parameters: {'feature_fraction': 0.631402704879503, 'num_leaves': 121, 'bagging_fraction': 0.8926633901832717, 'min_sum_hessian_in_leaf': 0.8914606849331738}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.631402704879503, 'num_leaves': 121, 'bagging_fraction': 0.8926633901832717, 'min_sum_hessian_in_leaf': 0.8914606849331738} scored 0.798611111111111 in 0:00:00.068189\n",
            "Optimization Progress:  18%|█▊        | 18/100 [00:03<00:10,  7.46it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.8649174147658507, 'num_leaves': 173, 'bagging_fraction': 0.8226906749996505, 'min_sum_hessian_in_leaf': 3.2995575446337932}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8649174147658507, 'num_leaves': 173, 'bagging_fraction': 0.8226906749996505, 'min_sum_hessian_in_leaf': 3.2995575446337932} scored 0.7847222222222223 in 0:00:00.066630\n",
            "Optimization Progress:  20%|██        | 20/100 [00:03<00:09,  8.76it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.836806\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.7067070498463563, 'num_leaves': 85, 'bagging_fraction': 0.9541456411286611, 'min_sum_hessian_in_leaf': 0.04898881695460263}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.7067070498463563, 'num_leaves': 85, 'bagging_fraction': 0.9541456411286611, 'min_sum_hessian_in_leaf': 0.04898881695460263} scored 0.8472222222222221 in 0:00:00.059310\n",
            "Optimization Progress:  20%|██        | 20/100 [00:03<00:09,  8.76it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5559263702359063, 'num_leaves': 84, 'bagging_fraction': 0.9986377482329701, 'min_sum_hessian_in_leaf': 0.17231008353933194}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5559263702359063, 'num_leaves': 84, 'bagging_fraction': 0.9986377482329701, 'min_sum_hessian_in_leaf': 0.17231008353933194} scored 0.8715277777777778 in 0:00:00.063347\n",
            "Optimization Progress:  22%|██▏       | 22/100 [00:03<00:07,  9.92it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.8368055555555555 and parameters: {'feature_fraction': 0.5054945946218856, 'num_leaves': 130, 'bagging_fraction': 0.94820017621314, 'min_sum_hessian_in_leaf': 0.308295294680854}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5054945946218856, 'num_leaves': 130, 'bagging_fraction': 0.94820017621314, 'min_sum_hessian_in_leaf': 0.308295294680854} scored 0.8368055555555555 in 0:00:00.096421\n",
            "Optimization Progress:  22%|██▏       | 22/100 [00:03<00:07,  9.92it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.8125 and parameters: {'feature_fraction': 0.6165311953519939, 'num_leaves': 107, 'bagging_fraction': 0.8878524589325703, 'min_sum_hessian_in_leaf': 0.0012124232777004015}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.6165311953519939, 'num_leaves': 107, 'bagging_fraction': 0.8878524589325703, 'min_sum_hessian_in_leaf': 0.0012124232777004015} scored 0.8125 in 0:00:00.066622\n",
            "Optimization Progress:  24%|██▍       | 24/100 [00:03<00:07,  9.99it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[55]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.8541666666666666 and parameters: {'feature_fraction': 0.550617328682166, 'num_leaves': 69, 'bagging_fraction': 0.9779939568530936, 'min_sum_hessian_in_leaf': 1.1819341415222853}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.550617328682166, 'num_leaves': 69, 'bagging_fraction': 0.9779939568530936, 'min_sum_hessian_in_leaf': 1.1819341415222853} scored 0.8541666666666666 in 0:00:00.064561\n",
            "Optimization Progress:  24%|██▍       | 24/100 [00:03<00:07,  9.99it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.5514470366952647, 'num_leaves': 97, 'bagging_fraction': 0.7552952746257338, 'min_sum_hessian_in_leaf': 0.14794207709956203}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5514470366952647, 'num_leaves': 97, 'bagging_fraction': 0.7552952746257338, 'min_sum_hessian_in_leaf': 0.14794207709956203} scored 0.7986111111111112 in 0:00:00.059959\n",
            "Optimization Progress:  26%|██▌       | 26/100 [00:03<00:06, 10.71it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.8611111111111112 and parameters: {'feature_fraction': 0.5025765627923007, 'num_leaves': 134, 'bagging_fraction': 0.956134907542021, 'min_sum_hessian_in_leaf': 0.5348530477555123}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5025765627923007, 'num_leaves': 134, 'bagging_fraction': 0.956134907542021, 'min_sum_hessian_in_leaf': 0.5348530477555123} scored 0.8611111111111112 in 0:00:00.066175\n",
            "Optimization Progress:  26%|██▌       | 26/100 [00:04<00:06, 10.71it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.8125 and parameters: {'feature_fraction': 0.6123543264875693, 'num_leaves': 211, 'bagging_fraction': 0.8980629373406377, 'min_sum_hessian_in_leaf': 2.4727298255768178}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.6123543264875693, 'num_leaves': 211, 'bagging_fraction': 0.8980629373406377, 'min_sum_hessian_in_leaf': 2.4727298255768178} scored 0.8125 in 0:00:00.076871\n",
            "Optimization Progress:  28%|██▊       | 28/100 [00:04<00:06, 10.94it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.6738492699452632, 'num_leaves': 153, 'bagging_fraction': 0.864344536862268, 'min_sum_hessian_in_leaf': 0.06917430994658696}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.6738492699452632, 'num_leaves': 153, 'bagging_fraction': 0.864344536862268, 'min_sum_hessian_in_leaf': 0.06917430994658696} scored 0.7916666666666666 in 0:00:00.062558\n",
            "Optimization Progress:  28%|██▊       | 28/100 [00:04<00:06, 10.94it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[42]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.754625578626613, 'num_leaves': 72, 'bagging_fraction': 0.6875059696309002, 'min_sum_hessian_in_leaf': 0.21213838524854084}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.754625578626613, 'num_leaves': 72, 'bagging_fraction': 0.6875059696309002, 'min_sum_hessian_in_leaf': 0.21213838524854084} scored 0.7743055555555556 in 0:00:00.061790\n",
            "Optimization Progress:  30%|███       | 30/100 [00:04<00:06, 11.50it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[34]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.7777777777777778 and parameters: {'feature_fraction': 0.5706197351776557, 'num_leaves': 18, 'bagging_fraction': 0.7905237740880466, 'min_sum_hessian_in_leaf': 0.30016067833717425}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5706197351776557, 'num_leaves': 18, 'bagging_fraction': 0.7905237740880466, 'min_sum_hessian_in_leaf': 0.30016067833717425} scored 0.7777777777777778 in 0:00:00.062735\n",
            "Optimization Progress:  30%|███       | 30/100 [00:04<00:06, 11.50it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.5379401419008798, 'num_leaves': 86, 'bagging_fraction': 0.9986769697861296, 'min_sum_hessian_in_leaf': 0.16987299361785677}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5379401419008798, 'num_leaves': 86, 'bagging_fraction': 0.9986769697861296, 'min_sum_hessian_in_leaf': 0.16987299361785677} scored 0.8645833333333334 in 0:00:00.069801\n",
            "Optimization Progress:  32%|███▏      | 32/100 [00:04<00:05, 11.63it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5610209440253758, 'num_leaves': 100, 'bagging_fraction': 0.9589402492799868, 'min_sum_hessian_in_leaf': 0.028358643981436456}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.5610209440253758, 'num_leaves': 100, 'bagging_fraction': 0.9589402492799868, 'min_sum_hessian_in_leaf': 0.028358643981436456} scored 0.8472222222222222 in 0:00:00.068317\n",
            "Optimization Progress:  32%|███▏      | 32/100 [00:04<00:05, 11.63it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.5958430177790365, 'num_leaves': 121, 'bagging_fraction': 0.999680415235001, 'min_sum_hessian_in_leaf': 0.6481319077862837}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5958430177790365, 'num_leaves': 121, 'bagging_fraction': 0.999680415235001, 'min_sum_hessian_in_leaf': 0.6481319077862837} scored 0.861111111111111 in 0:00:00.067114\n",
            "Optimization Progress:  34%|███▍      | 34/100 [00:04<00:05, 11.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.5433537233548134, 'num_leaves': 65, 'bagging_fraction': 0.9341787178165374, 'min_sum_hessian_in_leaf': 4.9899201013561765}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5433537233548134, 'num_leaves': 65, 'bagging_fraction': 0.9341787178165374, 'min_sum_hessian_in_leaf': 4.9899201013561765} scored 0.7986111111111112 in 0:00:00.071699\n",
            "Optimization Progress:  34%|███▍      | 34/100 [00:04<00:05, 11.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[56]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5668227347721637, 'num_leaves': 55, 'bagging_fraction': 0.9706485216334223, 'min_sum_hessian_in_leaf': 0.22712233517259567}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5668227347721637, 'num_leaves': 55, 'bagging_fraction': 0.9706485216334223, 'min_sum_hessian_in_leaf': 0.22712233517259567} scored 0.8680555555555556 in 0:00:00.076609\n",
            "Optimization Progress:  36%|███▌      | 36/100 [00:04<00:05, 11.24it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[77]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.6332395074528491, 'num_leaves': 141, 'bagging_fraction': 0.8619202809672158, 'min_sum_hessian_in_leaf': 0.0859018688565443}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6332395074528491, 'num_leaves': 141, 'bagging_fraction': 0.8619202809672158, 'min_sum_hessian_in_leaf': 0.0859018688565443} scored 0.7847222222222223 in 0:00:00.075204\n",
            "Optimization Progress:  36%|███▌      | 36/100 [00:04<00:05, 11.24it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.652778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[9]\tvalid's auc: 0.725694\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.7256944444444445 and parameters: {'feature_fraction': 0.525662984573252, 'num_leaves': 83, 'bagging_fraction': 0.9091051222001301, 'min_sum_hessian_in_leaf': 9.074966324558195}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.525662984573252, 'num_leaves': 83, 'bagging_fraction': 0.9091051222001301, 'min_sum_hessian_in_leaf': 9.074966324558195} scored 0.7256944444444445 in 0:00:00.054623\n",
            "Optimization Progress:  38%|███▊      | 38/100 [00:05<00:05, 11.47it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.871528\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.875 and parameters: {'feature_fraction': 0.6794446347966296, 'num_leaves': 170, 'bagging_fraction': 0.9740659628079851, 'min_sum_hessian_in_leaf': 0.026733684234233765}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6794446347966296, 'num_leaves': 170, 'bagging_fraction': 0.9740659628079851, 'min_sum_hessian_in_leaf': 0.026733684234233765} scored 0.875 in 0:00:00.069189\n",
            "Optimization Progress:  38%|███▊      | 38/100 [00:05<00:05, 11.47it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.732639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.682635976821535, 'num_leaves': 194, 'bagging_fraction': 0.5821718262630846, 'min_sum_hessian_in_leaf': 0.012424791659069125}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.682635976821535, 'num_leaves': 194, 'bagging_fraction': 0.5821718262630846, 'min_sum_hessian_in_leaf': 0.012424791659069125} scored 0.7743055555555556 in 0:00:00.057487\n",
            "Optimization Progress:  40%|████      | 40/100 [00:05<00:05, 11.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.815972\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.7767062363660705, 'num_leaves': 223, 'bagging_fraction': 0.9418062092055598, 'min_sum_hessian_in_leaf': 0.014294895798843967}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7767062363660705, 'num_leaves': 223, 'bagging_fraction': 0.9418062092055598, 'min_sum_hessian_in_leaf': 0.014294895798843967} scored 0.8402777777777777 in 0:00:00.076841\n",
            "Optimization Progress:  40%|████      | 40/100 [00:05<00:05, 11.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[98]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.8499247626229005, 'num_leaves': 182, 'bagging_fraction': 0.9750268810977849, 'min_sum_hessian_in_leaf': 0.03277529409424081}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.8499247626229005, 'num_leaves': 182, 'bagging_fraction': 0.9750268810977849, 'min_sum_hessian_in_leaf': 0.03277529409424081} scored 0.861111111111111 in 0:00:00.075940\n",
            "Optimization Progress:  42%|████▏     | 42/100 [00:05<00:05, 11.38it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[90]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6543789089315727, 'num_leaves': 164, 'bagging_fraction': 0.9786655830512628, 'min_sum_hessian_in_leaf': 0.1462962355833542}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.6543789089315727, 'num_leaves': 164, 'bagging_fraction': 0.9786655830512628, 'min_sum_hessian_in_leaf': 0.1462962355833542} scored 0.8715277777777778 in 0:00:00.078692\n",
            "Optimization Progress:  42%|████▏     | 42/100 [00:05<00:05, 11.38it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5861241861467555, 'num_leaves': 138, 'bagging_fraction': 0.9971773394062716, 'min_sum_hessian_in_leaf': 0.00848147553770563}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5861241861467555, 'num_leaves': 138, 'bagging_fraction': 0.9971773394062716, 'min_sum_hessian_in_leaf': 0.00848147553770563} scored 0.8715277777777778 in 0:00:00.073096\n",
            "Optimization Progress:  44%|████▍     | 44/100 [00:05<00:05, 11.14it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.84375\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[101]\tvalid's auc: 0.850694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.8506944444444444 and parameters: {'feature_fraction': 0.7211265629053668, 'num_leaves': 114, 'bagging_fraction': 0.9598293613374059, 'min_sum_hessian_in_leaf': 0.1098334723278787}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.7211265629053668, 'num_leaves': 114, 'bagging_fraction': 0.9598293613374059, 'min_sum_hessian_in_leaf': 0.1098334723278787} scored 0.8506944444444444 in 0:00:00.083807\n",
            "Optimization Progress:  44%|████▍     | 44/100 [00:05<00:05, 11.14it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[69]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.5172546710784042, 'num_leaves': 96, 'bagging_fraction': 0.9223540183376234, 'min_sum_hessian_in_leaf': 0.0407504915948471}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.5172546710784042, 'num_leaves': 96, 'bagging_fraction': 0.9223540183376234, 'min_sum_hessian_in_leaf': 0.0407504915948471} scored 0.7916666666666666 in 0:00:00.085547\n",
            "Optimization Progress:  46%|████▌     | 46/100 [00:05<00:05, 10.68it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.802083\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.8020833333333333 and parameters: {'feature_fraction': 0.5311547018279753, 'num_leaves': 45, 'bagging_fraction': 0.545663749580285, 'min_sum_hessian_in_leaf': 0.37200808980947503}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.5311547018279753, 'num_leaves': 45, 'bagging_fraction': 0.545663749580285, 'min_sum_hessian_in_leaf': 0.37200808980947503} scored 0.8020833333333333 in 0:00:00.084157\n",
            "Optimization Progress:  46%|████▌     | 46/100 [00:05<00:05, 10.68it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.6134923868822042, 'num_leaves': 145, 'bagging_fraction': 0.8762211024599363, 'min_sum_hessian_in_leaf': 0.025281507072693138}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.6134923868822042, 'num_leaves': 145, 'bagging_fraction': 0.8762211024599363, 'min_sum_hessian_in_leaf': 0.025281507072693138} scored 0.7847222222222223 in 0:00:00.071607\n",
            "Optimization Progress:  48%|████▊     | 48/100 [00:05<00:05, 10.39it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5722847996162369, 'num_leaves': 126, 'bagging_fraction': 0.9390776418240152, 'min_sum_hessian_in_leaf': 1.0125432660178488}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.5722847996162369, 'num_leaves': 126, 'bagging_fraction': 0.9390776418240152, 'min_sum_hessian_in_leaf': 1.0125432660178488} scored 0.8472222222222222 in 0:00:00.076758\n",
            "Optimization Progress:  48%|████▊     | 48/100 [00:06<00:05, 10.39it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[175]\tvalid's auc: 0.770833\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.7708333333333334 and parameters: {'feature_fraction': 0.5972261990523502, 'num_leaves': 172, 'bagging_fraction': 0.7013402470396363, 'min_sum_hessian_in_leaf': 0.003417387460105571}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.5972261990523502, 'num_leaves': 172, 'bagging_fraction': 0.7013402470396363, 'min_sum_hessian_in_leaf': 0.003417387460105571} scored 0.7708333333333334 in 0:00:00.093156\n",
            "Optimization Progress:  50%|█████     | 50/100 [00:06<00:04, 10.09it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[28]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.5012937449274749, 'num_leaves': 76, 'bagging_fraction': 0.6626139126987496, 'min_sum_hessian_in_leaf': 2.0329490956388527}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.5012937449274749, 'num_leaves': 76, 'bagging_fraction': 0.6626139126987496, 'min_sum_hessian_in_leaf': 2.0329490956388527} scored 0.7916666666666666 in 0:00:00.067785\n",
            "Optimization Progress:  50%|█████     | 50/100 [00:06<00:04, 10.09it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[90]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6571376236191356, 'num_leaves': 166, 'bagging_fraction': 0.9805891412503506, 'min_sum_hessian_in_leaf': 0.13832513532005003}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.6571376236191356, 'num_leaves': 166, 'bagging_fraction': 0.9805891412503506, 'min_sum_hessian_in_leaf': 0.13832513532005003} scored 0.8715277777777778 in 0:00:00.071648\n",
            "Optimization Progress:  52%|█████▏    | 52/100 [00:06<00:04, 10.43it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[94]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.6942212569799582, 'num_leaves': 185, 'bagging_fraction': 0.9736314101715681, 'min_sum_hessian_in_leaf': 0.4253042151467997}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.6942212569799582, 'num_leaves': 185, 'bagging_fraction': 0.9736314101715681, 'min_sum_hessian_in_leaf': 0.4253042151467997} scored 0.8784722222222222 in 0:00:00.076858\n",
            "Optimization Progress:  52%|█████▏    | 52/100 [00:06<00:04, 10.43it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.829861\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.829861111111111 and parameters: {'feature_fraction': 0.7535342222529283, 'num_leaves': 189, 'bagging_fraction': 0.9136012901612219, 'min_sum_hessian_in_leaf': 1.3616609408398874}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.7535342222529283, 'num_leaves': 189, 'bagging_fraction': 0.9136012901612219, 'min_sum_hessian_in_leaf': 1.3616609408398874} scored 0.829861111111111 in 0:00:00.079880\n",
            "Optimization Progress:  54%|█████▍    | 54/100 [00:06<00:04, 10.36it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.8541666666666665 and parameters: {'feature_fraction': 0.6964673846126648, 'num_leaves': 201, 'bagging_fraction': 0.9657861289706489, 'min_sum_hessian_in_leaf': 0.44687560809299187}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.6964673846126648, 'num_leaves': 201, 'bagging_fraction': 0.9657861289706489, 'min_sum_hessian_in_leaf': 0.44687560809299187} scored 0.8541666666666665 in 0:00:00.078298\n",
            "Optimization Progress:  54%|█████▍    | 54/100 [00:06<00:04, 10.36it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5236182943225349, 'num_leaves': 109, 'bagging_fraction': 0.9887676447861163, 'min_sum_hessian_in_leaf': 0.592272074499006}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5236182943225349, 'num_leaves': 109, 'bagging_fraction': 0.9887676447861163, 'min_sum_hessian_in_leaf': 0.592272074499006} scored 0.8784722222222222 in 0:00:00.072256\n",
            "Optimization Progress:  56%|█████▌    | 56/100 [00:06<00:04, 10.43it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.815972\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.8402777777777778 and parameters: {'feature_fraction': 0.7351082836540076, 'num_leaves': 108, 'bagging_fraction': 0.9401179517868793, 'min_sum_hessian_in_leaf': 0.6759488103673505}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.7351082836540076, 'num_leaves': 108, 'bagging_fraction': 0.9401179517868793, 'min_sum_hessian_in_leaf': 0.6759488103673505} scored 0.8402777777777778 in 0:00:00.088232\n",
            "Optimization Progress:  56%|█████▌    | 56/100 [00:06<00:04, 10.43it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[27]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.7847222222222222 and parameters: {'feature_fraction': 0.5237055790304076, 'num_leaves': 221, 'bagging_fraction': 0.8436238084455718, 'min_sum_hessian_in_leaf': 3.85331757027904}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5237055790304076, 'num_leaves': 221, 'bagging_fraction': 0.8436238084455718, 'min_sum_hessian_in_leaf': 3.85331757027904} scored 0.7847222222222222 in 0:00:00.104132\n",
            "Optimization Progress:  58%|█████▊    | 58/100 [00:06<00:04,  9.82it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[101]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.8142634472008576, 'num_leaves': 148, 'bagging_fraction': 0.985242339724052, 'min_sum_hessian_in_leaf': 0.8457199071787568}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.8142634472008576, 'num_leaves': 148, 'bagging_fraction': 0.985242339724052, 'min_sum_hessian_in_leaf': 0.8457199071787568} scored 0.861111111111111 in 0:00:00.089626\n",
            "Optimization Progress:  59%|█████▉    | 59/100 [00:07<00:04,  9.65it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[61]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.8194444444444443 and parameters: {'feature_fraction': 0.6350698206790558, 'num_leaves': 244, 'bagging_fraction': 0.9016852820415449, 'min_sum_hessian_in_leaf': 1.7882195355586343}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.6350698206790558, 'num_leaves': 244, 'bagging_fraction': 0.9016852820415449, 'min_sum_hessian_in_leaf': 1.7882195355586343} scored 0.8194444444444443 in 0:00:00.075273\n",
            "Optimization Progress:  59%|█████▉    | 59/100 [00:07<00:04,  9.65it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.965946308365782, 'num_leaves': 177, 'bagging_fraction': 0.9546853364142939, 'min_sum_hessian_in_leaf': 0.6145281495340091}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.965946308365782, 'num_leaves': 177, 'bagging_fraction': 0.9546853364142939, 'min_sum_hessian_in_leaf': 0.6145281495340091} scored 0.861111111111111 in 0:00:00.076121\n",
            "Optimization Progress:  61%|██████    | 61/100 [00:07<00:03,  9.81it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5510250073842554, 'num_leaves': 94, 'bagging_fraction': 0.9999477860176184, 'min_sum_hessian_in_leaf': 0.28952978250789846}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5510250073842554, 'num_leaves': 94, 'bagging_fraction': 0.9999477860176184, 'min_sum_hessian_in_leaf': 0.28952978250789846} scored 0.8715277777777778 in 0:00:00.076206\n",
            "Optimization Progress:  61%|██████    | 61/100 [00:07<00:03,  9.81it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5153933180291268, 'num_leaves': 115, 'bagging_fraction': 0.982324781627865, 'min_sum_hessian_in_leaf': 0.08138363503213634}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5153933180291268, 'num_leaves': 115, 'bagging_fraction': 0.982324781627865, 'min_sum_hessian_in_leaf': 0.08138363503213634} scored 0.8680555555555556 in 0:00:00.066903\n",
            "Optimization Progress:  63%|██████▎   | 63/100 [00:07<00:03, 10.15it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[91]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.5442349619847018, 'num_leaves': 104, 'bagging_fraction': 0.9604479897129077, 'min_sum_hessian_in_leaf': 0.21092034714157915}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.5442349619847018, 'num_leaves': 104, 'bagging_fraction': 0.9604479897129077, 'min_sum_hessian_in_leaf': 0.21092034714157915} scored 0.8402777777777777 in 0:00:00.097326\n",
            "Optimization Progress:  63%|██████▎   | 63/100 [00:07<00:03, 10.15it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[88]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5586546834480711, 'num_leaves': 126, 'bagging_fraction': 0.927894146549521, 'min_sum_hessian_in_leaf': 0.33611463997776175}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.5586546834480711, 'num_leaves': 126, 'bagging_fraction': 0.927894146549521, 'min_sum_hessian_in_leaf': 0.33611463997776175} scored 0.8194444444444444 in 0:00:00.086692\n",
            "Optimization Progress:  65%|██████▌   | 65/100 [00:07<00:03,  9.67it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5815886339797922, 'num_leaves': 254, 'bagging_fraction': 0.986610252210261, 'min_sum_hessian_in_leaf': 1.1606828375448168}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5815886339797922, 'num_leaves': 254, 'bagging_fraction': 0.986610252210261, 'min_sum_hessian_in_leaf': 1.1606828375448168} scored 0.8715277777777778 in 0:00:00.080602\n",
            "Optimization Progress:  66%|██████▌   | 66/100 [00:07<00:03,  9.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.84375\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.8541666666666665 and parameters: {'feature_fraction': 0.6713728933283478, 'num_leaves': 58, 'bagging_fraction': 0.9666609804344071, 'min_sum_hessian_in_leaf': 0.5292834432355716}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.6713728933283478, 'num_leaves': 58, 'bagging_fraction': 0.9666609804344071, 'min_sum_hessian_in_leaf': 0.5292834432355716} scored 0.8541666666666665 in 0:00:00.086889\n",
            "Optimization Progress:  67%|██████▋   | 67/100 [00:07<00:03,  9.58it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.8368055555555556 and parameters: {'feature_fraction': 0.931507762058805, 'num_leaves': 134, 'bagging_fraction': 0.7809488345825834, 'min_sum_hessian_in_leaf': 0.18496191628762115}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.931507762058805, 'num_leaves': 134, 'bagging_fraction': 0.7809488345825834, 'min_sum_hessian_in_leaf': 0.18496191628762115} scored 0.8368055555555556 in 0:00:00.094330\n",
            "Optimization Progress:  68%|██████▊   | 68/100 [00:08<00:03,  9.31it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.857639\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.8576388888888888 and parameters: {'feature_fraction': 0.7060449691047949, 'num_leaves': 79, 'bagging_fraction': 0.9870744538184498, 'min_sum_hessian_in_leaf': 0.021261239895426266}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.7060449691047949, 'num_leaves': 79, 'bagging_fraction': 0.9870744538184498, 'min_sum_hessian_in_leaf': 0.021261239895426266} scored 0.8576388888888888 in 0:00:00.097476\n",
            "Optimization Progress:  69%|██████▉   | 69/100 [00:08<00:03,  9.03it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.8124999999999999 and parameters: {'feature_fraction': 0.5339850838357544, 'num_leaves': 91, 'bagging_fraction': 0.9426034992442726, 'min_sum_hessian_in_leaf': 0.05572916539472105}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.5339850838357544, 'num_leaves': 91, 'bagging_fraction': 0.9426034992442726, 'min_sum_hessian_in_leaf': 0.05572916539472105} scored 0.8124999999999999 in 0:00:00.079205\n",
            "Optimization Progress:  69%|██████▉   | 69/100 [00:08<00:03,  9.03it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.819444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5003974690318663, 'num_leaves': 119, 'bagging_fraction': 0.9502467799137907, 'min_sum_hessian_in_leaf': 2.520446337584062}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5003974690318663, 'num_leaves': 119, 'bagging_fraction': 0.9502467799137907, 'min_sum_hessian_in_leaf': 2.520446337584062} scored 0.8472222222222222 in 0:00:00.082184\n",
            "Optimization Progress:  71%|███████   | 71/100 [00:08<00:03,  9.30it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.6587894889025253, 'num_leaves': 162, 'bagging_fraction': 0.971180382458661, 'min_sum_hessian_in_leaf': 0.14602978757477644}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.6587894889025253, 'num_leaves': 162, 'bagging_fraction': 0.971180382458661, 'min_sum_hessian_in_leaf': 0.14602978757477644} scored 0.8645833333333334 in 0:00:00.090121\n",
            "Optimization Progress:  72%|███████▏  | 72/100 [00:08<00:03,  9.18it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[94]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.8645833333333333 and parameters: {'feature_fraction': 0.6435075837012219, 'num_leaves': 150, 'bagging_fraction': 0.9889161762237546, 'min_sum_hessian_in_leaf': 0.42319454689794295}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.6435075837012219, 'num_leaves': 150, 'bagging_fraction': 0.9889161762237546, 'min_sum_hessian_in_leaf': 0.42319454689794295} scored 0.8645833333333333 in 0:00:00.085614\n",
            "Optimization Progress:  73%|███████▎  | 73/100 [00:08<00:02,  9.15it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6202152842535253, 'num_leaves': 158, 'bagging_fraction': 0.9728853468830154, 'min_sum_hessian_in_leaf': 0.11288427812836782}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.6202152842535253, 'num_leaves': 158, 'bagging_fraction': 0.9728853468830154, 'min_sum_hessian_in_leaf': 0.11288427812836782} scored 0.8715277777777778 in 0:00:00.108146\n",
            "Optimization Progress:  74%|███████▍  | 74/100 [00:08<00:03,  8.59it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[106]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.9922172299870717, 'num_leaves': 169, 'bagging_fraction': 0.9988626222415926, 'min_sum_hessian_in_leaf': 0.25701821635058275}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.9922172299870717, 'num_leaves': 169, 'bagging_fraction': 0.9988626222415926, 'min_sum_hessian_in_leaf': 0.25701821635058275} scored 0.8194444444444444 in 0:00:00.096381\n",
            "Optimization Progress:  75%|███████▌  | 75/100 [00:08<00:02,  8.44it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.715451492634304, 'num_leaves': 186, 'bagging_fraction': 0.7265537839619253, 'min_sum_hessian_in_leaf': 0.7526601328978069}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.715451492634304, 'num_leaves': 186, 'bagging_fraction': 0.7265537839619253, 'min_sum_hessian_in_leaf': 0.7526601328978069} scored 0.7986111111111112 in 0:00:00.075894\n",
            "Optimization Progress:  75%|███████▌  | 75/100 [00:08<00:02,  8.44it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[67]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.6065607172116827, 'num_leaves': 178, 'bagging_fraction': 0.9505009162445209, 'min_sum_hessian_in_leaf': 0.07127636572932075}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.6065607172116827, 'num_leaves': 178, 'bagging_fraction': 0.9505009162445209, 'min_sum_hessian_in_leaf': 0.07127636572932075} scored 0.8402777777777777 in 0:00:00.107644\n",
            "Optimization Progress:  77%|███████▋  | 77/100 [00:09<00:02,  8.48it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[57]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.8368055555555555 and parameters: {'feature_fraction': 0.7389545838033889, 'num_leaves': 195, 'bagging_fraction': 0.9199592602613168, 'min_sum_hessian_in_leaf': 0.46347247430826616}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.7389545838033889, 'num_leaves': 195, 'bagging_fraction': 0.9199592602613168, 'min_sum_hessian_in_leaf': 0.46347247430826616} scored 0.8368055555555555 in 0:00:00.089929\n",
            "Optimization Progress:  78%|███████▊  | 78/100 [00:09<00:02,  8.57it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.875 and parameters: {'feature_fraction': 0.5179991373529929, 'num_leaves': 108, 'bagging_fraction': 0.9809288047802656, 'min_sum_hessian_in_leaf': 0.0968360871455689}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.5179991373529929, 'num_leaves': 108, 'bagging_fraction': 0.9809288047802656, 'min_sum_hessian_in_leaf': 0.0968360871455689} scored 0.875 in 0:00:00.096533\n",
            "Optimization Progress:  79%|███████▉  | 79/100 [00:09<00:02,  8.47it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[16]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.7847222222222221 and parameters: {'feature_fraction': 0.5165299464802199, 'num_leaves': 111, 'bagging_fraction': 0.880302520353175, 'min_sum_hessian_in_leaf': 0.04417565099296417}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.5165299464802199, 'num_leaves': 111, 'bagging_fraction': 0.880302520353175, 'min_sum_hessian_in_leaf': 0.04417565099296417} scored 0.7847222222222221 in 0:00:00.074463\n",
            "Optimization Progress:  80%|████████  | 80/100 [00:09<00:02,  8.80it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5628662446362218, 'num_leaves': 102, 'bagging_fraction': 0.9308700521231426, 'min_sum_hessian_in_leaf': 0.9865331070727973}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.5628662446362218, 'num_leaves': 102, 'bagging_fraction': 0.9308700521231426, 'min_sum_hessian_in_leaf': 0.9865331070727973} scored 0.8194444444444444 in 0:00:00.089873\n",
            "Optimization Progress:  81%|████████  | 81/100 [00:09<00:02,  8.78it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5140018302778545, 'num_leaves': 127, 'bagging_fraction': 0.9740461626910843, 'min_sum_hessian_in_leaf': 0.09590094980060127}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5140018302778545, 'num_leaves': 127, 'bagging_fraction': 0.9740461626910843, 'min_sum_hessian_in_leaf': 0.09590094980060127} scored 0.8680555555555556 in 0:00:00.104669\n",
            "Optimization Progress:  82%|████████▏ | 82/100 [00:09<00:02,  8.36it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5400918146326525, 'num_leaves': 83, 'bagging_fraction': 0.9853035332483234, 'min_sum_hessian_in_leaf': 0.12895664403306506}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5400918146326525, 'num_leaves': 83, 'bagging_fraction': 0.9853035332483234, 'min_sum_hessian_in_leaf': 0.12895664403306506} scored 0.8784722222222222 in 0:00:00.091391\n",
            "Optimization Progress:  83%|████████▎ | 83/100 [00:09<00:02,  8.48it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5420241445716252, 'num_leaves': 63, 'bagging_fraction': 0.9891938545376339, 'min_sum_hessian_in_leaf': 0.25186525541049065}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.5420241445716252, 'num_leaves': 63, 'bagging_fraction': 0.9891938545376339, 'min_sum_hessian_in_leaf': 0.25186525541049065} scored 0.8784722222222222 in 0:00:00.086066\n",
            "Optimization Progress:  84%|████████▍ | 84/100 [00:09<00:01,  8.70it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[91]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.5349821912223266, 'num_leaves': 74, 'bagging_fraction': 0.9597274709248406, 'min_sum_hessian_in_leaf': 0.25402714106672203}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.5349821912223266, 'num_leaves': 74, 'bagging_fraction': 0.9597274709248406, 'min_sum_hessian_in_leaf': 0.25402714106672203} scored 0.8402777777777777 in 0:00:00.093812\n",
            "Optimization Progress:  85%|████████▌ | 85/100 [00:09<00:01,  8.71it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5453070559042086, 'num_leaves': 34, 'bagging_fraction': 0.988884410319334, 'min_sum_hessian_in_leaf': 0.35907596837917594}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.5453070559042086, 'num_leaves': 34, 'bagging_fraction': 0.988884410319334, 'min_sum_hessian_in_leaf': 0.35907596837917594} scored 0.8784722222222222 in 0:00:00.106887\n",
            "Optimization Progress:  86%|████████▌ | 86/100 [00:10<00:01,  8.13it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.542442132333216, 'num_leaves': 34, 'bagging_fraction': 0.9891188933084762, 'min_sum_hessian_in_leaf': 0.3478660068639557}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.542442132333216, 'num_leaves': 34, 'bagging_fraction': 0.9891188933084762, 'min_sum_hessian_in_leaf': 0.3478660068639557} scored 0.8784722222222222 in 0:00:00.080445\n",
            "Optimization Progress:  87%|████████▋ | 87/100 [00:10<00:01,  8.53it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.5456854821829795, 'num_leaves': 36, 'bagging_fraction': 0.9664314125678126, 'min_sum_hessian_in_leaf': 0.3585973783497127}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.5456854821829795, 'num_leaves': 36, 'bagging_fraction': 0.9664314125678126, 'min_sum_hessian_in_leaf': 0.3585973783497127} scored 0.8472222222222221 in 0:00:00.106731\n",
            "Optimization Progress:  88%|████████▊ | 88/100 [00:10<00:01,  8.17it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[49]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5717930395409035, 'num_leaves': 23, 'bagging_fraction': 0.9908438928956786, 'min_sum_hessian_in_leaf': 0.609222270265115}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.5717930395409035, 'num_leaves': 23, 'bagging_fraction': 0.9908438928956786, 'min_sum_hessian_in_leaf': 0.609222270265115} scored 0.8715277777777778 in 0:00:00.091142\n",
            "Optimization Progress:  89%|████████▉ | 89/100 [00:10<00:01,  8.16it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.829861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.7700082544907914, 'num_leaves': 63, 'bagging_fraction': 0.9474266656038242, 'min_sum_hessian_in_leaf': 0.8083999595883224}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.7700082544907914, 'num_leaves': 63, 'bagging_fraction': 0.9474266656038242, 'min_sum_hessian_in_leaf': 0.8083999595883224} scored 0.8402777777777777 in 0:00:00.084999\n",
            "Optimization Progress:  90%|█████████ | 90/100 [00:10<00:01,  8.44it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[117]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.8124999999999999 and parameters: {'feature_fraction': 0.5320991537039005, 'num_leaves': 37, 'bagging_fraction': 0.9342208107794336, 'min_sum_hessian_in_leaf': 1.198898829246122}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5320991537039005, 'num_leaves': 37, 'bagging_fraction': 0.9342208107794336, 'min_sum_hessian_in_leaf': 1.198898829246122} scored 0.8124999999999999 in 0:00:00.113878\n",
            "Optimization Progress:  91%|█████████ | 91/100 [00:10<00:01,  7.79it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.875 and parameters: {'feature_fraction': 0.5224098975703473, 'num_leaves': 17, 'bagging_fraction': 0.9783128504432712, 'min_sum_hessian_in_leaf': 0.5019710007681817}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5224098975703473, 'num_leaves': 17, 'bagging_fraction': 0.9783128504432712, 'min_sum_hessian_in_leaf': 0.5019710007681817} scored 0.875 in 0:00:00.096419\n",
            "Optimization Progress:  92%|█████████▏| 92/100 [00:10<00:01,  7.89it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5126009986632776, 'num_leaves': 30, 'bagging_fraction': 0.991266370279817, 'min_sum_hessian_in_leaf': 0.21372480074150202}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5126009986632776, 'num_leaves': 30, 'bagging_fraction': 0.991266370279817, 'min_sum_hessian_in_leaf': 0.21372480074150202} scored 0.8784722222222222 in 0:00:00.079539\n",
            "Optimization Progress:  93%|█████████▎| 93/100 [00:10<00:00,  8.35it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5106006783285167, 'num_leaves': 48, 'bagging_fraction': 0.9920425196319581, 'min_sum_hessian_in_leaf': 0.20651803860434362}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5106006783285167, 'num_leaves': 48, 'bagging_fraction': 0.9920425196319581, 'min_sum_hessian_in_leaf': 0.20651803860434362} scored 0.8784722222222222 in 0:00:00.088487\n",
            "Optimization Progress:  94%|█████████▍| 94/100 [00:11<00:00,  8.51it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5420192536871441, 'num_leaves': 31, 'bagging_fraction': 0.986100713715147, 'min_sum_hessian_in_leaf': 0.18655612368210403}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5420192536871441, 'num_leaves': 31, 'bagging_fraction': 0.986100713715147, 'min_sum_hessian_in_leaf': 0.18655612368210403} scored 0.8784722222222222 in 0:00:00.119683\n",
            "Optimization Progress:  95%|█████████▌| 95/100 [00:11<00:00,  7.96it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5038746542159122, 'num_leaves': 47, 'bagging_fraction': 0.9909038196268936, 'min_sum_hessian_in_leaf': 0.29469233444658083}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.5038746542159122, 'num_leaves': 47, 'bagging_fraction': 0.9909038196268936, 'min_sum_hessian_in_leaf': 0.29469233444658083} scored 0.8784722222222222 in 0:00:00.092147\n",
            "Optimization Progress:  96%|█████████▌| 96/100 [00:11<00:00,  8.12it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.8611111111111112 and parameters: {'feature_fraction': 0.5092851676877003, 'num_leaves': 43, 'bagging_fraction': 0.9593694934099157, 'min_sum_hessian_in_leaf': 0.4039454900330683}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.5092851676877003, 'num_leaves': 43, 'bagging_fraction': 0.9593694934099157, 'min_sum_hessian_in_leaf': 0.4039454900330683} scored 0.8611111111111112 in 0:00:00.103308\n",
            "Optimization Progress:  97%|█████████▋| 97/100 [00:11<00:00,  8.03it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.819444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.5282116926663797, 'num_leaves': 31, 'bagging_fraction': 0.9682710276660659, 'min_sum_hessian_in_leaf': 0.12510994860342406}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.5282116926663797, 'num_leaves': 31, 'bagging_fraction': 0.9682710276660659, 'min_sum_hessian_in_leaf': 0.12510994860342406} scored 0.8472222222222221 in 0:00:00.103579\n",
            "Optimization Progress:  98%|█████████▊| 98/100 [00:11<00:00,  7.87it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5516189818173235, 'num_leaves': 57, 'bagging_fraction': 0.9985176163592306, 'min_sum_hessian_in_leaf': 0.23215060117206943}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5516189818173235, 'num_leaves': 57, 'bagging_fraction': 0.9985176163592306, 'min_sum_hessian_in_leaf': 0.23215060117206943} scored 0.8715277777777778 in 0:00:00.106881\n",
            "Optimization Progress:  99%|█████████▉| 99/100 [00:11<00:00,  7.55it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.763889\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.7638888888888888 and parameters: {'feature_fraction': 0.5783502070090707, 'num_leaves': 41, 'bagging_fraction': 0.6252760024086583, 'min_sum_hessian_in_leaf': 0.3600704200690418}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.5783502070090707, 'num_leaves': 41, 'bagging_fraction': 0.6252760024086583, 'min_sum_hessian_in_leaf': 0.3600704200690418} scored 0.7638888888888888 in 0:00:00.079668\n",
            "Optimization Progress: 100%|██████████| 100/100 [00:11<00:00,  8.44it/s, best_trial=10, best_value=0.878]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:59] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655}\u001b[0m\n",
            " achieve 0.8785 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:59] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 129, 'feature_fraction': 0.5102734049121492, 'bagging_fraction': 0.9847685553939329, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.689539874561655}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[37]\tvalid's auc: 0.850694\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.881119\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.895105\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685315\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[42]\tvalid's auc: 0.706294\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685315\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[11]\tvalid's auc: 0.783217\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.769231\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[41]\tvalid's auc: 0.811189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:59] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7660435267857142\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7660435267857142\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:59] \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:46:59] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ... Time budget is 138.49 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ... Time budget is 138.49 secs\n",
            "Optimization Progress:   0%|          | 0/100 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-2976143d-c2a1-435e-9228-6f878bdb014f\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.49ms\tremaining: 745ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8819444 (12)\ttotal: 70.2ms\tremaining: 277ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8819444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.8819444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.8819444444444444.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.8819444444444444 in 0:00:00.147354\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:16,  6.12it/s, best_trial=0, best_value=0.882]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 4.13ms\tremaining: 2.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8958333 (1)\ttotal: 90.3ms\tremaining: 357ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4} scored 0.8958333333333334 in 0:00:00.139019\n",
            "Optimization Progress:   2%|▏         | 2/100 [00:00<00:15,  6.22it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 662us\tremaining: 331ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8506944 (0)\ttotal: 61ms\tremaining: 241ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.105452\n",
            "Optimization Progress:   3%|▎         | 3/100 [00:00<00:14,  6.91it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 1.78ms\tremaining: 891ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8576389 (1)\ttotal: 118ms\tremaining: 466ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8576388889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.8576388888888888 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20} scored 0.8576388888888888 in 0:00:00.172737\n",
            "Optimization Progress:   4%|▍         | 4/100 [00:00<00:15,  6.19it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 2.11ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8819444 (4)\ttotal: 158ms\tremaining: 626ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8819444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.8819444444444445 and parameters: {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.8819444444444445 in 0:00:00.214435\n",
            "Optimization Progress:   5%|▌         | 5/100 [00:00<00:17,  5.39it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 706us\tremaining: 352ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8923611 (4)\ttotal: 55.4ms\tremaining: 219ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11} scored 0.8923611111111112 in 0:00:00.108999\n",
            "Optimization Progress:   6%|▌         | 6/100 [00:00<00:15,  6.00it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.6ms\tremaining: 799ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6875000\tbest: 0.8958333 (1)\ttotal: 232ms\tremaining: 916ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13} scored 0.8958333333333334 in 0:00:00.303165\n",
            "Optimization Progress:   7%|▋         | 7/100 [00:01<00:20,  4.62it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 827us\tremaining: 413ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8923611 (4)\ttotal: 93.8ms\tremaining: 371ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8} scored 0.8923611111111112 in 0:00:00.183388\n",
            "Optimization Progress:   8%|▊         | 8/100 [00:01<00:19,  4.66it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.28ms\tremaining: 641ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8958333 (1)\ttotal: 163ms\tremaining: 645ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4} scored 0.8958333333333334 in 0:00:00.239702\n",
            "Optimization Progress:   9%|▉         | 9/100 [00:01<00:21,  4.31it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 2.11ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8958333 (1)\ttotal: 162ms\tremaining: 638ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.8958333333333334 in 0:00:00.224449\n",
            "Optimization Progress:  10%|█         | 10/100 [00:02<00:21,  4.27it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 5.35ms\tremaining: 2.67s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8680556 (4)\ttotal: 358ms\tremaining: 1.41s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8680555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.8680555555555556 and parameters: {'max_depth': 7, 'l2_leaf_reg': 1.1323342574942026e-08, 'min_data_in_leaf': 7}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 1.1323342574942026e-08, 'min_data_in_leaf': 7} scored 0.8680555555555556 in 0:00:00.438212\n",
            "Optimization Progress:  11%|█         | 11/100 [00:02<00:26,  3.33it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 3.85ms\tremaining: 1.92s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8645833 (6)\ttotal: 328ms\tremaining: 1.29s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.8645833333333333 and parameters: {'max_depth': 6, 'l2_leaf_reg': 0.00021189647537044038, 'min_data_in_leaf': 17}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 0.00021189647537044038, 'min_data_in_leaf': 17} scored 0.8645833333333333 in 0:00:00.415659\n",
            "Optimization Progress:  12%|█▏        | 12/100 [00:02<00:29,  2.95it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 3.18ms\tremaining: 1.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8854167 (5)\ttotal: 194ms\tremaining: 767ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.504608987495313e-07, 'min_data_in_leaf': 10}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.504608987495313e-07, 'min_data_in_leaf': 10} scored 0.8854166666666666 in 0:00:00.272350\n",
            "Optimization Progress:  13%|█▎        | 13/100 [00:03<00:28,  3.08it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 3.83ms\tremaining: 1.91s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8645833 (5)\ttotal: 165ms\tremaining: 651ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.8645833333333333 and parameters: {'max_depth': 5, 'l2_leaf_reg': 8.77791614314671e-05, 'min_data_in_leaf': 1}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 8.77791614314671e-05, 'min_data_in_leaf': 1} scored 0.8645833333333333 in 0:00:00.274569\n",
            "Optimization Progress:  14%|█▍        | 14/100 [00:03<00:27,  3.18it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 1.8ms\tremaining: 899ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.7916667 (42)\ttotal: 242ms\tremaining: 958ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7916666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.7916666666666667 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.0860170570447388e-05, 'min_data_in_leaf': 6}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.0860170570447388e-05, 'min_data_in_leaf': 6} scored 0.7916666666666667 in 0:00:00.468976\n",
            "Optimization Progress:  15%|█▌        | 15/100 [00:03<00:31,  2.73it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.51ms\tremaining: 752ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.9027778 (10)\ttotal: 106ms\tremaining: 419ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9027777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 10\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 11 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.9027777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232823, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232823, 'min_data_in_leaf': 12} scored 0.9027777777777778 in 0:00:00.200768\n",
            "Optimization Progress:  16%|█▌        | 16/100 [00:04<00:27,  3.07it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.6ms\tremaining: 801ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8854167 (5)\ttotal: 166ms\tremaining: 654ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0053223209907244575, 'min_data_in_leaf': 10}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0053223209907244575, 'min_data_in_leaf': 10} scored 0.8854166666666666 in 0:00:00.284828\n",
            "Optimization Progress:  17%|█▋        | 17/100 [00:04<00:26,  3.14it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 890us\tremaining: 444ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8263889\tbest: 0.8854167 (5)\ttotal: 66.6ms\tremaining: 263ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.007809132161023211, 'min_data_in_leaf': 4}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.007809132161023211, 'min_data_in_leaf': 4} scored 0.8854166666666666 in 0:00:00.128262\n",
            "Optimization Progress:  18%|█▊        | 18/100 [00:04<00:21,  3.74it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 796us\tremaining: 397ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8888889 (18)\ttotal: 67.7ms\tremaining: 267ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 18\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 19 iterations.\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.888888888888889 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.06012007950445106, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.06012007950445106, 'min_data_in_leaf': 18} scored 0.888888888888889 in 0:00:00.139288\n",
            "Optimization Progress:  19%|█▉        | 19/100 [00:04<00:18,  4.28it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 1.4ms\tremaining: 699ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8645833 (6)\ttotal: 106ms\tremaining: 420ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.8645833333333333 and parameters: {'max_depth': 6, 'l2_leaf_reg': 0.0010749883760899615, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 0.0010749883760899615, 'min_data_in_leaf': 13} scored 0.8645833333333333 in 0:00:00.174721\n",
            "Optimization Progress:  20%|██        | 20/100 [00:05<00:17,  4.54it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 907us\tremaining: 453ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8854167 (5)\ttotal: 67.7ms\tremaining: 268ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.4400903220306502e-07, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.4400903220306502e-07, 'min_data_in_leaf': 8} scored 0.8854166666666666 in 0:00:00.135734\n",
            "Optimization Progress:  21%|██        | 21/100 [00:05<00:15,  4.99it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.12ms\tremaining: 560ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8958333 (1)\ttotal: 81.1ms\tremaining: 321ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.060726382877094e-05, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.060726382877094e-05, 'min_data_in_leaf': 13} scored 0.8958333333333334 in 0:00:00.135268\n",
            "Optimization Progress:  22%|██▏       | 22/100 [00:05<00:14,  5.37it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 987us\tremaining: 493ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8958333 (1)\ttotal: 107ms\tremaining: 422ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.4908285328345343e-06, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.4908285328345343e-06, 'min_data_in_leaf': 15} scored 0.8958333333333334 in 0:00:00.172474\n",
            "Optimization Progress:  23%|██▎       | 23/100 [00:05<00:14,  5.35it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 971us\tremaining: 485ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8958333 (1)\ttotal: 83ms\tremaining: 328ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 9.390138332052496e-08, 'min_data_in_leaf': 11}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 9.390138332052496e-08, 'min_data_in_leaf': 11} scored 0.8958333333333334 in 0:00:00.151081\n",
            "Optimization Progress:  24%|██▍       | 24/100 [00:05<00:13,  5.47it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 1.42ms\tremaining: 710ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8055556 (98)\ttotal: 104ms\tremaining: 409ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8055556\tbest: 0.8125000 (101)\ttotal: 216ms\tremaining: 321ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 101\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 102 iterations.\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.8125 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.209353836699894e-05, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.209353836699894e-05, 'min_data_in_leaf': 15} scored 0.8125 in 0:00:00.286070\n",
            "Optimization Progress:  25%|██▌       | 25/100 [00:05<00:16,  4.58it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.12ms\tremaining: 559ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8854167 (4)\ttotal: 66ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0003252761374770595, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0003252761374770595, 'min_data_in_leaf': 12} scored 0.8854166666666666 in 0:00:00.124703\n",
            "Optimization Progress:  26%|██▌       | 26/100 [00:06<00:14,  5.14it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.4ms\tremaining: 700ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8958333 (1)\ttotal: 88.1ms\tremaining: 348ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.022355382861496083, 'min_data_in_leaf': 9}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.022355382861496083, 'min_data_in_leaf': 9} scored 0.8958333333333334 in 0:00:00.146022\n",
            "Optimization Progress:  27%|██▋       | 27/100 [00:06<00:13,  5.39it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 968us\tremaining: 483ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8958333 (1)\ttotal: 83.3ms\tremaining: 329ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.5765199750320534e-06, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.5765199750320534e-06, 'min_data_in_leaf': 6} scored 0.8958333333333334 in 0:00:00.144402\n",
            "Optimization Progress:  28%|██▊       | 28/100 [00:06<00:13,  5.53it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.06ms\tremaining: 531ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8993056 (1)\ttotal: 57.5ms\tremaining: 227ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.442518943575423e-08, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.442518943575423e-08, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.134791\n",
            "Optimization Progress:  29%|██▉       | 29/100 [00:06<00:12,  5.78it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 674us\tremaining: 337ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 61.6ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.4134699879705236e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.4134699879705236e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.120589\n",
            "Optimization Progress:  30%|███       | 30/100 [00:06<00:11,  6.14it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 707us\tremaining: 353ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8541667 (10)\ttotal: 57.1ms\tremaining: 226ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8541666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 10\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 11 iterations.\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.8541666666666666 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.188488835785422, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.188488835785422, 'min_data_in_leaf': 17} scored 0.8541666666666666 in 0:00:00.124349\n",
            "Optimization Progress:  31%|███       | 31/100 [00:06<00:10,  6.33it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 688us\tremaining: 343ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.8993056 (1)\ttotal: 56.9ms\tremaining: 225ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.650542623766143e-08, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.650542623766143e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.116254\n",
            "Optimization Progress:  32%|███▏      | 32/100 [00:07<00:10,  6.58it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 809us\tremaining: 404ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 57.6ms\tremaining: 228ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.1823409220603664e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.1823409220603664e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.114421\n",
            "Optimization Progress:  33%|███▎      | 33/100 [00:07<00:09,  6.82it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 697us\tremaining: 348ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7152778\tbest: 0.8993056 (1)\ttotal: 55.5ms\tremaining: 219ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.159000694120228e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.159000694120228e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.117293\n",
            "Optimization Progress:  34%|███▍      | 34/100 [00:07<00:09,  6.96it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 688us\tremaining: 343ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7083333\tbest: 0.8993056 (1)\ttotal: 56.8ms\tremaining: 224ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.720192828080591e-08, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.720192828080591e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.113134\n",
            "Optimization Progress:  35%|███▌      | 35/100 [00:07<00:09,  7.13it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 682us\tremaining: 341ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 80.1ms\tremaining: 316ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.28170520176123e-07, 'min_data_in_leaf': 20}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.28170520176123e-07, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.138256\n",
            "Optimization Progress:  36%|███▌      | 36/100 [00:07<00:09,  6.82it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 675us\tremaining: 337ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8993056 (1)\ttotal: 59.7ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.095856531971167e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.095856531971167e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.122847\n",
            "Optimization Progress:  37%|███▋      | 37/100 [00:07<00:09,  6.82it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 661us\tremaining: 330ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7152778\tbest: 0.8993056 (1)\ttotal: 54.6ms\tremaining: 216ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.1508585197425347e-08, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.1508585197425347e-08, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.116008\n",
            "Optimization Progress:  38%|███▊      | 38/100 [00:07<00:08,  6.95it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 945us\tremaining: 472ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8958333 (4)\ttotal: 75.3ms\tremaining: 297ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.8958333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.45483427335788185, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.45483427335788185, 'min_data_in_leaf': 14} scored 0.8958333333333334 in 0:00:00.143992\n",
            "Optimization Progress:  39%|███▉      | 39/100 [00:08<00:09,  6.62it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 700us\tremaining: 349ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 55.6ms\tremaining: 220ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.2208662558040907e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.2208662558040907e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.112574\n",
            "Optimization Progress:  40%|████      | 40/100 [00:08<00:08,  6.83it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 860us\tremaining: 429ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8854167 (5)\ttotal: 68.2ms\tremaining: 270ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.7820441408904687e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.7820441408904687e-08, 'min_data_in_leaf': 19} scored 0.8854166666666666 in 0:00:00.132514\n",
            "Optimization Progress:  41%|████      | 41/100 [00:08<00:08,  6.71it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 680us\tremaining: 339ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8993056 (1)\ttotal: 61.4ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.9623862411537926e-08, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.9623862411537926e-08, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.122735\n",
            "Optimization Progress:  42%|████▏     | 42/100 [00:08<00:08,  6.78it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 684us\tremaining: 342ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 76.2ms\tremaining: 301ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.1406372409997107e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.1406372409997107e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.145920\n",
            "Optimization Progress:  43%|████▎     | 43/100 [00:08<00:08,  6.48it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 779us\tremaining: 389ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8993056 (1)\ttotal: 60.8ms\tremaining: 240ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.6249437881459255e-08, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.6249437881459255e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.128157\n",
            "Optimization Progress:  44%|████▍     | 44/100 [00:08<00:08,  6.49it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 658us\tremaining: 329ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 61.6ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0055062426520163e-08, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0055062426520163e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.120204\n",
            "Optimization Progress:  45%|████▌     | 45/100 [00:08<00:08,  6.64it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 772us\tremaining: 386ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 58.4ms\tremaining: 231ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.9976972846690276e-07, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.9976972846690276e-07, 'min_data_in_leaf': 12} scored 0.8993055555555556 in 0:00:00.120781\n",
            "Optimization Progress:  46%|████▌     | 46/100 [00:09<00:07,  6.75it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 840us\tremaining: 419ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8854167 (5)\ttotal: 71ms\tremaining: 280ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.86297740047586e-06, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.86297740047586e-06, 'min_data_in_leaf': 17} scored 0.8854166666666666 in 0:00:00.136337\n",
            "Optimization Progress:  47%|████▋     | 47/100 [00:09<00:08,  6.62it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 708us\tremaining: 354ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8506944 (0)\ttotal: 59.1ms\tremaining: 233ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0018943984158954804, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0018943984158954804, 'min_data_in_leaf': 18} scored 0.8506944444444444 in 0:00:00.125760\n",
            "Optimization Progress:  48%|████▊     | 48/100 [00:09<00:07,  6.64it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 836us\tremaining: 417ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8854167 (4)\ttotal: 75ms\tremaining: 296ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0004935798242156365, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0004935798242156365, 'min_data_in_leaf': 12} scored 0.8854166666666666 in 0:00:00.143781\n",
            "Optimization Progress:  49%|████▉     | 49/100 [00:09<00:07,  6.43it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.72ms\tremaining: 1.36s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7083333\tbest: 0.8993056 (1)\ttotal: 72.4ms\tremaining: 286ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.661020987044852e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.661020987044852e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.148121\n",
            "Optimization Progress:  50%|█████     | 50/100 [00:09<00:08,  6.20it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 871us\tremaining: 435ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8993056 (1)\ttotal: 61.6ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.232758972489976e-07, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.232758972489976e-07, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.125440\n",
            "Optimization Progress:  51%|█████     | 51/100 [00:09<00:07,  6.32it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 960us\tremaining: 480ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7291667\tbest: 0.8993056 (1)\ttotal: 59.9ms\tremaining: 237ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.4462826848165575e-08, 'min_data_in_leaf': 20}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.4462826848165575e-08, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.123977\n",
            "Optimization Progress:  52%|█████▏    | 52/100 [00:10<00:07,  6.45it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 669us\tremaining: 334ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 65.3ms\tremaining: 258ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.3769681675165e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.3769681675165e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.132982\n",
            "Optimization Progress:  53%|█████▎    | 53/100 [00:10<00:07,  6.41it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 657us\tremaining: 328ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8993056 (1)\ttotal: 59ms\tremaining: 233ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.2558664260896004e-08, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.2558664260896004e-08, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.119576\n",
            "Optimization Progress:  54%|█████▍    | 54/100 [00:10<00:07,  6.57it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.03ms\tremaining: 516ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (5)\ttotal: 73ms\tremaining: 288ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.235512222698528e-07, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.235512222698528e-07, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.148903\n",
            "Optimization Progress:  55%|█████▌    | 55/100 [00:10<00:07,  6.38it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.32ms\tremaining: 660ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8854167 (5)\ttotal: 77.2ms\tremaining: 305ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.389245257455328e-06, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.389245257455328e-06, 'min_data_in_leaf': 15} scored 0.8854166666666666 in 0:00:00.163151\n",
            "Optimization Progress:  56%|█████▌    | 56/100 [00:10<00:07,  5.87it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 664us\tremaining: 332ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8993056 (1)\ttotal: 55.5ms\tremaining: 219ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3124247660133686e-07, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3124247660133686e-07, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.114504\n",
            "Optimization Progress:  57%|█████▋    | 57/100 [00:10<00:06,  6.22it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 734us\tremaining: 367ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.9236111 (17)\ttotal: 57.7ms\tremaining: 228ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9236111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 17\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 18 iterations.\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.9236111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00011427914857502921, 'min_data_in_leaf': 19}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00011427914857502921, 'min_data_in_leaf': 19} scored 0.9236111111111112 in 0:00:00.132771\n",
            "Optimization Progress:  58%|█████▊    | 58/100 [00:11<00:06,  6.24it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 2.11ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8888889 (4)\ttotal: 160ms\tremaining: 633ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.888888888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 7.76351174092854e-05, 'min_data_in_leaf': 16}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 7.76351174092854e-05, 'min_data_in_leaf': 16} scored 0.888888888888889 in 0:00:00.232603\n",
            "Optimization Progress:  59%|█████▉    | 59/100 [00:11<00:07,  5.28it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.22ms\tremaining: 611ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8854167 (5)\ttotal: 71ms\tremaining: 280ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.00969553246325887, 'min_data_in_leaf': 11}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.00969553246325887, 'min_data_in_leaf': 11} scored 0.8854166666666666 in 0:00:00.139553\n",
            "Optimization Progress:  60%|██████    | 60/100 [00:11<00:07,  5.56it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 848us\tremaining: 423ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8819444\tbest: 0.9305556 (18)\ttotal: 66.2ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9305555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 18\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 19 iterations.\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.9305555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13} scored 0.9305555555555556 in 0:00:00.153233\n",
            "Optimization Progress:  61%|██████    | 61/100 [00:11<00:07,  5.55it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 727us\tremaining: 363ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8506944 (0)\ttotal: 68.6ms\tremaining: 271ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00014297368512434865, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00014297368512434865, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.130368\n",
            "Optimization Progress:  62%|██████▏   | 62/100 [00:11<00:06,  5.65it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 719us\tremaining: 359ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.9166667 (39)\ttotal: 60.1ms\tremaining: 237ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9166666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.9166666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0985096705459318e-05, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0985096705459318e-05, 'min_data_in_leaf': 14} scored 0.9166666666666667 in 0:00:00.156542\n",
            "Optimization Progress:  63%|██████▎   | 63/100 [00:11<00:06,  5.61it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 699us\tremaining: 349ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8923611 (4)\ttotal: 62.5ms\tremaining: 247ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0967284650253425e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0967284650253425e-05, 'min_data_in_leaf': 13} scored 0.8923611111111112 in 0:00:00.123475\n",
            "Optimization Progress:  64%|██████▍   | 64/100 [00:12<00:06,  5.89it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 663us\tremaining: 331ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8680556 (59)\ttotal: 57.7ms\tremaining: 228ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8680555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 59\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 60 iterations.\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.8680555555555555 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.8032558846650763e-05, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.8032558846650763e-05, 'min_data_in_leaf': 12} scored 0.8680555555555555 in 0:00:00.157647\n",
            "Optimization Progress:  65%|██████▌   | 65/100 [00:12<00:06,  5.75it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 709us\tremaining: 354ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8958333 (11)\ttotal: 54.9ms\tremaining: 217ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 11\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 12 iterations.\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.8958333333333333 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.797618576000362e-06, 'min_data_in_leaf': 10}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.797618576000362e-06, 'min_data_in_leaf': 10} scored 0.8958333333333333 in 0:00:00.127203\n",
            "Optimization Progress:  66%|██████▌   | 66/100 [00:12<00:05,  5.90it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 950us\tremaining: 474ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (4)\ttotal: 70.7ms\tremaining: 279ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0006267299025268735, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0006267299025268735, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.138494\n",
            "Optimization Progress:  67%|██████▋   | 67/100 [00:12<00:05,  5.94it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 886us\tremaining: 443ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.8888889 (46)\ttotal: 59.4ms\tremaining: 235ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 46\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 47 iterations.\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.8888888888888888 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3264621125681148e-05, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3264621125681148e-05, 'min_data_in_leaf': 15} scored 0.8888888888888888 in 0:00:00.157455\n",
            "Optimization Progress:  68%|██████▊   | 68/100 [00:12<00:05,  5.79it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 701us\tremaining: 350ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8541667 (39)\ttotal: 59.4ms\tremaining: 235ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8541666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.8541666666666666 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.002354278893510329, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.002354278893510329, 'min_data_in_leaf': 14} scored 0.8541666666666666 in 0:00:00.160448\n",
            "Optimization Progress:  69%|██████▉   | 69/100 [00:12<00:05,  5.66it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 943us\tremaining: 471ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8854167 (4)\ttotal: 75.5ms\tremaining: 298ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.8854166666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.00017522862089164933, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.00017522862089164933, 'min_data_in_leaf': 12} scored 0.8854166666666667 in 0:00:00.144895\n",
            "Optimization Progress:  70%|███████   | 70/100 [00:13<00:05,  5.67it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 689us\tremaining: 344ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8506944 (0)\ttotal: 59.7ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.954655866173518e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.954655866173518e-05, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.125746\n",
            "Optimization Progress:  71%|███████   | 71/100 [00:13<00:04,  5.91it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 671us\tremaining: 335ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8923611 (4)\ttotal: 60.5ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.708528754471435e-06, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.708528754471435e-06, 'min_data_in_leaf': 15} scored 0.8923611111111112 in 0:00:00.131188\n",
            "Optimization Progress:  72%|███████▏  | 72/100 [00:13<00:04,  5.99it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 679us\tremaining: 339ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8993056 (1)\ttotal: 56.9ms\tremaining: 225ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0017403982001171e-06, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0017403982001171e-06, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.120231\n",
            "Optimization Progress:  73%|███████▎  | 73/100 [00:13<00:04,  6.23it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 730us\tremaining: 364ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8506944 (0)\ttotal: 63.7ms\tremaining: 252ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.03451772479612021, 'min_data_in_leaf': 2}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.03451772479612021, 'min_data_in_leaf': 2} scored 0.8506944444444444 in 0:00:00.133903\n",
            "Optimization Progress:  74%|███████▍  | 74/100 [00:13<00:04,  6.18it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 653us\tremaining: 326ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8506944 (0)\ttotal: 80.3ms\tremaining: 317ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.7467971562387907e-05, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.7467971562387907e-05, 'min_data_in_leaf': 16} scored 0.8506944444444444 in 0:00:00.151158\n",
            "Optimization Progress:  75%|███████▌  | 75/100 [00:13<00:04,  5.95it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 695us\tremaining: 347ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 61.5ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.641624404951669e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.641624404951669e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.134982\n",
            "Optimization Progress:  76%|███████▌  | 76/100 [00:14<00:03,  6.04it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 734us\tremaining: 366ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8506944 (0)\ttotal: 62.4ms\tremaining: 246ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0011880893230096533, 'min_data_in_leaf': 9}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0011880893230096533, 'min_data_in_leaf': 9} scored 0.8506944444444444 in 0:00:00.135114\n",
            "Optimization Progress:  77%|███████▋  | 77/100 [00:14<00:03,  6.01it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 703us\tremaining: 351ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8506944 (0)\ttotal: 61.4ms\tremaining: 242ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0002602491028654061, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0002602491028654061, 'min_data_in_leaf': 18} scored 0.8506944444444444 in 0:00:00.133312\n",
            "Optimization Progress:  78%|███████▊  | 78/100 [00:14<00:03,  5.97it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 2.46ms\tremaining: 1.23s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (5)\ttotal: 129ms\tremaining: 511ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.3931921030086025e-08, 'min_data_in_leaf': 11}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.3931921030086025e-08, 'min_data_in_leaf': 11} scored 0.8854166666666666 in 0:00:00.243893\n",
            "Optimization Progress:  79%|███████▉  | 79/100 [00:14<00:04,  4.90it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 835us\tremaining: 417ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8506944 (0)\ttotal: 81.6ms\tremaining: 322ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.010571814412111384, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.010571814412111384, 'min_data_in_leaf': 17} scored 0.8506944444444444 in 0:00:00.147245\n",
            "Optimization Progress:  80%|████████  | 80/100 [00:14<00:04,  4.95it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 728us\tremaining: 363ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8958333 (12)\ttotal: 109ms\tremaining: 431ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.8958333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.12265494738583436, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.12265494738583436, 'min_data_in_leaf': 16} scored 0.8958333333333334 in 0:00:00.224281\n",
            "Optimization Progress:  81%|████████  | 81/100 [00:15<00:04,  4.53it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 922us\tremaining: 460ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 125ms\tremaining: 494ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.006507216470076e-08, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.006507216470076e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.224337\n",
            "Optimization Progress:  82%|████████▏ | 82/100 [00:15<00:04,  4.26it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.06ms\tremaining: 531ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 165ms\tremaining: 652ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.5997884243913893e-07, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.5997884243913893e-07, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.253931\n",
            "Optimization Progress:  83%|████████▎ | 83/100 [00:15<00:04,  3.98it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.54ms\tremaining: 1.27s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8993056 (1)\ttotal: 157ms\tremaining: 622ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.319522631972632e-08, 'min_data_in_leaf': 20}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.319522631972632e-08, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.231378\n",
            "Optimization Progress:  84%|████████▍ | 84/100 [00:16<00:04,  3.92it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.69ms\tremaining: 1.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8611111 (31)\ttotal: 167ms\tremaining: 660ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8611111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 31\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 32 iterations.\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.861111111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.004371275312998932, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.004371275312998932, 'min_data_in_leaf': 18} scored 0.861111111111111 in 0:00:00.308834\n",
            "Optimization Progress:  85%|████████▌ | 85/100 [00:16<00:04,  3.57it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 871us\tremaining: 435ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8993056 (1)\ttotal: 161ms\tremaining: 636ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.5903399973819104e-08, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.5903399973819104e-08, 'min_data_in_leaf': 13} scored 0.8993055555555556 in 0:00:00.234484\n",
            "Optimization Progress:  86%|████████▌ | 86/100 [00:16<00:03,  3.61it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 864us\tremaining: 431ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8993056 (1)\ttotal: 163ms\tremaining: 645ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.946396663764725e-07, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.946396663764725e-07, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.253217\n",
            "Optimization Progress:  87%|████████▋ | 87/100 [00:16<00:03,  3.57it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 924us\tremaining: 461ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 167ms\tremaining: 658ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.070207940399716e-07, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.070207940399716e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.258123\n",
            "Optimization Progress:  88%|████████▊ | 88/100 [00:17<00:03,  3.48it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 3.93ms\tremaining: 1.96s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8854167 (5)\ttotal: 165ms\tremaining: 652ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.021772738882567e-08, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.021772738882567e-08, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.272742\n",
            "Optimization Progress:  89%|████████▉ | 89/100 [00:17<00:03,  3.39it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.58ms\tremaining: 1.29s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8923611 (4)\ttotal: 126ms\tremaining: 497ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.6716061986961368e-06, 'min_data_in_leaf': 20}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.6716061986961368e-06, 'min_data_in_leaf': 20} scored 0.8923611111111112 in 0:00:00.212801\n",
            "Optimization Progress:  90%|█████████ | 90/100 [00:17<00:02,  3.51it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.06ms\tremaining: 528ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8993056 (1)\ttotal: 94.9ms\tremaining: 375ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8085746015379232e-08, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8085746015379232e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.207773\n",
            "Optimization Progress:  91%|█████████ | 91/100 [00:18<00:02,  3.61it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.11ms\tremaining: 556ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.9097222 (57)\ttotal: 83.6ms\tremaining: 330ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9097222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.9097222222222221 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.437840574423421e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.437840574423421e-08, 'min_data_in_leaf': 15} scored 0.9097222222222221 in 0:00:00.227506\n",
            "Optimization Progress:  92%|█████████▏| 92/100 [00:18<00:02,  3.61it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 749us\tremaining: 374ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 96.3ms\tremaining: 380ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0046393741347246e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0046393741347246e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.174356\n",
            "Optimization Progress:  93%|█████████▎| 93/100 [00:18<00:01,  3.86it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 778us\tremaining: 388ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 102ms\tremaining: 402ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.57946305853902e-08, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.57946305853902e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.176915\n",
            "Optimization Progress:  94%|█████████▍| 94/100 [00:18<00:01,  4.06it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 669us\tremaining: 334ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 79.8ms\tremaining: 315ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0355501846551036e-07, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0355501846551036e-07, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.174173\n",
            "Optimization Progress:  95%|█████████▌| 95/100 [00:18<00:01,  4.18it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 4.05ms\tremaining: 2.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 107ms\tremaining: 424ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.33560027136623e-08, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.33560027136623e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.196857\n",
            "Optimization Progress:  96%|█████████▌| 96/100 [00:19<00:00,  4.24it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 879us\tremaining: 439ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 64.4ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.11172783540778e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.11172783540778e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.134516\n",
            "Optimization Progress:  97%|█████████▋| 97/100 [00:19<00:00,  4.57it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 905us\tremaining: 452ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8506944 (0)\ttotal: 70.2ms\tremaining: 277ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00011966526621705177, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00011966526621705177, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.137769\n",
            "Optimization Progress:  98%|█████████▊| 98/100 [00:19<00:00,  4.90it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 2.1ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8333333 (25)\ttotal: 77.3ms\tremaining: 305ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8333333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.8333333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.597868329377265e-05, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.597868329377265e-05, 'min_data_in_leaf': 17} scored 0.8333333333333333 in 0:00:00.172459\n",
            "Optimization Progress:  99%|█████████▉| 99/100 [00:19<00:00,  4.90it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 758us\tremaining: 378ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8993056 (1)\ttotal: 61.5ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8768050814480855e-07, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8768050814480855e-07, 'min_data_in_leaf': 12} scored 0.8993055555555556 in 0:00:00.126595\n",
            "Optimization Progress: 100%|██████████| 100/100 [00:19<00:00,  5.02it/s, best_trial=60, best_value=0.931]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:19] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13}\u001b[0m\n",
            " achieve 0.9306 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:19] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 1.4142208298719828e-05, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 13, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 687us\tremaining: 2.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8923611 (4)\ttotal: 70.5ms\tremaining: 2.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6783217\tbest: 0.6783217 (0)\ttotal: 3.28ms\tremaining: 9.84s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8321678\tbest: 0.9230769 (4)\ttotal: 90.2ms\tremaining: 2.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9230769231\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4300699\tbest: 0.4300699 (0)\ttotal: 766us\tremaining: 2.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5174825\tbest: 0.6993007 (7)\ttotal: 56ms\tremaining: 1.61s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6993006993\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 7\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 8 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5384615\tbest: 0.5384615 (0)\ttotal: 883us\tremaining: 2.65s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5874126\tbest: 0.7552448 (3)\ttotal: 57.3ms\tremaining: 1.65s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7552447552\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 3\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 4 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5909091\tbest: 0.5909091 (0)\ttotal: 729us\tremaining: 2.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6853147\tbest: 0.7482517 (77)\ttotal: 85.8ms\tremaining: 2.46s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7482517483\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7657645089285713\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7657645089285713\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'n_estimators': 3000, 'early_stopping_rounds': 100, 'seed': 42, 'verbose_eval': 100, 'nthread': 2}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.76042\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.77778\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[104]\tvalid-auc:0.77778\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.75524\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.82517\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[112]\tvalid-auc:0.82517\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.81469\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[99]\tvalid-auc:0.67832\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.70629\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.58741\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.66434\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.72028\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[105]\tvalid-auc:0.72028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.7287946428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.7287946428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Time left 566.46 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 566.46 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Layer \u001b[1m2\u001b[0m train process start. Time left 566.45 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m2\u001b[0m train process start. Time left 566.45 secs\n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 0 \n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 22 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:20] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': False, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 50, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 10, 'swa': True}, 'bs': 256, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': 'UniversalDataset', 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 256], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': 'LeakyReLU', 'use_noise': False, 'use_bn': True, 'share_training_batches': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'device_ids': None, 'num_dims': 22, 'text_features': [], 'bias': array([-0.13353139])}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.4866071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.4866071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] Time left 563.85 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 563.85 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] \u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] \u001b[1mAutoml preset training completed in 36.15 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 36.15 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:23] Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_2_XGBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 1.00000 * (5 averaged models Lvl_1_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_2_XGBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 1.00000 * (5 averaged models Lvl_1_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA Advanced] ROC-AUC: 0.5000  F1: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### конфигурация 4 - с feature selection и ограниченным набором моделей\n",
        "Только LGBM (c hyperparameter tuning) и линейная регрессия; включён feature selection (оставляем 80% лучших признаков); гиперпараметры подбираются на holdout-валидации.\n"
      ],
      "metadata": {
        "id": "SceXiK-JppB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl4 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['lgb_tuned', 'linear_l2']]  # Только LGBM + Linear\n",
        "    },\n",
        "    selection_params={\n",
        "        'select_algos': ['gbm', 'linear_l2'],\n",
        "        'selection_feats_rate': 0.8,\n",
        "        'max_features_cnt_in_result': None,\n",
        "    },\n",
        "    tuning_params={\n",
        "        'fit_on_holdout': True,\n",
        "        'max_tuning_iter': 50,\n",
        "        'max_tuning_time': 200,\n",
        "    }\n",
        ")\n",
        "\n",
        "oof_pred4 = automl4.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred4 = automl4.predict(test_LAMA)\n",
        "\n",
        "auc4 = roc_auc_score(y_test, test_pred4.data[:, 0])\n",
        "f1_4 = f1_score(y_test, test_pred4.data[:, 0] > 0.5)\n",
        "print(f'[LAMA FS+LGBM/Linear] ROC-AUC: {auc4:.4f}  F1: {f1_4:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdbO621ipxWL",
        "outputId": "faba0903-0de9-4382-def6-d3929c07d529"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] Layer \u001b[1m1\u001b[0m train process start. Time left 599.85 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 599.85 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:25] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0], 'embed_sizes': array([11], dtype=int32), 'data_size': 17}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.5555555555555556\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6923076923076923\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6923076923076923\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6923076923076923\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8111888111888111\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8111888111888111\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8111888111888111\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5174825174825175\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5174825174825175\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5174825174825175\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.951048951048951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:26] Time left 599.37 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 599.37 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 200.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 200.00 secs\n",
            "Optimization Progress:   0%|          | 0/50 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-46fa2c95-a5df-43c9-bf80-f5a343aa9c77\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[50]\tvalid's auc: 0.520833\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5208333333333334 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125}. Best is trial 0 with value: 0.5208333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125} scored 0.5208333333333334 in 0:00:00.052158\n",
            "Optimization Progress:   0%|          | 0/50 [00:00<?, ?it/s, best_trial=0, best_value=0.521]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547}. Best is trial 1 with value: 0.5763888888888888.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547} scored 0.5763888888888888 in 0:00:00.040819\n",
            "Optimization Progress:   4%|▍         | 2/50 [00:00<00:02, 16.43it/s, best_trial=1, best_value=0.576]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.458333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[139]\tvalid's auc: 0.555556\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5416666666666667 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009}. Best is trial 1 with value: 0.5763888888888888.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009} scored 0.5416666666666667 in 0:00:00.045890\n",
            "Optimization Progress:   4%|▍         | 2/50 [00:00<00:02, 16.43it/s, best_trial=1, best_value=0.576]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[402]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254}. Best is trial 3 with value: 0.5833333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254} scored 0.5833333333333334 in 0:00:00.090867\n",
            "Optimization Progress:   8%|▊         | 4/50 [00:00<00:03, 13.42it/s, best_trial=3, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[12]\tvalid's auc: 0.565972\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.5659722222222222 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957}. Best is trial 3 with value: 0.5833333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957} scored 0.5659722222222222 in 0:00:00.042501\n",
            "Optimization Progress:   8%|▊         | 4/50 [00:00<00:03, 13.42it/s, best_trial=3, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[16]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.59375 and parameters: {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112}. Best is trial 5 with value: 0.59375.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112} scored 0.59375 in 0:00:00.039734\n",
            "Optimization Progress:  12%|█▏        | 6/50 [00:00<00:02, 15.26it/s, best_trial=5, best_value=0.594]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[227]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326} scored 0.5972222222222222 in 0:00:00.085407\n",
            "Optimization Progress:  12%|█▏        | 6/50 [00:00<00:02, 15.26it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.569444\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573} scored 0.5694444444444444 in 0:00:00.062072\n",
            "Optimization Progress:  16%|█▌        | 8/50 [00:00<00:03, 13.36it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[7]\tvalid's auc: 0.53125\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.53125 and parameters: {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988} scored 0.53125 in 0:00:00.044916\n",
            "Optimization Progress:  16%|█▌        | 8/50 [00:00<00:03, 13.36it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[427]\tvalid's auc: 0.541667\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5416666666666666 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026} scored 0.5416666666666666 in 0:00:00.115755\n",
            "Optimization Progress:  20%|██        | 10/50 [00:00<00:03, 12.23it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9725682721151934, 'num_leaves': 185, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.36240382475490457}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 185, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.36240382475490457} scored 0.5902777777777778 in 0:00:00.058527\n",
            "Optimization Progress:  20%|██        | 10/50 [00:00<00:03, 12.23it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.8575848060983975, 'num_leaves': 98, 'bagging_fraction': 0.6277217293825994, 'min_sum_hessian_in_leaf': 0.04513723813064542}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.8575848060983975, 'num_leaves': 98, 'bagging_fraction': 0.6277217293825994, 'min_sum_hessian_in_leaf': 0.04513723813064542} scored 0.5833333333333333 in 0:00:00.059915\n",
            "Optimization Progress:  24%|██▍       | 12/50 [00:00<00:02, 12.71it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7421560723588667, 'num_leaves': 142, 'bagging_fraction': 0.6254362249366492, 'min_sum_hessian_in_leaf': 0.001236260708045277}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.7421560723588667, 'num_leaves': 142, 'bagging_fraction': 0.6254362249366492, 'min_sum_hessian_in_leaf': 0.001236260708045277} scored 0.5833333333333334 in 0:00:00.058163\n",
            "Optimization Progress:  24%|██▍       | 12/50 [00:00<00:02, 12.71it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7320725411691559, 'num_leaves': 194, 'bagging_fraction': 0.6836109219932778, 'min_sum_hessian_in_leaf': 0.21884560252976312}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.7320725411691559, 'num_leaves': 194, 'bagging_fraction': 0.6836109219932778, 'min_sum_hessian_in_leaf': 0.21884560252976312} scored 0.5902777777777778 in 0:00:00.095669\n",
            "Optimization Progress:  28%|██▊       | 14/50 [00:01<00:03, 11.96it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8482867273170794, 'num_leaves': 102, 'bagging_fraction': 0.5733270423472366, 'min_sum_hessian_in_leaf': 0.022895661493813613}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8482867273170794, 'num_leaves': 102, 'bagging_fraction': 0.5733270423472366, 'min_sum_hessian_in_leaf': 0.022895661493813613} scored 0.5902777777777778 in 0:00:00.063354\n",
            "Optimization Progress:  28%|██▊       | 14/50 [00:01<00:03, 11.96it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[19]\tvalid's auc: 0.559028\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5590277777777778 and parameters: {'feature_fraction': 0.8957346661249761, 'num_leaves': 98, 'bagging_fraction': 0.7630489631580071, 'min_sum_hessian_in_leaf': 0.9258339016713287}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.8957346661249761, 'num_leaves': 98, 'bagging_fraction': 0.7630489631580071, 'min_sum_hessian_in_leaf': 0.9258339016713287} scored 0.5590277777777778 in 0:00:00.057780\n",
            "Optimization Progress:  32%|███▏      | 16/50 [00:01<00:02, 12.29it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[45]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7894295884659824, 'num_leaves': 205, 'bagging_fraction': 0.6510316760083694, 'min_sum_hessian_in_leaf': 0.09841756758357928}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.7894295884659824, 'num_leaves': 205, 'bagging_fraction': 0.6510316760083694, 'min_sum_hessian_in_leaf': 0.09841756758357928} scored 0.5902777777777778 in 0:00:00.060921\n",
            "Optimization Progress:  32%|███▏      | 16/50 [00:01<00:02, 12.29it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[444]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6029735171388793, 'num_leaves': 157, 'bagging_fraction': 0.5634924220005435, 'min_sum_hessian_in_leaf': 0.010900752652193337}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6029735171388793, 'num_leaves': 157, 'bagging_fraction': 0.5634924220005435, 'min_sum_hessian_in_leaf': 0.010900752652193337} scored 0.5972222222222222 in 0:00:00.118245\n",
            "Optimization Progress:  36%|███▌      | 18/50 [00:01<00:02, 11.24it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[189]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.5841593416403906, 'num_leaves': 159, 'bagging_fraction': 0.5547583595525817, 'min_sum_hessian_in_leaf': 0.007868553528824849}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.5841593416403906, 'num_leaves': 159, 'bagging_fraction': 0.5547583595525817, 'min_sum_hessian_in_leaf': 0.007868553528824849} scored 0.5694444444444444 in 0:00:00.080386\n",
            "Optimization Progress:  36%|███▌      | 18/50 [00:01<00:02, 11.24it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[608]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.5065701578589041, 'num_leaves': 223, 'bagging_fraction': 0.5104677846825332, 'min_sum_hessian_in_leaf': 0.0013214932238275125}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 223, 'bagging_fraction': 0.5104677846825332, 'min_sum_hessian_in_leaf': 0.0013214932238275125} scored 0.5902777777777778 in 0:00:00.166315\n",
            "Optimization Progress:  40%|████      | 20/50 [00:01<00:03,  9.46it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[18]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.5277777777777778 and parameters: {'feature_fraction': 0.615426845535755, 'num_leaves': 170, 'bagging_fraction': 0.9264342202471387, 'min_sum_hessian_in_leaf': 0.5709831496754405}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.615426845535755, 'num_leaves': 170, 'bagging_fraction': 0.9264342202471387, 'min_sum_hessian_in_leaf': 0.5709831496754405} scored 0.5277777777777778 in 0:00:00.065576\n",
            "Optimization Progress:  40%|████      | 20/50 [00:01<00:03,  9.46it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[159]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7105633352072851, 'num_leaves': 126, 'bagging_fraction': 0.596609562772596, 'min_sum_hessian_in_leaf': 0.027724933928716656}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.7105633352072851, 'num_leaves': 126, 'bagging_fraction': 0.596609562772596, 'min_sum_hessian_in_leaf': 0.027724933928716656} scored 0.5833333333333334 in 0:00:00.067380\n",
            "Optimization Progress:  44%|████▍     | 22/50 [00:01<00:02, 10.05it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[144]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.6819187188748133, 'num_leaves': 218, 'bagging_fraction': 0.6665654273844691, 'min_sum_hessian_in_leaf': 0.10334219428052598}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.6819187188748133, 'num_leaves': 218, 'bagging_fraction': 0.6665654273844691, 'min_sum_hessian_in_leaf': 0.10334219428052598} scored 0.5902777777777778 in 0:00:00.078634\n",
            "Optimization Progress:  44%|████▍     | 22/50 [00:02<00:02, 10.05it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[109]\tvalid's auc: 0.569444\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.8352725713024433, 'num_leaves': 73, 'bagging_fraction': 0.7333246876448902, 'min_sum_hessian_in_leaf': 0.012255253606587906}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.8352725713024433, 'num_leaves': 73, 'bagging_fraction': 0.7333246876448902, 'min_sum_hessian_in_leaf': 0.012255253606587906} scored 0.5694444444444444 in 0:00:00.102891\n",
            "Optimization Progress:  48%|████▊     | 24/50 [00:02<00:02,  9.81it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7776039056849715, 'num_leaves': 122, 'bagging_fraction': 0.6100808232291592, 'min_sum_hessian_in_leaf': 0.0034347001966147355}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.7776039056849715, 'num_leaves': 122, 'bagging_fraction': 0.6100808232291592, 'min_sum_hessian_in_leaf': 0.0034347001966147355} scored 0.5972222222222222 in 0:00:00.067133\n",
            "Optimization Progress:  48%|████▊     | 24/50 [00:02<00:02,  9.81it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[502]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6258082362855537, 'num_leaves': 130, 'bagging_fraction': 0.5743338109094763, 'min_sum_hessian_in_leaf': 0.0027565261382618876}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6258082362855537, 'num_leaves': 130, 'bagging_fraction': 0.5743338109094763, 'min_sum_hessian_in_leaf': 0.0027565261382618876} scored 0.5972222222222222 in 0:00:00.128030\n",
            "Optimization Progress:  52%|█████▏    | 26/50 [00:02<00:02,  9.42it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[65]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.576388888888889 and parameters: {'feature_fraction': 0.5592743997151934, 'num_leaves': 160, 'bagging_fraction': 0.5463668247936341, 'min_sum_hessian_in_leaf': 0.0022719680169641728}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5592743997151934, 'num_leaves': 160, 'bagging_fraction': 0.5463668247936341, 'min_sum_hessian_in_leaf': 0.0022719680169641728} scored 0.576388888888889 in 0:00:00.765328\n",
            "Optimization Progress:  54%|█████▍    | 27/50 [00:03<00:05,  4.20it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[61]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.7486261419689739, 'num_leaves': 114, 'bagging_fraction': 0.6084906475348004, 'min_sum_hessian_in_leaf': 0.08704658595003716}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.7486261419689739, 'num_leaves': 114, 'bagging_fraction': 0.6084906475348004, 'min_sum_hessian_in_leaf': 0.08704658595003716} scored 0.6041666666666667 in 0:00:00.633993\n",
            "Optimization Progress:  56%|█████▌    | 28/50 [00:03<00:07,  3.01it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[21]\tvalid's auc: 0.552083\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.5520833333333333 and parameters: {'feature_fraction': 0.7590534849545673, 'num_leaves': 173, 'bagging_fraction': 0.7752847229001598, 'min_sum_hessian_in_leaf': 0.10695607255524689}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.7590534849545673, 'num_leaves': 173, 'bagging_fraction': 0.7752847229001598, 'min_sum_hessian_in_leaf': 0.10695607255524689} scored 0.5520833333333333 in 0:00:01.074137\n",
            "Optimization Progress:  58%|█████▊    | 29/50 [00:05<00:10,  1.95it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[15]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.6948223695310548, 'num_leaves': 239, 'bagging_fraction': 0.7096324540883361, 'min_sum_hessian_in_leaf': 0.23161630959792906}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6948223695310548, 'num_leaves': 239, 'bagging_fraction': 0.7096324540883361, 'min_sum_hessian_in_leaf': 0.23161630959792906} scored 0.5798611111111112 in 0:00:00.429833\n",
            "Optimization Progress:  60%|██████    | 30/50 [00:05<00:10,  1.96it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[435]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6720822529159559, 'num_leaves': 112, 'bagging_fraction': 0.560678768673456, 'min_sum_hessian_in_leaf': 0.010068157024166188}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.6720822529159559, 'num_leaves': 112, 'bagging_fraction': 0.560678768673456, 'min_sum_hessian_in_leaf': 0.010068157024166188} scored 0.5972222222222222 in 0:00:01.020513\n",
            "Optimization Progress:  62%|██████▏   | 31/50 [00:06<00:12,  1.54it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.7644346131217467, 'num_leaves': 114, 'bagging_fraction': 0.6080173945084689, 'min_sum_hessian_in_leaf': 0.004136664781485284}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.7644346131217467, 'num_leaves': 114, 'bagging_fraction': 0.6080173945084689, 'min_sum_hessian_in_leaf': 0.004136664781485284} scored 0.6041666666666667 in 0:00:00.414868\n",
            "Optimization Progress:  64%|██████▍   | 32/50 [00:07<00:10,  1.68it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.7268302678751436, 'num_leaves': 84, 'bagging_fraction': 0.542692684485182, 'min_sum_hessian_in_leaf': 0.050255687475452886}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7268302678751436, 'num_leaves': 84, 'bagging_fraction': 0.542692684485182, 'min_sum_hessian_in_leaf': 0.050255687475452886} scored 0.5763888888888888 in 0:00:00.165736\n",
            "Optimization Progress:  66%|██████▌   | 33/50 [00:07<00:08,  2.05it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5972222222222223 and parameters: {'feature_fraction': 0.7546200918058636, 'num_leaves': 151, 'bagging_fraction': 0.5075106058128436, 'min_sum_hessian_in_leaf': 0.17539299952349766}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.7546200918058636, 'num_leaves': 151, 'bagging_fraction': 0.5075106058128436, 'min_sum_hessian_in_leaf': 0.17539299952349766} scored 0.5972222222222223 in 0:00:00.385827\n",
            "Optimization Progress:  68%|██████▊   | 34/50 [00:07<00:07,  2.14it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[205]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7630899510439957, 'num_leaves': 82, 'bagging_fraction': 0.51398332300743, 'min_sum_hessian_in_leaf': 1.0048323354929665}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.7630899510439957, 'num_leaves': 82, 'bagging_fraction': 0.51398332300743, 'min_sum_hessian_in_leaf': 1.0048323354929665} scored 0.5833333333333334 in 0:00:00.152639\n",
            "Optimization Progress:  70%|███████   | 35/50 [00:07<00:05,  2.56it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5555555555555556 and parameters: {'feature_fraction': 0.7023788576881956, 'num_leaves': 115, 'bagging_fraction': 0.6037910445825557, 'min_sum_hessian_in_leaf': 6.362583979504018}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.7023788576881956, 'num_leaves': 115, 'bagging_fraction': 0.6037910445825557, 'min_sum_hessian_in_leaf': 6.362583979504018} scored 0.5555555555555556 in 0:00:00.094432\n",
            "Optimization Progress:  72%|███████▏  | 36/50 [00:08<00:04,  3.19it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531} scored 0.6145833333333334 in 0:00:00.126170\n",
            "Optimization Progress:  74%|███████▍  | 37/50 [00:08<00:03,  3.71it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.5972222222222223 and parameters: {'feature_fraction': 0.8218539073651699, 'num_leaves': 142, 'bagging_fraction': 0.5073308534027855, 'min_sum_hessian_in_leaf': 0.3474846140961544}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.8218539073651699, 'num_leaves': 142, 'bagging_fraction': 0.5073308534027855, 'min_sum_hessian_in_leaf': 0.3474846140961544} scored 0.5972222222222223 in 0:00:00.173399\n",
            "Optimization Progress:  76%|███████▌  | 38/50 [00:08<00:02,  4.01it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.6006944444444445 and parameters: {'feature_fraction': 0.9147579597726889, 'num_leaves': 148, 'bagging_fraction': 0.5312125692578071, 'min_sum_hessian_in_leaf': 3.1233887286501005}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.9147579597726889, 'num_leaves': 148, 'bagging_fraction': 0.5312125692578071, 'min_sum_hessian_in_leaf': 3.1233887286501005} scored 0.6006944444444445 in 0:00:00.127169\n",
            "Optimization Progress:  78%|███████▊  | 39/50 [00:08<00:02,  4.49it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9851899024509025, 'num_leaves': 108, 'bagging_fraction': 0.5337337739945639, 'min_sum_hessian_in_leaf': 4.149213776758782}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9851899024509025, 'num_leaves': 108, 'bagging_fraction': 0.5337337739945639, 'min_sum_hessian_in_leaf': 4.149213776758782} scored 0.6006944444444444 in 0:00:00.167171\n",
            "Optimization Progress:  80%|████████  | 40/50 [00:08<00:02,  4.65it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.572917\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.5729166666666666 and parameters: {'feature_fraction': 0.889137025130443, 'num_leaves': 59, 'bagging_fraction': 0.6349130370364919, 'min_sum_hessian_in_leaf': 2.2842483223278864}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.889137025130443, 'num_leaves': 59, 'bagging_fraction': 0.6349130370364919, 'min_sum_hessian_in_leaf': 2.2842483223278864} scored 0.5729166666666666 in 0:00:00.256870\n",
            "Optimization Progress:  82%|████████▏ | 41/50 [00:09<00:02,  4.18it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9958026270163949, 'num_leaves': 109, 'bagging_fraction': 0.5335861598398993, 'min_sum_hessian_in_leaf': 5.570202963554855}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.9958026270163949, 'num_leaves': 109, 'bagging_fraction': 0.5335861598398993, 'min_sum_hessian_in_leaf': 5.570202963554855} scored 0.6145833333333334 in 0:00:00.831677\n",
            "Optimization Progress:  84%|████████▍ | 42/50 [00:09<00:03,  2.35it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9553879335277939, 'num_leaves': 133, 'bagging_fraction': 0.5812032091253919, 'min_sum_hessian_in_leaf': 4.912873224706649}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.9553879335277939, 'num_leaves': 133, 'bagging_fraction': 0.5812032091253919, 'min_sum_hessian_in_leaf': 4.912873224706649} scored 0.5902777777777778 in 0:00:00.352548\n",
            "Optimization Progress:  86%|████████▌ | 43/50 [00:10<00:02,  2.40it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1]\tvalid's auc: 0.5\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5 and parameters: {'feature_fraction': 0.9416860695555195, 'num_leaves': 90, 'bagging_fraction': 0.5327319139478942, 'min_sum_hessian_in_leaf': 9.686596290655332}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.9416860695555195, 'num_leaves': 90, 'bagging_fraction': 0.5327319139478942, 'min_sum_hessian_in_leaf': 9.686596290655332} scored 0.5 in 0:00:00.075604\n",
            "Optimization Progress:  88%|████████▊ | 44/50 [00:10<00:01,  3.04it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.6006944444444445 and parameters: {'feature_fraction': 0.9232857389532847, 'num_leaves': 117, 'bagging_fraction': 0.5293864727524185, 'min_sum_hessian_in_leaf': 1.2716775603487556}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.9232857389532847, 'num_leaves': 117, 'bagging_fraction': 0.5293864727524185, 'min_sum_hessian_in_leaf': 1.2716775603487556} scored 0.6006944444444445 in 0:00:00.112186\n",
            "Optimization Progress:  90%|█████████ | 45/50 [00:10<00:01,  3.65it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[71]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9979426475884785, 'num_leaves': 138, 'bagging_fraction': 0.5873366638078265, 'min_sum_hessian_in_leaf': 2.3778366648996148}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.9979426475884785, 'num_leaves': 138, 'bagging_fraction': 0.5873366638078265, 'min_sum_hessian_in_leaf': 2.3778366648996148} scored 0.5972222222222222 in 0:00:00.134010\n",
            "Optimization Progress:  92%|█████████▏| 46/50 [00:10<00:00,  4.16it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.8744908342367126, 'num_leaves': 16, 'bagging_fraction': 0.618368145908441, 'min_sum_hessian_in_leaf': 3.5644793534748884}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.8744908342367126, 'num_leaves': 16, 'bagging_fraction': 0.618368145908441, 'min_sum_hessian_in_leaf': 3.5644793534748884} scored 0.5763888888888888 in 0:00:00.155892\n",
            "Optimization Progress:  94%|█████████▍| 47/50 [00:10<00:00,  4.36it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.53125\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.53125 and parameters: {'feature_fraction': 0.9133806114646719, 'num_leaves': 149, 'bagging_fraction': 0.8870525704755607, 'min_sum_hessian_in_leaf': 0.020526616410047247}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.9133806114646719, 'num_leaves': 149, 'bagging_fraction': 0.8870525704755607, 'min_sum_hessian_in_leaf': 0.020526616410047247} scored 0.53125 in 0:00:01.276309\n",
            "Optimization Progress:  96%|█████████▌| 48/50 [00:12<00:01,  1.79it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.8162620264600886, 'num_leaves': 74, 'bagging_fraction': 0.5022755128714155, 'min_sum_hessian_in_leaf': 0.5104593639993887}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.8162620264600886, 'num_leaves': 74, 'bagging_fraction': 0.5022755128714155, 'min_sum_hessian_in_leaf': 0.5104593639993887} scored 0.5833333333333334 in 0:00:00.160395\n",
            "Optimization Progress:  98%|█████████▊| 49/50 [00:12<00:00,  2.18it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[127]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.576388888888889 and parameters: {'feature_fraction': 0.9576703429462708, 'num_leaves': 103, 'bagging_fraction': 0.6499298499734096, 'min_sum_hessian_in_leaf': 1.6250927229845524}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.9576703429462708, 'num_leaves': 103, 'bagging_fraction': 0.6499298499734096, 'min_sum_hessian_in_leaf': 1.6250927229845524} scored 0.576388888888889 in 0:00:00.195947\n",
            "Optimization Progress: 100%|██████████| 50/50 [00:12<00:00,  3.91it/s, best_trial=36, best_value=0.615]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531}\u001b[0m\n",
            " achieve 0.6146 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 144, 'feature_fraction': 0.8124527509966039, 'bagging_fraction': 0.5086792017528844, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.17837062520581531}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.594406\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.723776\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.755245\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.818182\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.597902\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.685315\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.909091\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.940559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6868024553571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6868024553571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Time left 586.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 586.04 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Blending: optimization starts with equal weights. Score = \u001b[1m0.6939174\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.6939174\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7134487\u001b[0m, weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7134487\u001b[0m, weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Blending: best score = \u001b[1m0.7134487\u001b[0m, best weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.7134487\u001b[0m, best weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] \u001b[1mAutoml preset training completed in 14.12 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 14.12 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:47:39] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.66234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.33766 * (5 averaged models Lvl_0_Pipe_1_Mod_0_Tuned_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.66234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.33766 * (5 averaged models Lvl_0_Pipe_1_Mod_0_Tuned_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA FS+LGBM/Linear] ROC-AUC: 0.7217  F1: 0.4082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Выбор лучшего"
      ],
      "metadata": {
        "id": "w5_DMUZzqaXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "results['LAMA_DEFAULT'] = (auc1, f1_1)\n",
        "results['LAMA_FAST'] = (auc2, f1_2)\n",
        "results['LAMA_ADVANCED'] = (auc3, f1_3)\n",
        "results['LAMA_FS'] = (auc4, f1_4)\n",
        "for k, v in results.items():\n",
        "    print(f'{k:15}| ROC-AUC: {v[0]:.4f} | F1: {v[1]:.4f}')\n",
        "\n",
        "best_lama_name = max(results, key=lambda k: results[k][0])\n",
        "print(f'--> Лучший бэйзлайн: {best_lama_name}, ROC-AUC = {results[best_lama_name][0]:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cJ_g-LmooB",
        "outputId": "88810b43-42f1-423d-e0c1-78514fa27750"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LAMA_DEFAULT   | ROC-AUC: 0.7217 | F1: 0.6557\n",
            "LAMA_FAST      | ROC-AUC: 0.7138 | F1: 0.6552\n",
            "LAMA_ADVANCED  | ROC-AUC: 0.5000 | F1: 0.0000\n",
            "LAMA_FS        | ROC-AUC: 0.7217 | F1: 0.4082\n",
            "--> Лучший бэйзлайн: LAMA_DEFAULT, ROC-AUC = 0.7217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классическая конфигурация LAMA, несмотря на консерватизм, дала лучший результат среди тестируемых."
      ],
      "metadata": {
        "id": "-34OVh9Dq55-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 1"
      ],
      "metadata": {
        "id": "o1lzPSo_rP9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 1: LightGBM + scale + auto feature selection\n",
        "\n",
        "# PIPELINE 1A: только scaling + LGBM (без фичер селекции)\n",
        "pipe_lgbm_base = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "pipe_lgbm_base.fit(X_train, y_train)\n",
        "pred_lgbm_base = pipe_lgbm_base.predict_proba(X_test)[:, 1]\n",
        "auc_lgbm_base = roc_auc_score(y_test, pred_lgbm_base)\n",
        "print(f'[Pipeline LGBM basic] ROC-AUC: {auc_lgbm_base:.4f}')\n",
        "\n",
        "# PIPELINE 1B: scaling + feature selection + LGBM\n",
        "# Селектор тренируется внутри пайплайна по cross-val на train (без data leakage)\n",
        "pipe_lgbm_fs = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectFromModel(LGBMClassifier(n_estimators=100, random_state=42), threshold=\"median\")),\n",
        "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "pipe_lgbm_fs.fit(X_train, y_train)\n",
        "pred_lgbm_fs = pipe_lgbm_fs.predict_proba(X_test)[:, 1]\n",
        "auc_lgbm_fs = roc_auc_score(y_test, pred_lgbm_fs)\n",
        "print(f'[Pipeline LGBM + feature selection] ROC-AUC: {auc_lgbm_fs:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBczjODitxHr",
        "outputId": "9f3aff59-6d37-4907-ef8f-2906882af5c8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline LGBM basic] ROC-AUC: 0.6980\n",
            "[Pipeline LGBM + feature selection] ROC-AUC: 0.6742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 2"
      ],
      "metadata": {
        "id": "8t-JPEQOrc1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 2: CatBoost + простая обработка пропусков\n",
        "pipe_catboost = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('catboost', CatBoostClassifier(iterations=200,\n",
        "                                    learning_rate=0.05,\n",
        "                                    eval_metric='AUC',\n",
        "                                    random_state=42,\n",
        "                                    verbose=0))\n",
        "])\n",
        "\n",
        "pipe_catboost.fit(X_train, y_train)\n",
        "pred_cat = pipe_catboost.predict_proba(X_test)[:, 1]\n",
        "auc_cat = roc_auc_score(y_test, pred_cat)\n",
        "print(f'[Pipeline CatBoost] ROC-AUC: {auc_cat:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mIVIPpQrmlO",
        "outputId": "e92dafaa-1dc3-4103-cc54-18097fb6fa4a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline CatBoost] ROC-AUC: 0.7048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 3"
      ],
      "metadata": {
        "id": "9ieCUGhPrrqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 3: Logistic Regression + StandardScaler + гиперпараметры GridSearch\n",
        "pipe_logreg = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logreg', LogisticRegression(max_iter=300))\n",
        "])\n",
        "\n",
        "param_grid = {'logreg__C': [0.01, 0.1, 1, 3, 10]}\n",
        "grid = GridSearchCV(pipe_logreg, param_grid, scoring='roc_auc', cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"[Pipeline LogReg] Лучшее C: {grid.best_params_}\")\n",
        "best_logreg = grid.best_estimator_\n",
        "preds_lr = best_logreg.predict_proba(X_test)[:, 1]\n",
        "auc_lr = roc_auc_score(y_test, preds_lr)\n",
        "print(f'[Pipeline LogReg tuned] ROC-AUC: {auc_lr:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYneA9o1rqKD",
        "outputId": "544afca5-ef93-4208-bbcb-b043b5cd2fee"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline LogReg] Лучшее C: {'logreg__C': 0.1}\n",
            "[Pipeline LogReg tuned] ROC-AUC: 0.7455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод\n",
        "Свое решение оказалось лучше LAMA baseline: максимум ROC-AUC своего решения: 0.7455 (пайплайн 3), лучшего baseline: 0.7217\n"
      ],
      "metadata": {
        "id": "Aaec6QLkr2eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "### [Дополнительно]"
      ],
      "metadata": {
        "id": "-A-JnAn2kc66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Проблема 1 - не GridSearch \"в лоб\", а хотя бы RandomSearch."
      ],
      "metadata": {
        "id": "m5WA2RZpk4Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "KabgJFs9oVUe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    # ('pca', PCA(n_components=0.95)),\n",
        "    ('lgbm', LGBMClassifier(verbose=-1, random_state=42))\n",
        "])\n",
        "\n",
        "param_dist = {\n",
        "    'lgbm__n_estimators': randint(100, 500),\n",
        "    'lgbm__learning_rate': uniform(0.01, 0.1),\n",
        "    'lgbm__max_depth': randint(3, 7),\n",
        "    'lgbm__num_leaves': randint(5, 20),\n",
        "    'lgbm__subsample': uniform(0.6, 0.4),\n",
        "    'lgbm__reg_alpha': uniform(0, 5),\n",
        "    'lgbm__reg_lambda': uniform(0, 5)\n",
        "}\n",
        "\n",
        "rs = RandomizedSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring='roc_auc',\n",
        "    cv=5\n",
        "    # random_state=42,\n",
        "    # n_jobs=-1\n",
        ")\n",
        "\n",
        "rs.fit(X_train, y_train)\n",
        "print(f\"Best params: {rs.best_params_}\")\n",
        "best_model = rs.best_estimator_\n",
        "preds_tuned = best_model.predict_proba(X_test)[:, 1]\n",
        "auc_tuned = roc_auc_score(y_test, preds_tuned)\n",
        "print(f'[Pipeline LGBM + RandomSearch] ROC-AUC: {auc_tuned:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRA-kVdZlIlN",
        "outputId": "f3299fe7-f31e-4ea5-cb87-f1151f1b8149"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'lgbm__learning_rate': np.float64(0.021586905952512975), 'lgbm__max_depth': 5, 'lgbm__n_estimators': 300, 'lgbm__num_leaves': 12, 'lgbm__reg_alpha': np.float64(2.247253370691017), 'lgbm__reg_lambda': np.float64(0.47705058245205656), 'lgbm__subsample': np.float64(0.7483273008793065)}\n",
            "[Pipeline LGBM + RandomSearch] ROC-AUC: 0.6810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** на решении (#3), где ранее использовался GridSearch, те же метрики были 0.7455 - после использования RandomSearch стало хуже."
      ],
      "metadata": {
        "id": "VJ4ykG-NncQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Проблема 2 - пофильтерить все-таки коррелирующие фичи"
      ],
      "metadata": {
        "id": "m-ccEAfTmNQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_highcorr_features(x, threshold):\n",
        "    corr_matrix = x.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "\n",
        "    print(f\"Dropping {len(to_drop)} correlated features: {to_drop}\")\n",
        "    return x.drop(columns=to_drop), to_drop\n",
        "\n",
        "X_train_uncorr, dropped_cols = remove_highcorr_features(X_train, 0.80)\n",
        "X_test_uncorr = X_test.drop(columns=dropped_cols)\n",
        "\n",
        "print(f\"Cleaned train shape: {X_train_uncorr.shape}\")\n",
        "\n",
        "pipe_uncorr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logreg', LogisticRegression(max_iter=300, C=1.0))\n",
        "])\n",
        "\n",
        "pipe_uncorr.fit(X_train_uncorr, y_train)\n",
        "pred_uncorr = pipe_uncorr.predict_proba(X_test_uncorr)[:, 1]\n",
        "auc_uncorr = roc_auc_score(y_test, pred_uncorr)\n",
        "print(f'\\n[Alternative solution: NO correlation] ROC-AUC: {auc_uncorr:.4f}')\n",
        "print(\"-\" * 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMpmD9C5mlYD",
        "outputId": "e114b635-0891-4cd3-93e2-ba2d4dbc7f67"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropping 4 correlated features: ['f4_p300', 'p4_p300', 'p8_p300', 'o2_p300']\n",
            "Cleaned train shape: (120, 15)\n",
            "\n",
            "[Alternative solution: NO correlation] ROC-AUC: 0.7387\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:** после удаления признаков с коррелацией более 80% ROC-AUC опустился с 0.7455 до 0.7387 при том же решении."
      ],
      "metadata": {
        "id": "yPs9DrKBpEgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Проблема 3 - странности результатов я думаю связаны в первую очередь с тем, что данных очень мало, медицинские данные редки и как правило довольно шумны."
      ],
      "metadata": {
        "id": "RyaFICbgpYnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# лимитим max_depth и num_leaves\n",
        "# добавила PCA - полезно для EEG и заодно полечит корреляционность\n",
        "\n",
        "pipe_lgbm_constrained = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=0.95)),\n",
        "    ('lgbm', LGBMClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.03,   # помедленнее обучение\n",
        "        num_leaves=7,         # малое количество\n",
        "        max_depth=3,          # низкая граница\n",
        "        reg_alpha=1,\n",
        "        reg_lambda=1,\n",
        "        random_state=42,\n",
        "        verbose=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipe_lgbm_constrained.fit(X_train, y_train)\n",
        "pred_lgbm_fix = pipe_lgbm_constrained.predict_proba(X_test)[:, 1]\n",
        "auc_lgbm_fix = roc_auc_score(y_test, pred_lgbm_fix)\n",
        "print(f'[Pipeline LGBM Constrained + PCA] ROC-AUC: {auc_lgbm_fix:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9JrLMl-prh4",
        "outputId": "7d182102-7e8c-45a6-f3b3-878cf10e8d6d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline LGBM Constrained + PCA] ROC-AUC: 0.6867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пробуем еще воутинг:\n",
        "clf1 = LogisticRegression(C=1, solver='liblinear', random_state=42)\n",
        "clf2 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "clf3 = SVC(probability=True, kernel='rbf', C=1, random_state=42)\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "    estimators=[('lr', clf1), ('rf', clf2), ('svm', clf3)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "pipe_voting = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('voting', eclf)\n",
        "])\n",
        "\n",
        "pipe_voting.fit(X_train, y_train)\n",
        "pred_vote = pipe_voting.predict_proba(X_test)[:, 1]\n",
        "auc_vote = roc_auc_score(y_test, pred_vote)\n",
        "print(f'[Pipeline Voting Ensemble] ROC-AUC: {auc_vote:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuG8qNkqRAe",
        "outputId": "d26f05d1-26bd-43e1-d40c-152c25335cc4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline Voting Ensemble] ROC-AUC: 0.7115\n"
          ]
        }
      ]
    }
  ]
}