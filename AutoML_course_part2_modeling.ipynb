{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "DBSPh0JCaH4C"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Загрузка данных"
      ],
      "metadata": {
        "id": "6k8MIz6QaZ0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "!wget https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/train.csv\n",
        "!wget https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODNLEiD3acJR",
        "outputId": "584c5d14-ad3b-4e75-da08-05761a468e0c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.11.12)\n",
            "--2025-12-15 02:01:22--  https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5381138 (5.1M) [text/plain]\n",
            "Saving to: ‘train.csv.2’\n",
            "\n",
            "train.csv.2         100%[===================>]   5.13M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-12-15 02:01:22 (64.4 MB/s) - ‘train.csv.2’ saved [5381138/5381138]\n",
            "\n",
            "--2025-12-15 02:01:22--  https://raw.githubusercontent.com/adasegroup/NEUROML2020/seminar1/seminar1/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3567877 (3.4M) [text/plain]\n",
            "Saving to: ‘test.csv.2’\n",
            "\n",
            "test.csv.2          100%[===================>]   3.40M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-12-15 02:01:23 (36.4 MB/s) - ‘test.csv.2’ saved [3567877/3567877]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightautoml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCPiunfbIb3",
        "outputId": "957134fc-1f18-488a-cc0b-d720614dc35d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightautoml in /usr/local/lib/python3.12/dist-packages (0.4.2)\n",
            "Requirement already satisfied: SQLAlchemy>=2.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.0.44)\n",
            "Requirement already satisfied: autowoe>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.3.4)\n",
            "Requirement already satisfied: catboost>=0.26.1 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.2.8)\n",
            "Requirement already satisfied: cmaes in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.12.0)\n",
            "Requirement already satisfied: holidays in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.86)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.5.2)\n",
            "Requirement already satisfied: json2html in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.3.0)\n",
            "Requirement already satisfied: lightgbm>=2.3 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from lightautoml) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.0.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.2.2)\n",
            "Requirement already satisfied: poetry-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.9.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from lightautoml) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightautoml) (1.16.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.13.2)\n",
            "Requirement already satisfied: statsmodels<=0.14.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.14.0)\n",
            "Requirement already satisfied: tabicl in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.1.4)\n",
            "Requirement already satisfied: tabm in /usr/local/lib/python3.12/dist-packages (from lightautoml) (0.0.3)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lightautoml) (4.67.1)\n",
            "Requirement already satisfied: xgboost<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from lightautoml) (2.1.4)\n",
            "Requirement already satisfied: StrEnum<0.5.0,>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (0.4.15)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (3.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.4.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (2025.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (8.2.3)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.12/dist-packages (from autowoe>=1.3.3->lightautoml) (3.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost>=0.26.1->lightautoml) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->lightautoml) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->lightautoml) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy>=2.0->lightautoml) (4.15.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels<=0.14.0->lightautoml) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (1.14.0)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->lightautoml) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost<3.0.0,>=2.0.0->lightautoml) (2.28.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->lightautoml) (3.0.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->lightautoml) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->lightautoml) (6.10.1)\n",
            "Requirement already satisfied: einops>=0.7 in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.8.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.36.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (5.9.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (4.57.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from tabicl->lightautoml) (0.23.1)\n",
            "Requirement already satisfied: rtdl_num_embeddings<0.1,>=0.0.12 in /usr/local/lib/python3.12/dist-packages (from tabm->lightautoml) (0.0.12)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.10)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autowoe>=1.3.3->lightautoml) (3.2.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->lightautoml) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->tabicl->lightautoml) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->tabicl->lightautoml) (1.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost>=0.26.1->lightautoml) (9.1.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->autowoe>=1.3.3->lightautoml) (2.19.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.0.0)\n",
            "Requirement already satisfied: docutils<0.22,>=0.20 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (0.21.2)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.0.1)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (2.17.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.0.0)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (1.4.1)\n",
            "Requirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from sphinx->autowoe>=1.3.3->lightautoml) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.12/dist-packages (from sphinx-rtd-theme->autowoe>=1.3.3->lightautoml) (4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->tabicl->lightautoml) (0.7.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->tabicl->lightautoml) (2.47.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->tabicl->lightautoml) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->tabicl->lightautoml) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->tabicl->lightautoml) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->tabicl->lightautoml) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
        "from lightautoml.tasks import Task\n",
        "\n",
        "from src.dataset import get_target, calc_features\n",
        "\n",
        "delimiter = \"\\n\" + \"-\"*10"
      ],
      "metadata": {
        "id": "sMcfyU7_ad9u"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "xSLVv2x7ahdl",
        "outputId": "3b2e6c2b-ab18-4b85-ad36-d3621f2069d6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   time  condition  epoch         C3         Cz         C4        Fp1  \\\n",
              "0     0          1      0  -5.885714  -2.533107   9.866895   7.962973   \n",
              "1     1          1      0  -7.999715 -16.916729 -11.924855  17.955477   \n",
              "2     2          1      0  -6.727283 -15.979567 -11.114195  17.183478   \n",
              "3     3          1      0   6.819390  -0.204905  10.090124  20.265222   \n",
              "4     4          1      0  13.129486  -5.817193   5.040633  19.462210   \n",
              "\n",
              "        Fp2         F7         F3  ...         F8         T7        T8  \\\n",
              "0  5.694433  23.638605  27.899784  ...  23.588723  12.178548  0.685809   \n",
              "1  8.526994  56.635981  28.508435  ...   1.045533  14.656061 -4.119778   \n",
              "2  4.497028  43.914130  10.079754  ... -14.741630  14.793562 -6.624813   \n",
              "3  7.843006  36.250611  13.291199  ...  -7.135541  21.723418 -2.276825   \n",
              "4  9.634234  42.311729  20.641012  ...   0.015602  19.703190  3.739076   \n",
              "\n",
              "         P7         P3         Pz         P4         P8         O1        O2  \n",
              "0 -4.887397 -10.646985 -14.735646  -8.729323  -0.562578 -17.055458 -3.616732  \n",
              "1 -4.632381 -17.980657 -23.456960 -12.960684  -9.639784 -20.233549 -1.229811  \n",
              "2 -3.402757 -10.269473 -18.736144  -3.579046  -0.045658 -14.089755  2.453398  \n",
              "3  2.066859   4.325365  -2.803322   8.835114  13.878945  -5.772410  7.657873  \n",
              "4  2.714350   3.251047  -3.631448   3.212956   4.635574  -5.045448  5.086024  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29764490-9f06-4758-90b3-86cf70107acd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>condition</th>\n",
              "      <th>epoch</th>\n",
              "      <th>C3</th>\n",
              "      <th>Cz</th>\n",
              "      <th>C4</th>\n",
              "      <th>Fp1</th>\n",
              "      <th>Fp2</th>\n",
              "      <th>F7</th>\n",
              "      <th>F3</th>\n",
              "      <th>...</th>\n",
              "      <th>F8</th>\n",
              "      <th>T7</th>\n",
              "      <th>T8</th>\n",
              "      <th>P7</th>\n",
              "      <th>P3</th>\n",
              "      <th>Pz</th>\n",
              "      <th>P4</th>\n",
              "      <th>P8</th>\n",
              "      <th>O1</th>\n",
              "      <th>O2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-5.885714</td>\n",
              "      <td>-2.533107</td>\n",
              "      <td>9.866895</td>\n",
              "      <td>7.962973</td>\n",
              "      <td>5.694433</td>\n",
              "      <td>23.638605</td>\n",
              "      <td>27.899784</td>\n",
              "      <td>...</td>\n",
              "      <td>23.588723</td>\n",
              "      <td>12.178548</td>\n",
              "      <td>0.685809</td>\n",
              "      <td>-4.887397</td>\n",
              "      <td>-10.646985</td>\n",
              "      <td>-14.735646</td>\n",
              "      <td>-8.729323</td>\n",
              "      <td>-0.562578</td>\n",
              "      <td>-17.055458</td>\n",
              "      <td>-3.616732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-7.999715</td>\n",
              "      <td>-16.916729</td>\n",
              "      <td>-11.924855</td>\n",
              "      <td>17.955477</td>\n",
              "      <td>8.526994</td>\n",
              "      <td>56.635981</td>\n",
              "      <td>28.508435</td>\n",
              "      <td>...</td>\n",
              "      <td>1.045533</td>\n",
              "      <td>14.656061</td>\n",
              "      <td>-4.119778</td>\n",
              "      <td>-4.632381</td>\n",
              "      <td>-17.980657</td>\n",
              "      <td>-23.456960</td>\n",
              "      <td>-12.960684</td>\n",
              "      <td>-9.639784</td>\n",
              "      <td>-20.233549</td>\n",
              "      <td>-1.229811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-6.727283</td>\n",
              "      <td>-15.979567</td>\n",
              "      <td>-11.114195</td>\n",
              "      <td>17.183478</td>\n",
              "      <td>4.497028</td>\n",
              "      <td>43.914130</td>\n",
              "      <td>10.079754</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.741630</td>\n",
              "      <td>14.793562</td>\n",
              "      <td>-6.624813</td>\n",
              "      <td>-3.402757</td>\n",
              "      <td>-10.269473</td>\n",
              "      <td>-18.736144</td>\n",
              "      <td>-3.579046</td>\n",
              "      <td>-0.045658</td>\n",
              "      <td>-14.089755</td>\n",
              "      <td>2.453398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.819390</td>\n",
              "      <td>-0.204905</td>\n",
              "      <td>10.090124</td>\n",
              "      <td>20.265222</td>\n",
              "      <td>7.843006</td>\n",
              "      <td>36.250611</td>\n",
              "      <td>13.291199</td>\n",
              "      <td>...</td>\n",
              "      <td>-7.135541</td>\n",
              "      <td>21.723418</td>\n",
              "      <td>-2.276825</td>\n",
              "      <td>2.066859</td>\n",
              "      <td>4.325365</td>\n",
              "      <td>-2.803322</td>\n",
              "      <td>8.835114</td>\n",
              "      <td>13.878945</td>\n",
              "      <td>-5.772410</td>\n",
              "      <td>7.657873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13.129486</td>\n",
              "      <td>-5.817193</td>\n",
              "      <td>5.040633</td>\n",
              "      <td>19.462210</td>\n",
              "      <td>9.634234</td>\n",
              "      <td>42.311729</td>\n",
              "      <td>20.641012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015602</td>\n",
              "      <td>19.703190</td>\n",
              "      <td>3.739076</td>\n",
              "      <td>2.714350</td>\n",
              "      <td>3.251047</td>\n",
              "      <td>-3.631448</td>\n",
              "      <td>3.212956</td>\n",
              "      <td>4.635574</td>\n",
              "      <td>-5.045448</td>\n",
              "      <td>5.086024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29764490-9f06-4758-90b3-86cf70107acd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29764490-9f06-4758-90b3-86cf70107acd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29764490-9f06-4758-90b3-86cf70107acd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e9e09306-f7ac-47cf-8a95-0d45a680ea4f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9e09306-f7ac-47cf-8a95-0d45a680ea4f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e9e09306-f7ac-47cf-8a95-0d45a680ea4f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_eeg = ['time', 'condition', 'epoch', 'target']\n",
        "channels = [ch for ch in df_train.columns if ch not in non_eeg]"
      ],
      "metadata": {
        "id": "lQoNvQJej_QN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = get_target(df_train)\n",
        "X = X.merge(calc_features(df_train, channels), on='epoch')\n",
        "y = X['condition'].apply(lambda x: 0 if x == 1 else 1)\n",
        "\n",
        "X = X.drop(['epoch', 'condition'], axis=1)\n",
        "y = y.astype(int)\n",
        "y.name = 'target'\n",
        "X = X.reset_index(drop=True)\n",
        "y = y.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "20MD4kEla1Wo"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Моделирование (максимум 3.5 балла)\n",
        "[0.25] Обоснование стратегии разделения данных (train-test split)\n",
        "Особое внимание уделить предотвращению утечки данных\n",
        "\n",
        "[0.25] LAMA бейзлайн:\n",
        "- Минимум 2 различные конфигурации\n",
        "- Выбор лучшего решения\n",
        "\n",
        "[3.0] Собственное решение (если не удалось побить LLama baseline: 3 x 1.0 балл за различные пайплайны/попытки):\n",
        "- Выбор модели\n",
        "- Построение пайплайна (препроцессинг, обработка пропусков, генерация признаков, отбор признаков, финальная модель/ансамбль)\n",
        "- Оптимизация гиперпараметров"
      ],
      "metadata": {
        "id": "3wrlxECraw8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cтратегии разделения данных:\n",
        "# В соответствием с выводами из файла EDA (part 1) делаем корректный train-test split по данным, предварительно подготовленным по эпохам\n",
        "npr = np.random.RandomState(42)\n",
        "epoch_list = X.index\n",
        "train_idx, test_idx = train_test_split(epoch_list, test_size=0.33, random_state=42) ### делаем разбиение по эпохам как независимым объектам, чтобы избежать утечки между зависимыми наблюдениями, поскольку эпохи коррелированы внутри себя\n",
        "\n",
        "X_train = X.iloc[train_idx]\n",
        "X_test = X.iloc[test_idx]\n",
        "y_train = y.iloc[train_idx]\n",
        "y_test = y.iloc[test_idx]\n"
      ],
      "metadata": {
        "id": "4AscAZe7kZPi"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовим данные для конфигураций\n",
        "roles = {'target': 'target'}\n",
        "task = Task('binary')\n",
        "\n",
        "train_LAMA = X_train.copy()\n",
        "train_LAMA['target'] = y_train.values\n",
        "\n",
        "test_LAMA = X_test.copy()\n",
        "test_LAMA['target'] = y_test.values"
      ],
      "metadata": {
        "id": "RHBrprJMn5bm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Конфигурация 1 - Классический LAMA (default)\n",
        "Стандартная конфигурация - подбор лучших моделей (LGB, CatBoost и др.) с автотюнингом. Используем пресеты \"по умолчанию\"."
      ],
      "metadata": {
        "id": "6aT6E80FntZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl1 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        ")\n",
        "oof_pred1 = automl1.fit_predict(train_LAMA, roles=roles, verbose=2)\n",
        "test_pred1 = automl1.predict(test_LAMA)\n",
        "\n",
        "auc1 = roc_auc_score(y_test, test_pred1.data[:, 0])\n",
        "f1_1 = f1_score(y_test, test_pred1.data[:, 0] > 0.5)\n",
        "print(f\"[LAMA Default] ROC-AUC: {auc1:.4f} F1: {f1_1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mme0xL9slg9L",
        "outputId": "422afa41-2f16-498c-c8a7-d4a455f9b786"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:14] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:28] Layer \u001b[1m1\u001b[0m train process start. Time left 585.72 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 585.72 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:28] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0, 1], 'embed_sizes': array([11, 11], dtype=int32), 'data_size': 27}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:28] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.5694444444444444\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.001 score = 0.5763888888888888\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.005 score = 0.5694444444444444\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.01 score = 0.5694444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:28] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.7062937062937064\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.7062937062937064\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.7062937062937064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8041958041958042\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8041958041958042\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8041958041958042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.4755244755244755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.4755244755244755\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.4755244755244755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.951048951048951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428572\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428572\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] Time left 584.66 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 584.66 secs\n",
            "\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[198]\tvalid's auc: 0.576389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.734266\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.800699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.797203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.811189\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.825175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[4]\tvalid's auc: 0.65035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.86014\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.867133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 130.11 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 130.11 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-e9788c11-99bb-41fc-9790-cccdf175966c\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[62]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5277777777777779 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07}. Best is trial 0 with value: 0.5277777777777779.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.5277777777777779 in 0:00:00.086014\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<00:10,  9.22it/s, best_trial=0, best_value=0.528]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[184]\tvalid's auc: 0.541667\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.5416666666666667 and parameters: {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}. Best is trial 1 with value: 0.5416666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.5416666666666667 in 0:00:00.077575\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<00:10,  9.22it/s, best_trial=1, best_value=0.542]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323}. Best is trial 2 with value: 0.5833333333333333.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254, 'reg_alpha': 5.472429642032198e-06, 'reg_lambda': 0.00052821153945323} scored 0.5833333333333333 in 0:00:00.048910\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:00<00:08, 11.69it/s, best_trial=2, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[311]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05}. Best is trial 2 with value: 0.5833333333333333.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.7159725093210578, 'num_leaves': 85, 'bagging_fraction': 0.8059264473611898, 'min_sum_hessian_in_leaf': 0.003613894271216527, 'reg_alpha': 4.258943089524393e-06, 'reg_lambda': 1.9826980964985924e-05} scored 0.5486111111111112 in 0:00:00.093224\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:00<00:08, 11.69it/s, best_trial=2, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08} scored 0.5902777777777778 in 0:00:00.055565\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:00<00:08, 11.32it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.524306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[31]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.517361111111111 and parameters: {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8037724259507192, 'num_leaves': 56, 'bagging_fraction': 0.5325257964926398, 'min_sum_hessian_in_leaf': 6.245139574743075, 'reg_alpha': 4.905556676028774, 'reg_lambda': 0.18861495878553936} scored 0.517361111111111 in 0:00:00.046551\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:00<00:08, 11.32it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[102]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026, 'reg_alpha': 1.254134495897175e-07, 'reg_lambda': 0.00028614897264046574} scored 0.5486111111111112 in 0:00:00.063128\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:00<00:07, 12.30it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[19]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.5625 and parameters: {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.5171942605576092, 'num_leaves': 234, 'bagging_fraction': 0.6293899908000085, 'min_sum_hessian_in_leaf': 0.4467752817973907, 'reg_alpha': 6.388511557344611e-06, 'reg_lambda': 0.0004793052550782129} scored 0.5625 in 0:00:00.049140\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:00<00:07, 12.30it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[438]\tvalid's auc: 0.548611\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.5486111111111112 and parameters: {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.7733551396716398, 'num_leaves': 60, 'bagging_fraction': 0.9847923138822793, 'min_sum_hessian_in_leaf': 1.2604664585649468, 'reg_alpha': 2.854239907497756, 'reg_lambda': 1.1309571585271483} scored 0.5486111111111112 in 0:00:00.117437\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:00<00:08, 11.31it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.7989499894055425, 'num_leaves': 237, 'bagging_fraction': 0.5442462510259598, 'min_sum_hessian_in_leaf': 0.006080390190296602, 'reg_alpha': 2.5529693461039728e-08, 'reg_lambda': 8.471746987003668e-06} scored 0.5902777777777778 in 0:00:00.085678\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:00<00:08, 11.31it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196177, 'reg_lambda': 2.2311398834761413e-08}. Best is trial 4 with value: 0.5902777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 177, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.050888616200595385, 'reg_alpha': 0.010510985525196177, 'reg_lambda': 2.2311398834761413e-08} scored 0.5833333333333334 in 0:00:00.067202\n",
            "Optimization Progress:  11%|█         | 11/101 [00:00<00:08, 11.05it/s, best_trial=4, best_value=0.59]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.8469126656582232, 'num_leaves': 169, 'bagging_fraction': 0.519289733032828, 'min_sum_hessian_in_leaf': 0.0010742716082928, 'reg_alpha': 0.002611279023867545, 'reg_lambda': 1.2039880553605616e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.8469126656582232, 'num_leaves': 169, 'bagging_fraction': 0.519289733032828, 'min_sum_hessian_in_leaf': 0.0010742716082928, 'reg_alpha': 0.002611279023867545, 'reg_lambda': 1.2039880553605616e-06} scored 0.6145833333333334 in 0:00:00.059896\n",
            "Optimization Progress:  11%|█         | 11/101 [00:01<00:08, 11.05it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8658978481302979, 'num_leaves': 153, 'bagging_fraction': 0.6830184529242326, 'min_sum_hessian_in_leaf': 0.001202733529302086, 'reg_alpha': 0.004235211413864064, 'reg_lambda': 1.2326376711599453e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.8658978481302979, 'num_leaves': 153, 'bagging_fraction': 0.6830184529242326, 'min_sum_hessian_in_leaf': 0.001202733529302086, 'reg_alpha': 0.004235211413864064, 'reg_lambda': 1.2326376711599453e-08} scored 0.5902777777777778 in 0:00:00.077388\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:01<00:08, 10.95it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[372]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.6257630446746575, 'num_leaves': 187, 'bagging_fraction': 0.5326590026895619, 'min_sum_hessian_in_leaf': 0.022305423901154794, 'reg_alpha': 0.0006936640966924947, 'reg_lambda': 8.739363284316351e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.6257630446746575, 'num_leaves': 187, 'bagging_fraction': 0.5326590026895619, 'min_sum_hessian_in_leaf': 0.022305423901154794, 'reg_alpha': 0.0006936640966924947, 'reg_lambda': 8.739363284316351e-07} scored 0.5902777777777778 in 0:00:00.108158\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:01<00:08, 10.95it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[121]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.8528943199501071, 'num_leaves': 115, 'bagging_fraction': 0.501737064356651, 'min_sum_hessian_in_leaf': 0.015569757430144106, 'reg_alpha': 0.06472842457094885, 'reg_lambda': 2.5237953668110687e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8528943199501071, 'num_leaves': 115, 'bagging_fraction': 0.501737064356651, 'min_sum_hessian_in_leaf': 0.015569757430144106, 'reg_alpha': 0.06472842457094885, 'reg_lambda': 2.5237953668110687e-07} scored 0.5763888888888888 in 0:00:00.082595\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:01<00:08,  9.97it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.9996812193207756, 'num_leaves': 194, 'bagging_fraction': 0.622344146322471, 'min_sum_hessian_in_leaf': 0.15801126222075507, 'reg_alpha': 0.0001319721127943001, 'reg_lambda': 6.170708682186709e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9996812193207756, 'num_leaves': 194, 'bagging_fraction': 0.622344146322471, 'min_sum_hessian_in_leaf': 0.15801126222075507, 'reg_alpha': 0.0001319721127943001, 'reg_lambda': 6.170708682186709e-06} scored 0.5798611111111112 in 0:00:00.064486\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:01<00:08,  9.97it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.559028\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5590277777777778 and parameters: {'feature_fraction': 0.5921106718245519, 'num_leaves': 134, 'bagging_fraction': 0.7100199146543272, 'min_sum_hessian_in_leaf': 0.0010292076269383125, 'reg_alpha': 0.18433207025107978, 'reg_lambda': 0.0072619186476958935}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5921106718245519, 'num_leaves': 134, 'bagging_fraction': 0.7100199146543272, 'min_sum_hessian_in_leaf': 0.0010292076269383125, 'reg_alpha': 0.18433207025107978, 'reg_lambda': 0.0072619186476958935} scored 0.5590277777777778 in 0:00:00.065025\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:01<00:07, 10.52it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[85]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7347827814876735, 'num_leaves': 207, 'bagging_fraction': 0.6005597633103007, 'min_sum_hessian_in_leaf': 2.688837274792938, 'reg_alpha': 4.993406319402674e-05, 'reg_lambda': 9.057479064075203e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.7347827814876735, 'num_leaves': 207, 'bagging_fraction': 0.6005597633103007, 'min_sum_hessian_in_leaf': 2.688837274792938, 'reg_alpha': 4.993406319402674e-05, 'reg_lambda': 9.057479064075203e-08} scored 0.5972222222222222 in 0:00:00.076814\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:01<00:07, 10.52it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.503472\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.447917\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[41]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.4479166666666667 and parameters: {'feature_fraction': 0.858919856983951, 'num_leaves': 154, 'bagging_fraction': 0.5798160663037338, 'min_sum_hessian_in_leaf': 8.27374948552204, 'reg_alpha': 1.13634012677488e-05, 'reg_lambda': 9.391747423110572e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.858919856983951, 'num_leaves': 154, 'bagging_fraction': 0.5798160663037338, 'min_sum_hessian_in_leaf': 8.27374948552204, 'reg_alpha': 1.13634012677488e-05, 'reg_lambda': 9.391747423110572e-07} scored 0.4479166666666667 in 0:00:00.069745\n",
            "Optimization Progress:  19%|█▉        | 19/101 [00:01<00:07, 10.65it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[173]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.9312856915263297, 'num_leaves': 116, 'bagging_fraction': 0.7423578866620045, 'min_sum_hessian_in_leaf': 2.2094860255768407, 'reg_alpha': 6.425073507898103e-05, 'reg_lambda': 2.1216144115076414e-05}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.9312856915263297, 'num_leaves': 116, 'bagging_fraction': 0.7423578866620045, 'min_sum_hessian_in_leaf': 2.2094860255768407, 'reg_alpha': 6.425073507898103e-05, 'reg_lambda': 2.1216144115076414e-05} scored 0.5763888888888888 in 0:00:00.087943\n",
            "Optimization Progress:  19%|█▉        | 19/101 [00:01<00:07, 10.65it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[63]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.5902777777777779 and parameters: {'feature_fraction': 0.8285726521637807, 'num_leaves': 163, 'bagging_fraction': 0.6567290912374351, 'min_sum_hessian_in_leaf': 2.291093257748377, 'reg_alpha': 0.04506957328221599, 'reg_lambda': 1.330641472132417e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.8285726521637807, 'num_leaves': 163, 'bagging_fraction': 0.6567290912374351, 'min_sum_hessian_in_leaf': 2.291093257748377, 'reg_alpha': 0.04506957328221599, 'reg_lambda': 1.330641472132417e-07} scored 0.5902777777777779 in 0:00:00.071794\n",
            "Optimization Progress:  21%|██        | 21/101 [00:01<00:07, 10.47it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8132466062529451, 'num_leaves': 166, 'bagging_fraction': 0.6637452938214106, 'min_sum_hessian_in_leaf': 1.8029132161525185, 'reg_alpha': 0.13261505382331965, 'reg_lambda': 1.3403992245220467e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.8132466062529451, 'num_leaves': 166, 'bagging_fraction': 0.6637452938214106, 'min_sum_hessian_in_leaf': 1.8029132161525185, 'reg_alpha': 0.13261505382331965, 'reg_lambda': 1.3403992245220467e-07} scored 0.5972222222222222 in 0:00:00.071629\n",
            "Optimization Progress:  21%|██        | 21/101 [00:02<00:07, 10.47it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[320]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7562001274743712, 'num_leaves': 207, 'bagging_fraction': 0.5675287464945606, 'min_sum_hessian_in_leaf': 4.07970344156614, 'reg_alpha': 0.4554200086220865, 'reg_lambda': 2.2436304140611774e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.7562001274743712, 'num_leaves': 207, 'bagging_fraction': 0.5675287464945606, 'min_sum_hessian_in_leaf': 4.07970344156614, 'reg_alpha': 0.4554200086220865, 'reg_lambda': 2.2436304140611774e-06} scored 0.5972222222222222 in 0:00:00.145368\n",
            "Optimization Progress:  23%|██▎       | 23/101 [00:02<00:08,  9.49it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[147]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9093784190410645, 'num_leaves': 176, 'bagging_fraction': 0.6476974120699914, 'min_sum_hessian_in_leaf': 0.8386729634138481, 'reg_alpha': 0.0007735053268340218, 'reg_lambda': 8.951936883000952e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.9093784190410645, 'num_leaves': 176, 'bagging_fraction': 0.6476974120699914, 'min_sum_hessian_in_leaf': 0.8386729634138481, 'reg_alpha': 0.0007735053268340218, 'reg_lambda': 8.951936883000952e-08} scored 0.5833333333333333 in 0:00:00.093995\n",
            "Optimization Progress:  24%|██▍       | 24/101 [00:02<00:08,  9.35it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.69062900978545, 'num_leaves': 216, 'bagging_fraction': 0.5018953531678593, 'min_sum_hessian_in_leaf': 0.3392513394576354, 'reg_alpha': 0.02784960091864702, 'reg_lambda': 0.0001143222482423875}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.69062900978545, 'num_leaves': 216, 'bagging_fraction': 0.5018953531678593, 'min_sum_hessian_in_leaf': 0.3392513394576354, 'reg_alpha': 0.02784960091864702, 'reg_lambda': 0.0001143222482423875} scored 0.5833333333333334 in 0:00:00.072605\n",
            "Optimization Progress:  24%|██▍       | 24/101 [00:02<00:08,  9.35it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[50]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.7973736500379813, 'num_leaves': 134, 'bagging_fraction': 0.7253961123667921, 'min_sum_hessian_in_leaf': 2.2830933022303608, 'reg_alpha': 4.340290398807059e-05, 'reg_lambda': 6.470627713514866e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.7973736500379813, 'num_leaves': 134, 'bagging_fraction': 0.7253961123667921, 'min_sum_hessian_in_leaf': 2.2830933022303608, 'reg_alpha': 4.340290398807059e-05, 'reg_lambda': 6.470627713514866e-08} scored 0.5763888888888888 in 0:00:00.066199\n",
            "Optimization Progress:  26%|██▌       | 26/101 [00:02<00:07,  9.94it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8814726721906899, 'num_leaves': 102, 'bagging_fraction': 0.5629483833276161, 'min_sum_hessian_in_leaf': 1.2615751233429964, 'reg_alpha': 0.0037547703608254456, 'reg_lambda': 7.945708557969849e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.8814726721906899, 'num_leaves': 102, 'bagging_fraction': 0.5629483833276161, 'min_sum_hessian_in_leaf': 1.2615751233429964, 'reg_alpha': 0.0037547703608254456, 'reg_lambda': 7.945708557969849e-07} scored 0.6006944444444444 in 0:00:00.075314\n",
            "Optimization Progress:  26%|██▌       | 26/101 [00:02<00:07,  9.94it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9019507906380755, 'num_leaves': 101, 'bagging_fraction': 0.563296715484897, 'min_sum_hessian_in_leaf': 3.910319441183966, 'reg_alpha': 0.00023179479805717014, 'reg_lambda': 0.009316730154012064}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.9019507906380755, 'num_leaves': 101, 'bagging_fraction': 0.563296715484897, 'min_sum_hessian_in_leaf': 3.910319441183966, 'reg_alpha': 0.00023179479805717014, 'reg_lambda': 0.009316730154012064} scored 0.6006944444444444 in 0:00:00.058439\n",
            "Optimization Progress:  28%|██▊       | 28/101 [00:02<00:06, 10.45it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1]\tvalid's auc: 0.5\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.5 and parameters: {'feature_fraction': 0.8883264334731107, 'num_leaves': 94, 'bagging_fraction': 0.5560058607786, 'min_sum_hessian_in_leaf': 9.074966324558195, 'reg_alpha': 0.00030718283897620977, 'reg_lambda': 0.003005978370436641}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.8883264334731107, 'num_leaves': 94, 'bagging_fraction': 0.5560058607786, 'min_sum_hessian_in_leaf': 9.074966324558195, 'reg_alpha': 0.00030718283897620977, 'reg_lambda': 0.003005978370436641} scored 0.5 in 0:00:00.081244\n",
            "Optimization Progress:  28%|██▊       | 28/101 [00:02<00:06, 10.45it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[95]\tvalid's auc: 0.520833\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5208333333333334 and parameters: {'feature_fraction': 0.9475842266303223, 'num_leaves': 255, 'bagging_fraction': 0.9313235884212914, 'min_sum_hessian_in_leaf': 0.20434587069222476, 'reg_alpha': 0.005817966286343741, 'reg_lambda': 0.02712150854591092}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.9475842266303223, 'num_leaves': 255, 'bagging_fraction': 0.9313235884212914, 'min_sum_hessian_in_leaf': 0.20434587069222476, 'reg_alpha': 0.005817966286343741, 'reg_lambda': 0.02712150854591092} scored 0.5208333333333334 in 0:00:00.092051\n",
            "Optimization Progress:  30%|██▉       | 30/101 [00:02<00:07,  9.97it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[124]\tvalid's auc: 0.555556\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5555555555555556 and parameters: {'feature_fraction': 0.8819428594209011, 'num_leaves': 105, 'bagging_fraction': 0.7703076770846052, 'min_sum_hessian_in_leaf': 0.7955110174517752, 'reg_alpha': 5.988099602010475e-07, 'reg_lambda': 0.05751673949831533}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.8819428594209011, 'num_leaves': 105, 'bagging_fraction': 0.7703076770846052, 'min_sum_hessian_in_leaf': 0.7955110174517752, 'reg_alpha': 5.988099602010475e-07, 'reg_lambda': 0.05751673949831533} scored 0.5555555555555556 in 0:00:00.094336\n",
            "Optimization Progress:  30%|██▉       | 30/101 [00:03<00:07,  9.97it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[43]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8373200013550088, 'num_leaves': 20, 'bagging_fraction': 0.6090712604865073, 'min_sum_hessian_in_leaf': 4.697771309000721, 'reg_alpha': 0.0012441773808045456, 'reg_lambda': 6.647131592608324e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.8373200013550088, 'num_leaves': 20, 'bagging_fraction': 0.6090712604865073, 'min_sum_hessian_in_leaf': 4.697771309000721, 'reg_alpha': 0.0012441773808045456, 'reg_lambda': 6.647131592608324e-07} scored 0.5902777777777778 in 0:00:00.072184\n",
            "Optimization Progress:  32%|███▏      | 32/101 [00:03<00:07,  9.85it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[427]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7701444315301456, 'num_leaves': 80, 'bagging_fraction': 0.5158465280916995, 'min_sum_hessian_in_leaf': 3.732189197494083, 'reg_alpha': 0.00016293127214441923, 'reg_lambda': 4.839057629056056e-05}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7701444315301456, 'num_leaves': 80, 'bagging_fraction': 0.5158465280916995, 'min_sum_hessian_in_leaf': 3.732189197494083, 'reg_alpha': 0.00016293127214441923, 'reg_lambda': 4.839057629056056e-05} scored 0.5902777777777778 in 0:00:00.167075\n",
            "Optimization Progress:  33%|███▎      | 33/101 [00:03<00:08,  8.49it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8998892026135179, 'num_leaves': 121, 'bagging_fraction': 0.5725101999084058, 'min_sum_hessian_in_leaf': 1.1598630173023619, 'reg_alpha': 0.010879463816978246, 'reg_lambda': 0.002475670094665481}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.8998892026135179, 'num_leaves': 121, 'bagging_fraction': 0.5725101999084058, 'min_sum_hessian_in_leaf': 1.1598630173023619, 'reg_alpha': 0.010879463816978246, 'reg_lambda': 0.002475670094665481} scored 0.5902777777777778 in 0:00:00.087276\n",
            "Optimization Progress:  34%|███▎      | 34/101 [00:03<00:07,  8.59it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9654252765746477, 'num_leaves': 143, 'bagging_fraction': 0.5932025272310425, 'min_sum_hessian_in_leaf': 0.37200808980947503, 'reg_alpha': 3.66942589306389e-05, 'reg_lambda': 2.717924248159728e-06}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.9654252765746477, 'num_leaves': 143, 'bagging_fraction': 0.5932025272310425, 'min_sum_hessian_in_leaf': 0.37200808980947503, 'reg_alpha': 3.66942589306389e-05, 'reg_lambda': 2.717924248159728e-06} scored 0.5833333333333333 in 0:00:00.081794\n",
            "Optimization Progress:  35%|███▍      | 35/101 [00:03<00:07,  8.82it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[284]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7248321173006003, 'num_leaves': 104, 'bagging_fraction': 0.5432143389065669, 'min_sum_hessian_in_leaf': 3.9340389173283947, 'reg_alpha': 1.3145174842777787e-06, 'reg_lambda': 5.616819190232959e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.7248321173006003, 'num_leaves': 104, 'bagging_fraction': 0.5432143389065669, 'min_sum_hessian_in_leaf': 3.9340389173283947, 'reg_alpha': 1.3145174842777787e-06, 'reg_lambda': 5.616819190232959e-07} scored 0.5902777777777778 in 0:00:00.121629\n",
            "Optimization Progress:  36%|███▌      | 36/101 [00:03<00:07,  8.18it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[39]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.6878781041902726, 'num_leaves': 89, 'bagging_fraction': 0.6050917464966283, 'min_sum_hessian_in_leaf': 0.5498900487995599, 'reg_alpha': 1.675870158978661e-05, 'reg_lambda': 0.7498650945882449}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6878781041902726, 'num_leaves': 89, 'bagging_fraction': 0.6050917464966283, 'min_sum_hessian_in_leaf': 0.5498900487995599, 'reg_alpha': 1.675870158978661e-05, 'reg_lambda': 0.7498650945882449} scored 0.5833333333333334 in 0:00:00.080611\n",
            "Optimization Progress:  37%|███▋      | 37/101 [00:03<00:07,  8.26it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9305029406741796, 'num_leaves': 73, 'bagging_fraction': 0.5253735472681968, 'min_sum_hessian_in_leaf': 0.001865553436196919, 'reg_alpha': 0.0022925756154773165, 'reg_lambda': 3.49629701653122e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.9305029406741796, 'num_leaves': 73, 'bagging_fraction': 0.5253735472681968, 'min_sum_hessian_in_leaf': 0.001865553436196919, 'reg_alpha': 0.0022925756154773165, 'reg_lambda': 3.49629701653122e-08} scored 0.6145833333333334 in 0:00:00.074772\n",
            "Optimization Progress:  37%|███▋      | 37/101 [00:03<00:07,  8.26it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9348560286191232, 'num_leaves': 68, 'bagging_fraction': 0.5257896500798322, 'min_sum_hessian_in_leaf': 0.0036573955142991618, 'reg_alpha': 0.0027541643540566975, 'reg_lambda': 2.9936787073789606e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.9348560286191232, 'num_leaves': 68, 'bagging_fraction': 0.5257896500798322, 'min_sum_hessian_in_leaf': 0.0036573955142991618, 'reg_alpha': 0.0027541643540566975, 'reg_lambda': 2.9936787073789606e-08} scored 0.6145833333333334 in 0:00:00.072804\n",
            "Optimization Progress:  39%|███▊      | 39/101 [00:03<00:06,  9.08it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9298305964756634, 'num_leaves': 45, 'bagging_fraction': 0.5226187215047378, 'min_sum_hessian_in_leaf': 0.0021336467619059167, 'reg_alpha': 0.002483771553959457, 'reg_lambda': 1.0886808766009548e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9298305964756634, 'num_leaves': 45, 'bagging_fraction': 0.5226187215047378, 'min_sum_hessian_in_leaf': 0.0021336467619059167, 'reg_alpha': 0.002483771553959457, 'reg_lambda': 1.0886808766009548e-08} scored 0.6145833333333334 in 0:00:00.075473\n",
            "Optimization Progress:  40%|███▉      | 40/101 [00:04<00:06,  9.25it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9439516136817188, 'num_leaves': 46, 'bagging_fraction': 0.5188991470819592, 'min_sum_hessian_in_leaf': 0.0021833719503143965, 'reg_alpha': 0.015722265406419748, 'reg_lambda': 1.2401629119014302e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.9439516136817188, 'num_leaves': 46, 'bagging_fraction': 0.5188991470819592, 'min_sum_hessian_in_leaf': 0.0021833719503143965, 'reg_alpha': 0.015722265406419748, 'reg_lambda': 1.2401629119014302e-08} scored 0.6145833333333334 in 0:00:00.086856\n",
            "Optimization Progress:  41%|████      | 41/101 [00:04<00:06,  9.17it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9321547889188007, 'num_leaves': 42, 'bagging_fraction': 0.5249342350802126, 'min_sum_hessian_in_leaf': 0.00212406210118282, 'reg_alpha': 0.023840676572282605, 'reg_lambda': 1.4645318441974015e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.9321547889188007, 'num_leaves': 42, 'bagging_fraction': 0.5249342350802126, 'min_sum_hessian_in_leaf': 0.00212406210118282, 'reg_alpha': 0.023840676572282605, 'reg_lambda': 1.4645318441974015e-08} scored 0.6145833333333334 in 0:00:00.083115\n",
            "Optimization Progress:  42%|████▏     | 42/101 [00:04<00:06,  9.03it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9814215540872783, 'num_leaves': 44, 'bagging_fraction': 0.5220389995601281, 'min_sum_hessian_in_leaf': 0.0037540431174034666, 'reg_alpha': 0.0015511968509139195, 'reg_lambda': 3.900266780665591e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.9814215540872783, 'num_leaves': 44, 'bagging_fraction': 0.5220389995601281, 'min_sum_hessian_in_leaf': 0.0037540431174034666, 'reg_alpha': 0.0015511968509139195, 'reg_lambda': 3.900266780665591e-08} scored 0.6145833333333334 in 0:00:00.077846\n",
            "Optimization Progress:  43%|████▎     | 43/101 [00:04<00:06,  9.20it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9296283008613073, 'num_leaves': 73, 'bagging_fraction': 0.5020782119359475, 'min_sum_hessian_in_leaf': 0.0019445430619787387, 'reg_alpha': 0.4703638334823923, 'reg_lambda': 1.1274007310170726e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.9296283008613073, 'num_leaves': 73, 'bagging_fraction': 0.5020782119359475, 'min_sum_hessian_in_leaf': 0.0019445430619787387, 'reg_alpha': 0.4703638334823923, 'reg_lambda': 1.1274007310170726e-08} scored 0.5902777777777778 in 0:00:00.080936\n",
            "Optimization Progress:  44%|████▎     | 44/101 [00:04<00:06,  9.34it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9547049024573764, 'num_leaves': 17, 'bagging_fraction': 0.5352683951575656, 'min_sum_hessian_in_leaf': 0.008999381191359188, 'reg_alpha': 0.01373820457217814, 'reg_lambda': 3.803166599544116e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.9547049024573764, 'num_leaves': 17, 'bagging_fraction': 0.5352683951575656, 'min_sum_hessian_in_leaf': 0.008999381191359188, 'reg_alpha': 0.01373820457217814, 'reg_lambda': 3.803166599544116e-08} scored 0.6006944444444444 in 0:00:00.091879\n",
            "Optimization Progress:  45%|████▍     | 45/101 [00:04<00:06,  9.22it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9430501937358311, 'num_leaves': 55, 'bagging_fraction': 0.5485045541315566, 'min_sum_hessian_in_leaf': 0.0019785093202409816, 'reg_alpha': 0.0032801608768030397, 'reg_lambda': 2.1110223829532783e-07}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.9430501937358311, 'num_leaves': 55, 'bagging_fraction': 0.5485045541315566, 'min_sum_hessian_in_leaf': 0.0019785093202409816, 'reg_alpha': 0.0032801608768030397, 'reg_lambda': 2.1110223829532783e-07} scored 0.6006944444444444 in 0:00:00.083051\n",
            "Optimization Progress:  46%|████▌     | 46/101 [00:04<00:05,  9.29it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[31]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9949782255858528, 'num_leaves': 69, 'bagging_fraction': 0.5863154693031444, 'min_sum_hessian_in_leaf': 0.0035660563069327346, 'reg_alpha': 0.000620780207931044, 'reg_lambda': 2.8581421713504514e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.9949782255858528, 'num_leaves': 69, 'bagging_fraction': 0.5863154693031444, 'min_sum_hessian_in_leaf': 0.0035660563069327346, 'reg_alpha': 0.000620780207931044, 'reg_lambda': 2.8581421713504514e-08} scored 0.5902777777777778 in 0:00:00.103993\n",
            "Optimization Progress:  47%|████▋     | 47/101 [00:04<00:06,  8.55it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[207]\tvalid's auc: 0.534722\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.5347222222222222 and parameters: {'feature_fraction': 0.9148750585485912, 'num_leaves': 53, 'bagging_fraction': 0.8723363300656801, 'min_sum_hessian_in_leaf': 0.008510587795946187, 'reg_alpha': 0.0017258849462186373, 'reg_lambda': 1.1639351371999156e-08}. Best is trial 11 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.9148750585485912, 'num_leaves': 53, 'bagging_fraction': 0.8723363300656801, 'min_sum_hessian_in_leaf': 0.008510587795946187, 'reg_alpha': 0.0017258849462186373, 'reg_lambda': 1.1639351371999156e-08} scored 0.5347222222222222 in 0:00:00.115432\n",
            "Optimization Progress:  48%|████▊     | 48/101 [00:04<00:06,  8.08it/s, best_trial=11, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.635417\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.6354166666666667 and parameters: {'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07} scored 0.6354166666666667 in 0:00:00.089519\n",
            "Optimization Progress:  49%|████▊     | 49/101 [00:05<00:06,  8.22it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[11]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.9781728906553796, 'num_leaves': 28, 'bagging_fraction': 0.6406089351880103, 'min_sum_hessian_in_leaf': 0.001355782027617838, 'reg_alpha': 0.0006150736030054262, 'reg_lambda': 3.619751378990793e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.9781728906553796, 'num_leaves': 28, 'bagging_fraction': 0.6406089351880103, 'min_sum_hessian_in_leaf': 0.001355782027617838, 'reg_alpha': 0.0006150736030054262, 'reg_lambda': 3.619751378990793e-07} scored 0.5763888888888888 in 0:00:00.102407\n",
            "Optimization Progress:  50%|████▉     | 50/101 [00:05<00:06,  8.10it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.8610135129763458, 'num_leaves': 32, 'bagging_fraction': 0.6190859463934587, 'min_sum_hessian_in_leaf': 0.003394751000828341, 'reg_alpha': 0.006039538582936169, 'reg_lambda': 1.859722874626421e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.8610135129763458, 'num_leaves': 32, 'bagging_fraction': 0.6190859463934587, 'min_sum_hessian_in_leaf': 0.003394751000828341, 'reg_alpha': 0.006039538582936169, 'reg_lambda': 1.859722874626421e-06} scored 0.5798611111111112 in 0:00:00.089178\n",
            "Optimization Progress:  50%|█████     | 51/101 [00:05<00:06,  8.11it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[303]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9588296285728293, 'num_leaves': 48, 'bagging_fraction': 0.5182778865659797, 'min_sum_hessian_in_leaf': 0.0014688315766160013, 'reg_alpha': 0.08393142968705078, 'reg_lambda': 5.051889327547736e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.9588296285728293, 'num_leaves': 48, 'bagging_fraction': 0.5182778865659797, 'min_sum_hessian_in_leaf': 0.0014688315766160013, 'reg_alpha': 0.08393142968705078, 'reg_lambda': 5.051889327547736e-08} scored 0.5972222222222222 in 0:00:00.152054\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [00:05<00:06,  7.08it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9260615235749264, 'num_leaves': 62, 'bagging_fraction': 0.5470752862825393, 'min_sum_hessian_in_leaf': 0.0027811625535005343, 'reg_alpha': 0.020917598579091822, 'reg_lambda': 2.678210282593266e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.9260615235749264, 'num_leaves': 62, 'bagging_fraction': 0.5470752862825393, 'min_sum_hessian_in_leaf': 0.0027811625535005343, 'reg_alpha': 0.020917598579091822, 'reg_lambda': 2.678210282593266e-07} scored 0.6006944444444444 in 0:00:00.080968\n",
            "Optimization Progress:  52%|█████▏    | 53/101 [00:05<00:06,  7.63it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[85]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.5536369471561253, 'num_leaves': 33, 'bagging_fraction': 0.5001221095785936, 'min_sum_hessian_in_leaf': 0.006661094351731153, 'reg_alpha': 0.006167175479320771, 'reg_lambda': 2.6809880407566107e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.5536369471561253, 'num_leaves': 33, 'bagging_fraction': 0.5001221095785936, 'min_sum_hessian_in_leaf': 0.006661094351731153, 'reg_alpha': 0.006167175479320771, 'reg_lambda': 2.6809880407566107e-08} scored 0.5694444444444444 in 0:00:00.089219\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [00:05<00:06,  7.77it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9861255992544901, 'num_leaves': 71, 'bagging_fraction': 0.5310990238874806, 'min_sum_hessian_in_leaf': 0.013977499969107719, 'reg_alpha': 0.321084826790021, 'reg_lambda': 1.0545467042157705e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.9861255992544901, 'num_leaves': 71, 'bagging_fraction': 0.5310990238874806, 'min_sum_hessian_in_leaf': 0.013977499969107719, 'reg_alpha': 0.321084826790021, 'reg_lambda': 1.0545467042157705e-07} scored 0.6006944444444444 in 0:00:00.078184\n",
            "Optimization Progress:  54%|█████▍    | 55/101 [00:05<00:05,  8.21it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[114]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9664636907261881, 'num_leaves': 80, 'bagging_fraction': 0.5788594495905532, 'min_sum_hessian_in_leaf': 0.0010114577180297046, 'reg_alpha': 2.264855375773613, 'reg_lambda': 2.1998774208462416e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.9664636907261881, 'num_leaves': 80, 'bagging_fraction': 0.5788594495905532, 'min_sum_hessian_in_leaf': 0.0010114577180297046, 'reg_alpha': 2.264855375773613, 'reg_lambda': 2.1998774208462416e-08} scored 0.5833333333333333 in 0:00:00.090628\n",
            "Optimization Progress:  55%|█████▌    | 56/101 [00:05<00:05,  8.34it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.874960577327053, 'num_leaves': 25, 'bagging_fraction': 0.5171331804115998, 'min_sum_hessian_in_leaf': 0.005181021933481765, 'reg_alpha': 0.0017284792234297539, 'reg_lambda': 8.20025939464645e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.874960577327053, 'num_leaves': 25, 'bagging_fraction': 0.5171331804115998, 'min_sum_hessian_in_leaf': 0.005181021933481765, 'reg_alpha': 0.0017284792234297539, 'reg_lambda': 8.20025939464645e-06} scored 0.5902777777777778 in 0:00:00.109659\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [00:06<00:05,  7.79it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8461247801196913, 'num_leaves': 38, 'bagging_fraction': 0.548819565094987, 'min_sum_hessian_in_leaf': 0.0025905903628920274, 'reg_alpha': 0.03801329737935307, 'reg_lambda': 1.5952379848718482e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.8461247801196913, 'num_leaves': 38, 'bagging_fraction': 0.548819565094987, 'min_sum_hessian_in_leaf': 0.0025905903628920274, 'reg_alpha': 0.03801329737935307, 'reg_lambda': 1.5952379848718482e-07} scored 0.6006944444444444 in 0:00:00.072925\n",
            "Optimization Progress:  57%|█████▋    | 58/101 [00:06<00:05,  8.29it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[68]\tvalid's auc: 0.5625\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.5625 and parameters: {'feature_fraction': 0.9389604032165146, 'num_leaves': 60, 'bagging_fraction': 0.8501399083840085, 'min_sum_hessian_in_leaf': 0.0015019835762393385, 'reg_alpha': 0.00038357823116459927, 'reg_lambda': 5.611792859757472e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.9389604032165146, 'num_leaves': 60, 'bagging_fraction': 0.8501399083840085, 'min_sum_hessian_in_leaf': 0.0015019835762393385, 'reg_alpha': 0.00038357823116459927, 'reg_lambda': 5.611792859757472e-08} scored 0.5625 in 0:00:00.094651\n",
            "Optimization Progress:  58%|█████▊    | 59/101 [00:06<00:05,  8.20it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9015211937609844, 'num_leaves': 49, 'bagging_fraction': 0.5838540248328894, 'min_sum_hessian_in_leaf': 0.004751676808119229, 'reg_alpha': 0.00010101264393424657, 'reg_lambda': 3.4864450028997447e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.9015211937609844, 'num_leaves': 49, 'bagging_fraction': 0.5838540248328894, 'min_sum_hessian_in_leaf': 0.004751676808119229, 'reg_alpha': 0.00010101264393424657, 'reg_lambda': 3.4864450028997447e-07} scored 0.5902777777777778 in 0:00:00.120154\n",
            "Optimization Progress:  59%|█████▉    | 60/101 [00:06<00:05,  7.49it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.586806\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.5868055555555555 and parameters: {'feature_fraction': 0.9168882630274567, 'num_leaves': 36, 'bagging_fraction': 0.6766643899084799, 'min_sum_hessian_in_leaf': 0.027686018660877165, 'reg_alpha': 0.009573816859155837, 'reg_lambda': 3.600155987170549e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.9168882630274567, 'num_leaves': 36, 'bagging_fraction': 0.6766643899084799, 'min_sum_hessian_in_leaf': 0.027686018660877165, 'reg_alpha': 0.009573816859155837, 'reg_lambda': 3.600155987170549e-06} scored 0.5868055555555555 in 0:00:00.081611\n",
            "Optimization Progress:  60%|██████    | 61/101 [00:06<00:05,  7.90it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.942430502919107, 'num_leaves': 42, 'bagging_fraction': 0.5288418704965183, 'min_sum_hessian_in_leaf': 0.0020368206282585666, 'reg_alpha': 0.02133359262103408, 'reg_lambda': 1.1406661630425062e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.942430502919107, 'num_leaves': 42, 'bagging_fraction': 0.5288418704965183, 'min_sum_hessian_in_leaf': 0.0020368206282585666, 'reg_alpha': 0.02133359262103408, 'reg_lambda': 1.1406661630425062e-08} scored 0.6215277777777778 in 0:00:00.075755\n",
            "Optimization Progress:  61%|██████▏   | 62/101 [00:06<00:04,  8.32it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9546334031595289, 'num_leaves': 25, 'bagging_fraction': 0.5378254715562456, 'min_sum_hessian_in_leaf': 0.0017377622282538896, 'reg_alpha': 0.0031223938236882532, 'reg_lambda': 1.8161103314700847e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.9546334031595289, 'num_leaves': 25, 'bagging_fraction': 0.5378254715562456, 'min_sum_hessian_in_leaf': 0.0017377622282538896, 'reg_alpha': 0.0031223938236882532, 'reg_lambda': 1.8161103314700847e-08} scored 0.6006944444444444 in 0:00:00.092587\n",
            "Optimization Progress:  62%|██████▏   | 63/101 [00:06<00:04,  8.35it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[69]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.9994875400251846, 'num_leaves': 61, 'bagging_fraction': 0.5623789247220361, 'min_sum_hessian_in_leaf': 0.0024969359098993495, 'reg_alpha': 0.07987259377379487, 'reg_lambda': 1.0719750722881284e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.9994875400251846, 'num_leaves': 61, 'bagging_fraction': 0.5623789247220361, 'min_sum_hessian_in_leaf': 0.0024969359098993495, 'reg_alpha': 0.07987259377379487, 'reg_lambda': 1.0719750722881284e-08} scored 0.6041666666666667 in 0:00:00.091181\n",
            "Optimization Progress:  63%|██████▎   | 64/101 [00:06<00:04,  8.32it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[252]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8909389962411892, 'num_leaves': 45, 'bagging_fraction': 0.511337245778791, 'min_sum_hessian_in_leaf': 0.0011908527737786567, 'reg_alpha': 0.0009750541837771642, 'reg_lambda': 6.147168849923748e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.8909389962411892, 'num_leaves': 45, 'bagging_fraction': 0.511337245778791, 'min_sum_hessian_in_leaf': 0.0011908527737786567, 'reg_alpha': 0.0009750541837771642, 'reg_lambda': 6.147168849923748e-08} scored 0.5972222222222222 in 0:00:00.108390\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [00:07<00:04,  7.89it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9179895581633201, 'num_leaves': 55, 'bagging_fraction': 0.5351088886151683, 'min_sum_hessian_in_leaf': 0.003968455887013349, 'reg_alpha': 0.014453234264072013, 'reg_lambda': 9.597134543399738}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.9179895581633201, 'num_leaves': 55, 'bagging_fraction': 0.5351088886151683, 'min_sum_hessian_in_leaf': 0.003968455887013349, 'reg_alpha': 0.014453234264072013, 'reg_lambda': 9.597134543399738} scored 0.6006944444444444 in 0:00:00.082749\n",
            "Optimization Progress:  65%|██████▌   | 66/101 [00:07<00:04,  8.06it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[265]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8137550995736841, 'num_leaves': 181, 'bagging_fraction': 0.5598382882064329, 'min_sum_hessian_in_leaf': 0.002812553344915786, 'reg_alpha': 0.0025026271820271003, 'reg_lambda': 1.2081422918076064e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.8137550995736841, 'num_leaves': 181, 'bagging_fraction': 0.5598382882064329, 'min_sum_hessian_in_leaf': 0.002812553344915786, 'reg_alpha': 0.0025026271820271003, 'reg_lambda': 1.2081422918076064e-06} scored 0.5902777777777778 in 0:00:00.147558\n",
            "Optimization Progress:  66%|██████▋   | 67/101 [00:07<00:04,  7.00it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[163]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.5277777777777778 and parameters: {'feature_fraction': 0.9714045688078509, 'num_leaves': 84, 'bagging_fraction': 0.9804396137360377, 'min_sum_hessian_in_leaf': 0.006976333241859699, 'reg_alpha': 0.006378905337391348, 'reg_lambda': 1.0304944804596318e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.9714045688078509, 'num_leaves': 84, 'bagging_fraction': 0.9804396137360377, 'min_sum_hessian_in_leaf': 0.006976333241859699, 'reg_alpha': 0.006378905337391348, 'reg_lambda': 1.0304944804596318e-07} scored 0.5277777777777778 in 0:00:00.167297\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [00:07<00:05,  6.23it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[21]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.59375 and parameters: {'feature_fraction': 0.8694462898154652, 'num_leaves': 76, 'bagging_fraction': 0.7944393537734248, 'min_sum_hessian_in_leaf': 0.0010173893074085687, 'reg_alpha': 0.03709224196564614, 'reg_lambda': 2.521720902722272e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.8694462898154652, 'num_leaves': 76, 'bagging_fraction': 0.7944393537734248, 'min_sum_hessian_in_leaf': 0.0010173893074085687, 'reg_alpha': 0.03709224196564614, 'reg_lambda': 2.521720902722272e-08} scored 0.59375 in 0:00:00.082311\n",
            "Optimization Progress:  68%|██████▊   | 69/101 [00:07<00:04,  6.90it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[346]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9438134524424316, 'num_leaves': 66, 'bagging_fraction': 0.514885526300983, 'min_sum_hessian_in_leaf': 0.051743092098014296, 'reg_alpha': 0.00046139415626740744, 'reg_lambda': 2.034068874554477e-05}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.9438134524424316, 'num_leaves': 66, 'bagging_fraction': 0.514885526300983, 'min_sum_hessian_in_leaf': 0.051743092098014296, 'reg_alpha': 0.00046139415626740744, 'reg_lambda': 2.034068874554477e-05} scored 0.5972222222222222 in 0:00:00.146591\n",
            "Optimization Progress:  69%|██████▉   | 70/101 [00:07<00:04,  6.46it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9043907657333571, 'num_leaves': 16, 'bagging_fraction': 0.5723640035663995, 'min_sum_hessian_in_leaf': 0.0016657419924648385, 'reg_alpha': 0.14695132685031148, 'reg_lambda': 1.7472296198492442e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.9043907657333571, 'num_leaves': 16, 'bagging_fraction': 0.5723640035663995, 'min_sum_hessian_in_leaf': 0.0016657419924648385, 'reg_alpha': 0.14695132685031148, 'reg_lambda': 1.7472296198492442e-07} scored 0.5902777777777778 in 0:00:00.079547\n",
            "Optimization Progress:  70%|███████   | 71/101 [00:08<00:04,  7.12it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9223939820020292, 'num_leaves': 41, 'bagging_fraction': 0.5238031840395967, 'min_sum_hessian_in_leaf': 0.0022966254514410343, 'reg_alpha': 0.01914089897415708, 'reg_lambda': 1.0293995286934194e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.9223939820020292, 'num_leaves': 41, 'bagging_fraction': 0.5238031840395967, 'min_sum_hessian_in_leaf': 0.0022966254514410343, 'reg_alpha': 0.01914089897415708, 'reg_lambda': 1.0293995286934194e-08} scored 0.6145833333333334 in 0:00:00.077666\n",
            "Optimization Progress:  71%|███████▏  | 72/101 [00:08<00:03,  7.64it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.930110134436058, 'num_leaves': 195, 'bagging_fraction': 0.5017032762241742, 'min_sum_hessian_in_leaf': 0.004793847940535511, 'reg_alpha': 0.026639853757879348, 'reg_lambda': 1.7211612899526624e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.930110134436058, 'num_leaves': 195, 'bagging_fraction': 0.5017032762241742, 'min_sum_hessian_in_leaf': 0.004793847940535511, 'reg_alpha': 0.026639853757879348, 'reg_lambda': 1.7211612899526624e-08} scored 0.5902777777777778 in 0:00:00.087926\n",
            "Optimization Progress:  72%|███████▏  | 73/101 [00:08<00:03,  7.88it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9463803858965383, 'num_leaves': 40, 'bagging_fraction': 0.528580130179981, 'min_sum_hessian_in_leaf': 0.0021333652397747646, 'reg_alpha': 0.009163765208397304, 'reg_lambda': 4.2453943104280346e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.9463803858965383, 'num_leaves': 40, 'bagging_fraction': 0.528580130179981, 'min_sum_hessian_in_leaf': 0.0021333652397747646, 'reg_alpha': 0.009163765208397304, 'reg_lambda': 4.2453943104280346e-08} scored 0.6215277777777778 in 0:00:00.082733\n",
            "Optimization Progress:  73%|███████▎  | 74/101 [00:08<00:03,  7.78it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9523746302288224, 'num_leaves': 31, 'bagging_fraction': 0.5541009340787182, 'min_sum_hessian_in_leaf': 0.001463941386349567, 'reg_alpha': 0.010610967187865254, 'reg_lambda': 4.293279366228622e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.9523746302288224, 'num_leaves': 31, 'bagging_fraction': 0.5541009340787182, 'min_sum_hessian_in_leaf': 0.001463941386349567, 'reg_alpha': 0.010610967187865254, 'reg_lambda': 4.293279366228622e-08} scored 0.6006944444444444 in 0:00:00.080622\n",
            "Optimization Progress:  74%|███████▍  | 75/101 [00:08<00:03,  8.15it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9836983526827456, 'num_leaves': 49, 'bagging_fraction': 0.5314065839402676, 'min_sum_hessian_in_leaf': 0.08157616343286032, 'reg_alpha': 0.00420710452536068, 'reg_lambda': 8.261280993326804e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.9836983526827456, 'num_leaves': 49, 'bagging_fraction': 0.5314065839402676, 'min_sum_hessian_in_leaf': 0.08157616343286032, 'reg_alpha': 0.00420710452536068, 'reg_lambda': 8.261280993326804e-08} scored 0.6006944444444444 in 0:00:00.091910\n",
            "Optimization Progress:  75%|███████▌  | 76/101 [00:08<00:03,  7.74it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[71]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.8927985592983662, 'num_leaves': 124, 'bagging_fraction': 0.6006676657576917, 'min_sum_hessian_in_leaf': 0.002869782684867002, 'reg_alpha': 4.118195884803171e-08, 'reg_lambda': 3.5523210592233605e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.8927985592983662, 'num_leaves': 124, 'bagging_fraction': 0.6006676657576917, 'min_sum_hessian_in_leaf': 0.002869782684867002, 'reg_alpha': 4.118195884803171e-08, 'reg_lambda': 3.5523210592233605e-08} scored 0.5972222222222222 in 0:00:00.098977\n",
            "Optimization Progress:  76%|███████▌  | 77/101 [00:08<00:03,  7.59it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9706182911986332, 'num_leaves': 23, 'bagging_fraction': 0.5413937799210031, 'min_sum_hessian_in_leaf': 0.0019408669178434855, 'reg_alpha': 0.0491465176383278, 'reg_lambda': 3.998752495266748e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.9706182911986332, 'num_leaves': 23, 'bagging_fraction': 0.5413937799210031, 'min_sum_hessian_in_leaf': 0.0019408669178434855, 'reg_alpha': 0.0491465176383278, 'reg_lambda': 3.998752495266748e-07} scored 0.6006944444444444 in 0:00:00.090156\n",
            "Optimization Progress:  77%|███████▋  | 78/101 [00:08<00:02,  7.85it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[324]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.945389974352393, 'num_leaves': 165, 'bagging_fraction': 0.5113466356700372, 'min_sum_hessian_in_leaf': 0.001271870421737334, 'reg_alpha': 0.0013313968472653493, 'reg_lambda': 7.49583050219547e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.945389974352393, 'num_leaves': 165, 'bagging_fraction': 0.5113466356700372, 'min_sum_hessian_in_leaf': 0.001271870421737334, 'reg_alpha': 0.0013313968472653493, 'reg_lambda': 7.49583050219547e-08} scored 0.5902777777777778 in 0:00:00.140550\n",
            "Optimization Progress:  78%|███████▊  | 79/101 [00:09<00:03,  7.03it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.913410970286741, 'num_leaves': 141, 'bagging_fraction': 0.5667622874976119, 'min_sum_hessian_in_leaf': 0.011228745248082067, 'reg_alpha': 0.00247792984101857, 'reg_lambda': 2.0403344409315574e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.913410970286741, 'num_leaves': 141, 'bagging_fraction': 0.5667622874976119, 'min_sum_hessian_in_leaf': 0.011228745248082067, 'reg_alpha': 0.00247792984101857, 'reg_lambda': 2.0403344409315574e-08} scored 0.6041666666666667 in 0:00:00.088310\n",
            "Optimization Progress:  79%|███████▉  | 80/101 [00:09<00:02,  7.39it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9592676737274902, 'num_leaves': 91, 'bagging_fraction': 0.5283153111198535, 'min_sum_hessian_in_leaf': 0.0033558493912850687, 'reg_alpha': 0.00024953070456939597, 'reg_lambda': 1.4659672381457417e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.9592676737274902, 'num_leaves': 91, 'bagging_fraction': 0.5283153111198535, 'min_sum_hessian_in_leaf': 0.0033558493912850687, 'reg_alpha': 0.00024953070456939597, 'reg_lambda': 1.4659672381457417e-07} scored 0.6215277777777778 in 0:00:00.096816\n",
            "Optimization Progress:  80%|████████  | 81/101 [00:09<00:02,  7.55it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.621528\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.6215277777777778 and parameters: {'feature_fraction': 0.9371237156469211, 'num_leaves': 95, 'bagging_fraction': 0.5281036990805675, 'min_sum_hessian_in_leaf': 0.0033393128578611056, 'reg_alpha': 0.00017968669251903086, 'reg_lambda': 1.8568558219010845e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.9371237156469211, 'num_leaves': 95, 'bagging_fraction': 0.5281036990805675, 'min_sum_hessian_in_leaf': 0.0033393128578611056, 'reg_alpha': 0.00017968669251903086, 'reg_lambda': 1.8568558219010845e-07} scored 0.6215277777777778 in 0:00:00.151404\n",
            "Optimization Progress:  81%|████████  | 82/101 [00:09<00:02,  6.41it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9633252749020128, 'num_leaves': 94, 'bagging_fraction': 0.5510917175616286, 'min_sum_hessian_in_leaf': 0.0033304622254419405, 'reg_alpha': 0.0002938417822631321, 'reg_lambda': 1.9700292851303042e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.9633252749020128, 'num_leaves': 94, 'bagging_fraction': 0.5510917175616286, 'min_sum_hessian_in_leaf': 0.0033304622254419405, 'reg_alpha': 0.0002938417822631321, 'reg_lambda': 1.9700292851303042e-07} scored 0.6006944444444444 in 0:00:00.120701\n",
            "Optimization Progress:  82%|████████▏ | 83/101 [00:09<00:02,  6.19it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9898551514967519, 'num_leaves': 85, 'bagging_fraction': 0.5348885469337178, 'min_sum_hessian_in_leaf': 0.004373236968203782, 'reg_alpha': 8.798945140831016e-05, 'reg_lambda': 7.942273087771848e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.9898551514967519, 'num_leaves': 85, 'bagging_fraction': 0.5348885469337178, 'min_sum_hessian_in_leaf': 0.004373236968203782, 'reg_alpha': 8.798945140831016e-05, 'reg_lambda': 7.942273087771848e-07} scored 0.6006944444444444 in 0:00:00.174755\n",
            "Optimization Progress:  83%|████████▎ | 84/101 [00:09<00:03,  5.50it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9324712100253683, 'num_leaves': 96, 'bagging_fraction': 0.5257873469563064, 'min_sum_hessian_in_leaf': 0.005844050033759311, 'reg_alpha': 1.9708508146627605e-05, 'reg_lambda': 1.1924168194065236e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.9324712100253683, 'num_leaves': 96, 'bagging_fraction': 0.5257873469563064, 'min_sum_hessian_in_leaf': 0.005844050033759311, 'reg_alpha': 1.9708508146627605e-05, 'reg_lambda': 1.1924168194065236e-07} scored 0.6145833333333334 in 0:00:00.127406\n",
            "Optimization Progress:  84%|████████▍ | 85/101 [00:10<00:02,  5.57it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.9571715365804392, 'num_leaves': 108, 'bagging_fraction': 0.5923862490090328, 'min_sum_hessian_in_leaf': 0.02070490074736979, 'reg_alpha': 0.00023849141121796614, 'reg_lambda': 4.5071919267358234e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.9571715365804392, 'num_leaves': 108, 'bagging_fraction': 0.5923862490090328, 'min_sum_hessian_in_leaf': 0.02070490074736979, 'reg_alpha': 0.00023849141121796614, 'reg_lambda': 4.5071919267358234e-07} scored 0.5833333333333333 in 0:00:00.164058\n",
            "Optimization Progress:  85%|████████▌ | 86/101 [00:10<00:02,  5.31it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[900]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[707]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.640870391490566, 'num_leaves': 76, 'bagging_fraction': 0.5077697109470044, 'min_sum_hessian_in_leaf': 0.0017534301451742412, 'reg_alpha': 0.00015496410650405544, 'reg_lambda': 1.3804641058807206e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.640870391490566, 'num_leaves': 76, 'bagging_fraction': 0.5077697109470044, 'min_sum_hessian_in_leaf': 0.0017534301451742412, 'reg_alpha': 0.00015496410650405544, 'reg_lambda': 1.3804641058807206e-06} scored 0.5972222222222222 in 0:00:00.328606\n",
            "Optimization Progress:  86%|████████▌ | 87/101 [00:10<00:03,  4.07it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.565972\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.5659722222222222 and parameters: {'feature_fraction': 0.9752774312869913, 'num_leaves': 156, 'bagging_fraction': 0.6154222090873193, 'min_sum_hessian_in_leaf': 0.001234022825554857, 'reg_alpha': 0.0009175332741032825, 'reg_lambda': 0.00012355755173482785}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.9752774312869913, 'num_leaves': 156, 'bagging_fraction': 0.6154222090873193, 'min_sum_hessian_in_leaf': 0.001234022825554857, 'reg_alpha': 0.0009175332741032825, 'reg_lambda': 0.00012355755173482785} scored 0.5659722222222222 in 0:00:00.481329\n",
            "Optimization Progress:  87%|████████▋ | 88/101 [00:11<00:04,  3.01it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8766602592079092, 'num_leaves': 66, 'bagging_fraction': 0.5739923713881478, 'min_sum_hessian_in_leaf': 0.003309515360306084, 'reg_alpha': 0.008041428753565174, 'reg_lambda': 5.273651462582435e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.8766602592079092, 'num_leaves': 66, 'bagging_fraction': 0.5739923713881478, 'min_sum_hessian_in_leaf': 0.003309515360306084, 'reg_alpha': 0.008041428753565174, 'reg_lambda': 5.273651462582435e-08} scored 0.5902777777777778 in 0:00:00.152146\n",
            "Optimization Progress:  88%|████████▊ | 89/101 [00:11<00:03,  3.43it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[264]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7815025327406322, 'num_leaves': 111, 'bagging_fraction': 0.5434682648204652, 'min_sum_hessian_in_leaf': 0.0023097941653223908, 'reg_alpha': 0.00047839433801774627, 'reg_lambda': 2.4457203156475713e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.7815025327406322, 'num_leaves': 111, 'bagging_fraction': 0.5434682648204652, 'min_sum_hessian_in_leaf': 0.0023097941653223908, 'reg_alpha': 0.00047839433801774627, 'reg_lambda': 2.4457203156475713e-07} scored 0.5902777777777778 in 0:00:00.604239\n",
            "Optimization Progress:  89%|████████▉ | 90/101 [00:12<00:04,  2.51it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[26]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9371005410548527, 'num_leaves': 127, 'bagging_fraction': 0.7023250606090462, 'min_sum_hessian_in_leaf': 0.0016716894099636506, 'reg_alpha': 0.004041638788933821, 'reg_lambda': 0.0009541486170814684}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.9371005410548527, 'num_leaves': 127, 'bagging_fraction': 0.7023250606090462, 'min_sum_hessian_in_leaf': 0.0016716894099636506, 'reg_alpha': 0.004041638788933821, 'reg_lambda': 0.0009541486170814684} scored 0.6006944444444444 in 0:00:00.321025\n",
            "Optimization Progress:  90%|█████████ | 91/101 [00:12<00:03,  2.54it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.944462844474678, 'num_leaves': 52, 'bagging_fraction': 0.5194569941235613, 'min_sum_hessian_in_leaf': 0.0020946306766425754, 'reg_alpha': 0.0017019134546921357, 'reg_lambda': 3.0201335726195324e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.944462844474678, 'num_leaves': 52, 'bagging_fraction': 0.5194569941235613, 'min_sum_hessian_in_leaf': 0.0020946306766425754, 'reg_alpha': 0.0017019134546921357, 'reg_lambda': 3.0201335726195324e-08} scored 0.6145833333333334 in 0:00:00.151715\n",
            "Optimization Progress:  91%|█████████ | 92/101 [00:12<00:03,  2.96it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.59375 and parameters: {'feature_fraction': 0.702954339705586, 'num_leaves': 39, 'bagging_fraction': 0.526315239321956, 'min_sum_hessian_in_leaf': 0.0029917223481043505, 'reg_alpha': 0.013721165447761667, 'reg_lambda': 1.6777799726070884e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.702954339705586, 'num_leaves': 39, 'bagging_fraction': 0.526315239321956, 'min_sum_hessian_in_leaf': 0.0029917223481043505, 'reg_alpha': 0.013721165447761667, 'reg_lambda': 1.6777799726070884e-08} scored 0.59375 in 0:00:00.166226\n",
            "Optimization Progress:  92%|█████████▏| 93/101 [00:12<00:02,  3.30it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.90836909876906, 'num_leaves': 58, 'bagging_fraction': 0.5550612247859568, 'min_sum_hessian_in_leaf': 0.0038316916744653567, 'reg_alpha': 0.0009737653075463701, 'reg_lambda': 1.3573127242658214e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.90836909876906, 'num_leaves': 58, 'bagging_fraction': 0.5550612247859568, 'min_sum_hessian_in_leaf': 0.0038316916744653567, 'reg_alpha': 0.0009737653075463701, 'reg_lambda': 1.3573127242658214e-07} scored 0.6006944444444444 in 0:00:00.139717\n",
            "Optimization Progress:  93%|█████████▎| 94/101 [00:13<00:01,  3.70it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9252262400640299, 'num_leaves': 44, 'bagging_fraction': 0.5101889351496826, 'min_sum_hessian_in_leaf': 0.002365064175976263, 'reg_alpha': 0.003135326524899884, 'reg_lambda': 3.796636602720537e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.9252262400640299, 'num_leaves': 44, 'bagging_fraction': 0.5101889351496826, 'min_sum_hessian_in_leaf': 0.002365064175976263, 'reg_alpha': 0.003135326524899884, 'reg_lambda': 3.796636602720537e-08} scored 0.6145833333333334 in 0:00:00.139353\n",
            "Optimization Progress:  94%|█████████▍| 95/101 [00:13<00:01,  4.04it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9603893859149825, 'num_leaves': 35, 'bagging_fraction': 0.5412820810145341, 'min_sum_hessian_in_leaf': 0.00797922127451075, 'reg_alpha': 0.0051155887344284615, 'reg_lambda': 3.886912476716241e-06}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.9603893859149825, 'num_leaves': 35, 'bagging_fraction': 0.5412820810145341, 'min_sum_hessian_in_leaf': 0.00797922127451075, 'reg_alpha': 0.0051155887344284615, 'reg_lambda': 3.886912476716241e-06} scored 0.6006944444444444 in 0:00:00.114931\n",
            "Optimization Progress:  95%|█████████▌| 96/101 [00:13<00:01,  4.54it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9783072886814193, 'num_leaves': 66, 'bagging_fraction': 0.5243614787929631, 'min_sum_hessian_in_leaf': 0.0012065503756931789, 'reg_alpha': 0.0007046500438769085, 'reg_lambda': 1.7490647622902465e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.9783072886814193, 'num_leaves': 66, 'bagging_fraction': 0.5243614787929631, 'min_sum_hessian_in_leaf': 0.0012065503756931789, 'reg_alpha': 0.0007046500438769085, 'reg_lambda': 1.7490647622902465e-08} scored 0.6145833333333334 in 0:00:00.108247\n",
            "Optimization Progress:  96%|█████████▌| 97/101 [00:13<00:00,  5.00it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9495759378997074, 'num_leaves': 71, 'bagging_fraction': 0.5018907652901287, 'min_sum_hessian_in_leaf': 0.036543678834212404, 'reg_alpha': 0.0023107681838588088, 'reg_lambda': 6.010592314516021e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.9495759378997074, 'num_leaves': 71, 'bagging_fraction': 0.5018907652901287, 'min_sum_hessian_in_leaf': 0.036543678834212404, 'reg_alpha': 0.0023107681838588088, 'reg_lambda': 6.010592314516021e-08} scored 0.5902777777777778 in 0:00:00.101844\n",
            "Optimization Progress:  97%|█████████▋| 98/101 [00:13<00:00,  5.56it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.8904873465890221, 'num_leaves': 229, 'bagging_fraction': 0.5589816170342593, 'min_sum_hessian_in_leaf': 0.005309180061201301, 'reg_alpha': 3.2466106147812156e-05, 'reg_lambda': 1.0466334183290597e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.8904873465890221, 'num_leaves': 229, 'bagging_fraction': 0.5589816170342593, 'min_sum_hessian_in_leaf': 0.005309180061201301, 'reg_alpha': 3.2466106147812156e-05, 'reg_lambda': 1.0466334183290597e-08} scored 0.6006944444444444 in 0:00:00.108538\n",
            "Optimization Progress:  98%|█████████▊| 99/101 [00:13<00:00,  5.89it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.8519441714971006, 'num_leaves': 29, 'bagging_fraction': 0.5804686031843174, 'min_sum_hessian_in_leaf': 0.0019493389917361035, 'reg_alpha': 0.008152758094642087, 'reg_lambda': 5.956298187510907e-07}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.8519441714971006, 'num_leaves': 29, 'bagging_fraction': 0.5804686031843174, 'min_sum_hessian_in_leaf': 0.0019493389917361035, 'reg_alpha': 0.008152758094642087, 'reg_lambda': 5.956298187510907e-07} scored 0.5833333333333333 in 0:00:00.104505\n",
            "Optimization Progress:  99%|█████████▉| 100/101 [00:13<00:00,  6.25it/s, best_trial=48, best_value=0.635]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 100 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9394873719724268, 'num_leaves': 90, 'bagging_fraction': 0.5312411477171192, 'min_sum_hessian_in_leaf': 0.0010055766458709951, 'reg_alpha': 0.00019069390776600405, 'reg_lambda': 8.574897361064482e-08}. Best is trial 48 with value: 0.6354166666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 101\u001b[0m with hyperparameters {'feature_fraction': 0.9394873719724268, 'num_leaves': 90, 'bagging_fraction': 0.5312411477171192, 'min_sum_hessian_in_leaf': 0.0010055766458709951, 'reg_alpha': 0.00019069390776600405, 'reg_lambda': 8.574897361064482e-08} scored 0.6006944444444444 in 0:00:00.089929\n",
            "Optimization Progress: 100%|██████████| 101/101 [00:14<00:00,  7.15it/s, best_trial=48, best_value=0.635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:43] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:43] The set of hyperparameters \u001b[1m{'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}\u001b[0m\n",
            " achieve 0.6354 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.9713386595732587, 'num_leaves': 28, 'bagging_fraction': 0.5263780042015709, 'min_sum_hessian_in_leaf': 0.0014715560349285325, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07}\u001b[0m\n",
            " achieve 0.6354 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 28, 'feature_fraction': 0.9713386595732587, 'bagging_fraction': 0.5263780042015709, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 0.005765667774595165, 'reg_lambda': 3.843066912688489e-07, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.0014715560349285325}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:43] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:43] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.566434\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.706294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.863636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.65035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.867133\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.93007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6961495535714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6961495535714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 500, 'learning_rate': 0.02, 'l2_leaf_reg': 0.01, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 5, 'min_data_in_leaf': 1, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 4.32ms\tremaining: 2.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5347222 (84)\ttotal: 115ms\tremaining: 453ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 84\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 85 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5174825\tbest: 0.5174825 (0)\ttotal: 1.18ms\tremaining: 587ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6713287\tbest: 0.7062937 (49)\ttotal: 94.6ms\tremaining: 374ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7062937063\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 49\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 50 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7762238\tbest: 0.7762238 (0)\ttotal: 999us\tremaining: 499ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8111888\tbest: 0.8951049 (8)\ttotal: 95.3ms\tremaining: 377ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8951048951\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 8\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 9 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6503497\tbest: 0.6503497 (0)\ttotal: 1ms\tremaining: 502ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6083916\tbest: 0.6608392 (2)\ttotal: 87ms\tremaining: 344ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6608391608\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:44] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5944056\tbest: 0.5944056 (0)\ttotal: 1.35ms\tremaining: 676ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8881119\tbest: 0.8951049 (10)\ttotal: 110ms\tremaining: 435ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8321678\tbest: 0.9020979 (101)\ttotal: 199ms\tremaining: 297ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9020979021\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 101\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 102 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6544363839285715\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.6544363839285715\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:45] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:26:45] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
            "Optimization Progress:   0%|          | 0/101 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-9e9c6c5d-5e13-4aa4-bad2-93ea4ebb1b9f\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4548611\tbest: 0.4548611 (0)\ttotal: 3.95ms\tremaining: 1.97s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5486111 (64)\ttotal: 90.5ms\tremaining: 358ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.5486111111111112 in 0:00:00.213562\n",
            "Optimization Progress:   1%|          | 1/101 [00:00<00:23,  4.26it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.06ms\tremaining: 530ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4305556\tbest: 0.4791667 (45)\ttotal: 83.1ms\tremaining: 328ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4791666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 45\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 46 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.47916666666666663 and parameters: {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4} scored 0.47916666666666663 in 0:00:00.177904\n",
            "Optimization Progress:   2%|▏         | 2/101 [00:00<00:21,  4.67it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 978us\tremaining: 488ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5416667 (99)\ttotal: 61.2ms\tremaining: 242ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5486111 (110)\ttotal: 128ms\tremaining: 190ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 110\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 111 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13} scored 0.5486111111111112 in 0:00:00.186967\n",
            "Optimization Progress:   3%|▎         | 3/101 [00:00<00:20,  4.77it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.41ms\tremaining: 701ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5208333 (87)\ttotal: 111ms\tremaining: 438ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5347222 (121)\ttotal: 257ms\tremaining: 383ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 121\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 122 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5347222222222222 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20}. Best is trial 0 with value: 0.5486111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20} scored 0.5347222222222222 in 0:00:00.359551\n",
            "Optimization Progress:   4%|▍         | 4/101 [00:01<00:26,  3.64it/s, best_trial=0, best_value=0.549]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 1.88ms\tremaining: 936ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5763889 (5)\ttotal: 143ms\tremaining: 564ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.576388888888889 in 0:00:00.206718\n",
            "Optimization Progress:   5%|▍         | 5/101 [00:01<00:24,  3.90it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 732us\tremaining: 366ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.4861111 (75)\ttotal: 61.9ms\tremaining: 245ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5138889 (155)\ttotal: 123ms\tremaining: 182ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.4722222\tbest: 0.5208333 (221)\ttotal: 188ms\tremaining: 124ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 221\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 222 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.5208333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11} scored 0.5208333333333334 in 0:00:00.264409\n",
            "Optimization Progress:   6%|▌         | 6/101 [00:01<00:25,  3.77it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.08ms\tremaining: 540ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5416667 (77)\ttotal: 90.7ms\tremaining: 358ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5416666666666667 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13}. Best is trial 4 with value: 0.576388888888889.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13} scored 0.5416666666666667 in 0:00:00.221805\n",
            "Optimization Progress:   7%|▋         | 7/101 [00:01<00:24,  3.89it/s, best_trial=4, best_value=0.576]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 875us\tremaining: 437ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.6111111 (39)\ttotal: 64.7ms\tremaining: 256ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5555556\tbest: 0.6180556 (105)\ttotal: 153ms\tremaining: 228ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 105\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 106 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.6180555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8} scored 0.6180555555555556 in 0:00:00.206715\n",
            "Optimization Progress:   8%|▊         | 8/101 [00:01<00:22,  4.06it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 2.29ms\tremaining: 1.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4305556\tbest: 0.4861111 (57)\ttotal: 86.2ms\tremaining: 340ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4861111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.48611111111111116 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4} scored 0.48611111111111116 in 0:00:00.188891\n",
            "Optimization Progress:   9%|▉         | 9/101 [00:02<00:21,  4.29it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.2ms\tremaining: 597ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5138889 (98)\ttotal: 83.6ms\tremaining: 330ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4791667\tbest: 0.5347222 (108)\ttotal: 164ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 108\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 109 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5347222222222222 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.5347222222222222 in 0:00:00.231624\n",
            "Optimization Progress:  10%|▉         | 10/101 [00:02<00:21,  4.18it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 915us\tremaining: 457ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5486111 (100)\ttotal: 56.4ms\tremaining: 223ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5902778 (175)\ttotal: 127ms\tremaining: 189ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 175\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 176 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5902777777777778 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0001819474163917752, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0001819474163917752, 'min_data_in_leaf': 8} scored 0.5902777777777778 in 0:00:00.233827\n",
            "Optimization Progress:  11%|█         | 11/101 [00:02<00:21,  4.12it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 816us\tremaining: 408ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5486111 (73)\ttotal: 54.9ms\tremaining: 217ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 73\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 74 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00046833878978964417, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00046833878978964417, 'min_data_in_leaf': 8} scored 0.5486111111111112 in 0:00:00.165213\n",
            "Optimization Progress:  12%|█▏        | 12/101 [00:02<00:20,  4.45it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.18ms\tremaining: 589ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4722222\tbest: 0.5347222 (19)\ttotal: 88ms\tremaining: 348ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 19\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 20 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5347222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.717362889366975e-05, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.717362889366975e-05, 'min_data_in_leaf': 8} scored 0.5347222222222222 in 0:00:00.170005\n",
            "Optimization Progress:  13%|█▎        | 13/101 [00:03<00:18,  4.66it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 819us\tremaining: 409ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5625000 (76)\ttotal: 66.8ms\tremaining: 264ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5694444 (130)\ttotal: 131ms\tremaining: 195ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5277778\tbest: 0.5763889 (215)\ttotal: 198ms\tremaining: 131ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 215\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 216 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5763888888888888 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.01829657623099352, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.01829657623099352, 'min_data_in_leaf': 8} scored 0.5763888888888888 in 0:00:00.289048\n",
            "Optimization Progress:  14%|█▍        | 14/101 [00:03<00:21,  4.13it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.04ms\tremaining: 522ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4930556\tbest: 0.5694444 (63)\ttotal: 63.4ms\tremaining: 250ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 63\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 64 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 8.113466471626518e-05, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 8.113466471626518e-05, 'min_data_in_leaf': 7} scored 0.5694444444444444 in 0:00:00.166802\n",
            "Optimization Progress:  15%|█▍        | 15/101 [00:03<00:19,  4.45it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.1ms\tremaining: 552ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5763889 (99)\ttotal: 68.9ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5833333 (117)\ttotal: 139ms\tremaining: 207ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 117\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 118 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232927, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232927, 'min_data_in_leaf': 17} scored 0.5833333333333334 in 0:00:00.219707\n",
            "Optimization Progress:  16%|█▌        | 16/101 [00:03<00:19,  4.38it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 899us\tremaining: 449ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5694444 (96)\ttotal: 66.3ms\tremaining: 262ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 96\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 97 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.048696351475407e-08, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.048696351475407e-08, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.202354\n",
            "Optimization Progress:  17%|█▋        | 17/101 [00:04<00:19,  4.35it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.56ms\tremaining: 779ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (99)\ttotal: 112ms\tremaining: 444ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5416667 (115)\ttotal: 216ms\tremaining: 321ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 115\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 116 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5416666666666667 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.957760880550027e-05, 'min_data_in_leaf': 6}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.957760880550027e-05, 'min_data_in_leaf': 6} scored 0.5416666666666667 in 0:00:00.308395\n",
            "Optimization Progress:  18%|█▊        | 18/101 [00:04<00:21,  3.86it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.01ms\tremaining: 505ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (73)\ttotal: 68.6ms\tremaining: 271ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 73\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 74 iterations.\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.2067858697356172e-07, 'min_data_in_leaf': 1}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.2067858697356172e-07, 'min_data_in_leaf': 1} scored 0.5486111111111112 in 0:00:00.175010\n",
            "Optimization Progress:  19%|█▉        | 19/101 [00:04<00:19,  4.18it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 821us\tremaining: 410ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (70)\ttotal: 56ms\tremaining: 221ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5069444\tbest: 0.5277778 (160)\ttotal: 110ms\tremaining: 164ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5069444\tbest: 0.5486111 (250)\ttotal: 166ms\tremaining: 110ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 250\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 251 iterations.\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.548611111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0004246257320120182, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0004246257320120182, 'min_data_in_leaf': 10} scored 0.548611111111111 in 0:00:00.264279\n",
            "Optimization Progress:  20%|█▉        | 20/101 [00:04<00:20,  3.97it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 2.19ms\tremaining: 1.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5763889 (5)\ttotal: 146ms\tremaining: 577ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 6.624697002635038e-06, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 6.624697002635038e-06, 'min_data_in_leaf': 10} scored 0.576388888888889 in 0:00:00.214142\n",
            "Optimization Progress:  21%|██        | 21/101 [00:05<00:19,  4.06it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.18ms\tremaining: 588ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5486111 (76)\ttotal: 83ms\tremaining: 328ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5763889\tbest: 0.5902778 (194)\ttotal: 146ms\tremaining: 217ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 194\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 195 iterations.\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5902777777777777 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.004449106483560384, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.004449106483560384, 'min_data_in_leaf': 18} scored 0.5902777777777777 in 0:00:00.299467\n",
            "Optimization Progress:  22%|██▏       | 22/101 [00:05<00:21,  3.73it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 833us\tremaining: 416ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5625000 (76)\ttotal: 71.8ms\tremaining: 284ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.019640160099654747, 'min_data_in_leaf': 19}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.019640160099654747, 'min_data_in_leaf': 19} scored 0.5625 in 0:00:00.193788\n",
            "Optimization Progress:  23%|██▎       | 23/101 [00:05<00:19,  3.95it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 838us\tremaining: 419ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5972222 (79)\ttotal: 60.5ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 79\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 80 iterations.\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5972222222222223 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.002072889876972783, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.002072889876972783, 'min_data_in_leaf': 14} scored 0.5972222222222223 in 0:00:00.180736\n",
            "Optimization Progress:  24%|██▍       | 24/101 [00:05<00:18,  4.23it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 826us\tremaining: 413ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5625000 (39)\ttotal: 63.5ms\tremaining: 251ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5625 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00016848413978965784, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00016848413978965784, 'min_data_in_leaf': 14} scored 0.5625 in 0:00:00.149661\n",
            "Optimization Progress:  25%|██▍       | 25/101 [00:05<00:16,  4.58it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 804us\tremaining: 401ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6180556 (96)\ttotal: 60.4ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 96\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 97 iterations.\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.6180555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.6440799271560485e-05, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.6440799271560485e-05, 'min_data_in_leaf': 15} scored 0.6180555555555556 in 0:00:00.184108\n",
            "Optimization Progress:  26%|██▌       | 26/101 [00:06<00:16,  4.57it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 833us\tremaining: 416ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4444444\tbest: 0.4791667 (20)\ttotal: 58.1ms\tremaining: 230ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4791666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 20\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 21 iterations.\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.4791666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0515463208746777e-06, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0515463208746777e-06, 'min_data_in_leaf': 15} scored 0.4791666666666667 in 0:00:00.128832\n",
            "Optimization Progress:  27%|██▋       | 27/101 [00:06<00:14,  5.02it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.29ms\tremaining: 642ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5277778 (49)\ttotal: 108ms\tremaining: 426ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5277777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 49\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 50 iterations.\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.5277777777777778 and parameters: {'max_depth': 6, 'l2_leaf_reg': 3.064331282043019e-05, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 3.064331282043019e-05, 'min_data_in_leaf': 16} scored 0.5277777777777778 in 0:00:00.221837\n",
            "Optimization Progress:  28%|██▊       | 28/101 [00:06<00:15,  4.73it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.12ms\tremaining: 558ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6180556 (85)\ttotal: 65.9ms\tremaining: 260ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 85\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 86 iterations.\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.0763729858585045e-07, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.0763729858585045e-07, 'min_data_in_leaf': 12} scored 0.6180555555555556 in 0:00:00.186851\n",
            "Optimization Progress:  29%|██▊       | 29/101 [00:06<00:15,  4.76it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.2ms\tremaining: 1.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5625000 (42)\ttotal: 72.8ms\tremaining: 288ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5347222\tbest: 0.5833333 (183)\ttotal: 143ms\tremaining: 213ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 183\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 184 iterations.\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.165310982087637e-08, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.165310982087637e-08, 'min_data_in_leaf': 12} scored 0.5833333333333333 in 0:00:00.324768\n",
            "Optimization Progress:  30%|██▉       | 30/101 [00:07<00:17,  3.97it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 811us\tremaining: 405ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.5833333 (97)\ttotal: 93.5ms\tremaining: 369ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.5902778 (154)\ttotal: 158ms\tremaining: 235ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 154\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 155 iterations.\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.028612442618824e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.028612442618824e-07, 'min_data_in_leaf': 16} scored 0.5902777777777778 in 0:00:00.263394\n",
            "Optimization Progress:  31%|███       | 31/101 [00:07<00:18,  3.81it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 744us\tremaining: 371ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5486111 (54)\ttotal: 62.3ms\tremaining: 246ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 54\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 55 iterations.\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.83050845790229e-08, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.83050845790229e-08, 'min_data_in_leaf': 14} scored 0.5486111111111112 in 0:00:00.153632\n",
            "Optimization Progress:  32%|███▏      | 32/101 [00:07<00:16,  4.23it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 693us\tremaining: 346ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5833333 (63)\ttotal: 57.5ms\tremaining: 227ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 63\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 64 iterations.\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5833333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.3787541364024313e-05, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.3787541364024313e-05, 'min_data_in_leaf': 12} scored 0.5833333333333334 in 0:00:00.158379\n",
            "Optimization Progress:  33%|███▎      | 33/101 [00:07<00:14,  4.56it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 943us\tremaining: 471ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5416667 (62)\ttotal: 66.5ms\tremaining: 263ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5138889\tbest: 0.5486111 (145)\ttotal: 227ms\tremaining: 338ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 145\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 146 iterations.\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 6.943442953080223, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 6.943442953080223, 'min_data_in_leaf': 15} scored 0.5486111111111112 in 0:00:00.414115\n",
            "Optimization Progress:  34%|███▎      | 34/101 [00:08<00:19,  3.51it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.16ms\tremaining: 577ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4375000\tbest: 0.5069444 (25)\ttotal: 183ms\tremaining: 722ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5069444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3803087778760937e-06, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3803087778760937e-06, 'min_data_in_leaf': 13} scored 0.5069444444444444 in 0:00:00.319480\n",
            "Optimization Progress:  35%|███▍      | 35/101 [00:08<00:19,  3.30it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.32ms\tremaining: 659ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5000000 (74)\ttotal: 212ms\tremaining: 836ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 74\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 75 iterations.\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.9082786134291037e-07, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.9082786134291037e-07, 'min_data_in_leaf': 17} scored 0.5 in 0:00:00.463758\n",
            "Optimization Progress:  36%|███▌      | 36/101 [00:09<00:23,  2.80it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.05ms\tremaining: 1.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5486111 (71)\ttotal: 148ms\tremaining: 585ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 71\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 72 iterations.\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.479872737032061e-08, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.479872737032061e-08, 'min_data_in_leaf': 9} scored 0.5486111111111112 in 0:00:00.340205\n",
            "Optimization Progress:  37%|███▋      | 37/101 [00:09<00:23,  2.76it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4548611\tbest: 0.4548611 (0)\ttotal: 2.34ms\tremaining: 1.17s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5625000 (64)\ttotal: 181ms\tremaining: 717ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.2153025282029422, 'min_data_in_leaf': 12}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.2153025282029422, 'min_data_in_leaf': 12} scored 0.5625 in 0:00:00.407958\n",
            "Optimization Progress:  38%|███▊      | 38/101 [00:09<00:24,  2.61it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.51ms\tremaining: 1.25s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5590278 (5)\ttotal: 189ms\tremaining: 748ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5590277778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.5590277777777777 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.060664273160767e-05, 'min_data_in_leaf': 5}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.060664273160767e-05, 'min_data_in_leaf': 5} scored 0.5590277777777777 in 0:00:00.276085\n",
            "Optimization Progress:  39%|███▊      | 39/101 [00:10<00:22,  2.78it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 4.94ms\tremaining: 2.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5277778 (100)\ttotal: 237ms\tremaining: 937ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5625000 (165)\ttotal: 414ms\tremaining: 616ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 165\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 166 iterations.\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.5625 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0008487932279426703, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0008487932279426703, 'min_data_in_leaf': 14} scored 0.5625 in 0:00:00.679667\n",
            "Optimization Progress:  40%|███▉      | 40/101 [00:10<00:28,  2.15it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 5.89ms\tremaining: 2.94s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4375000\tbest: 0.4722222 (32)\ttotal: 124ms\tremaining: 489ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4722222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 32\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 33 iterations.\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.4722222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.1478050215294242e-08, 'min_data_in_leaf': 20}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.1478050215294242e-08, 'min_data_in_leaf': 20} scored 0.4722222222222222 in 0:00:00.298185\n",
            "Optimization Progress:  41%|████      | 41/101 [00:11<00:25,  2.34it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.84ms\tremaining: 920ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5416667 (17)\ttotal: 148ms\tremaining: 586ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5416666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 17\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 18 iterations.\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.5416666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00013386206224969417, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00013386206224969417, 'min_data_in_leaf': 9} scored 0.5416666666666667 in 0:00:00.250748\n",
            "Optimization Progress:  42%|████▏     | 42/101 [00:11<00:22,  2.61it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.94ms\tremaining: 1.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4930556\tbest: 0.5208333 (91)\ttotal: 201ms\tremaining: 794ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5694444 (125)\ttotal: 280ms\tremaining: 416ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 125\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 126 iterations.\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.304546294989926e-06, 'min_data_in_leaf': 6}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.304546294989926e-06, 'min_data_in_leaf': 6} scored 0.5694444444444444 in 0:00:00.386555\n",
            "Optimization Progress:  43%|████▎     | 43/101 [00:11<00:22,  2.56it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 880us\tremaining: 440ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5555556 (80)\ttotal: 56.1ms\tremaining: 222ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.5694444 (117)\ttotal: 117ms\tremaining: 174ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 117\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 118 iterations.\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.014504522003259024, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.014504522003259024, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.206102\n",
            "Optimization Progress:  44%|████▎     | 44/101 [00:12<00:19,  2.92it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 970us\tremaining: 484ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5347222 (55)\ttotal: 66ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 55\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 56 iterations.\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.5347222222222223 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.001098252087462213, 'min_data_in_leaf': 9}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.001098252087462213, 'min_data_in_leaf': 9} scored 0.5347222222222223 in 0:00:00.173943\n",
            "Optimization Progress:  45%|████▍     | 45/101 [00:12<00:16,  3.32it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 934us\tremaining: 466ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (73)\ttotal: 62.9ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5694444 (128)\ttotal: 120ms\tremaining: 179ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 128\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 129 iterations.\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.5694444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.1115690888055284, 'min_data_in_leaf': 3}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.1115690888055284, 'min_data_in_leaf': 3} scored 0.5694444444444444 in 0:00:00.209861\n",
            "Optimization Progress:  46%|████▌     | 46/101 [00:12<00:15,  3.55it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 959us\tremaining: 479ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4791667\tbest: 0.5347222 (60)\ttotal: 60.7ms\tremaining: 240ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 60\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 61 iterations.\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5347222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0002693040540675074, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0002693040540675074, 'min_data_in_leaf': 7} scored 0.5347222222222222 in 0:00:00.196986\n",
            "Optimization Progress:  47%|████▋     | 47/101 [00:12<00:14,  3.78it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.81ms\tremaining: 906ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5486111 (55)\ttotal: 78.4ms\tremaining: 310ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 55\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 56 iterations.\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.5486111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.736840856541598e-05, 'min_data_in_leaf': 10}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.736840856541598e-05, 'min_data_in_leaf': 10} scored 0.5486111111111112 in 0:00:00.199837\n",
            "Optimization Progress:  48%|████▊     | 48/101 [00:13<00:13,  3.96it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 897us\tremaining: 448ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5069444 (89)\ttotal: 66.2ms\tremaining: 261ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4930556\tbest: 0.5208333 (105)\ttotal: 126ms\tremaining: 187ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 105\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 106 iterations.\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.5208333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8856689692767433e-05, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8856689692767433e-05, 'min_data_in_leaf': 13} scored 0.5208333333333334 in 0:00:00.197955\n",
            "Optimization Progress:  49%|████▊     | 49/101 [00:13<00:12,  4.13it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.33ms\tremaining: 1.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (70)\ttotal: 89.3ms\tremaining: 353ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 70\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 71 iterations.\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.4566674497558887e-06, 'min_data_in_leaf': 7}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.4566674497558887e-06, 'min_data_in_leaf': 7} scored 0.5694444444444444 in 0:00:00.213281\n",
            "Optimization Progress:  50%|████▉     | 50/101 [00:13<00:12,  4.15it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.1ms\tremaining: 551ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (97)\ttotal: 63.6ms\tremaining: 251ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 97\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 98 iterations.\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.5763888888888888 and parameters: {'max_depth': 3, 'l2_leaf_reg': 9.359397200734437e-05, 'min_data_in_leaf': 11}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 9.359397200734437e-05, 'min_data_in_leaf': 11} scored 0.5763888888888888 in 0:00:00.190735\n",
            "Optimization Progress:  50%|█████     | 51/101 [00:13<00:11,  4.28it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 946us\tremaining: 472ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (98)\ttotal: 101ms\tremaining: 399ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5694444\tbest: 0.5833333 (195)\ttotal: 167ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 195\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 196 iterations.\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.239744273560434e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.239744273560434e-07, 'min_data_in_leaf': 16} scored 0.5833333333333334 in 0:00:00.296546\n",
            "Optimization Progress:  51%|█████▏    | 52/101 [00:14<00:12,  3.85it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.26ms\tremaining: 632ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4166667\tbest: 0.4652778 (28)\ttotal: 89.6ms\tremaining: 354ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.4652777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 28\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 29 iterations.\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.4652777777777778 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.223069487676115e-07, 'min_data_in_leaf': 16}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.223069487676115e-07, 'min_data_in_leaf': 16} scored 0.4652777777777778 in 0:00:00.185416\n",
            "Optimization Progress:  52%|█████▏    | 53/101 [00:14<00:11,  4.06it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 951us\tremaining: 475ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5833333 (72)\ttotal: 68.8ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.251254490699665e-08, 'min_data_in_leaf': 17}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.251254490699665e-08, 'min_data_in_leaf': 17} scored 0.5833333333333333 in 0:00:00.179392\n",
            "Optimization Progress:  53%|█████▎    | 54/101 [00:14<00:11,  4.24it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 909us\tremaining: 454ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5069444\tbest: 0.5486111 (76)\ttotal: 59.8ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.548611111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.3717575614526088e-07, 'min_data_in_leaf': 13}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.3717575614526088e-07, 'min_data_in_leaf': 13} scored 0.548611111111111 in 0:00:00.171067\n",
            "Optimization Progress:  54%|█████▍    | 55/101 [00:14<00:10,  4.48it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.3ms\tremaining: 650ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6180556 (64)\ttotal: 68.5ms\tremaining: 271ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 64\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 65 iterations.\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.6207037946608346e-06, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.6207037946608346e-06, 'min_data_in_leaf': 18} scored 0.6180555555555556 in 0:00:00.193772\n",
            "Optimization Progress:  55%|█████▌    | 56/101 [00:14<00:10,  4.42it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.18ms\tremaining: 589ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.4930556 (58)\ttotal: 83.3ms\tremaining: 329ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4722222\tbest: 0.5069444 (126)\ttotal: 165ms\tremaining: 246ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 126\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 127 iterations.\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.5069444444444444 and parameters: {'max_depth': 5, 'l2_leaf_reg': 7.4657927614131616e-06, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 7.4657927614131616e-06, 'min_data_in_leaf': 18} scored 0.5069444444444444 in 0:00:00.262240\n",
            "Optimization Progress:  56%|█████▋    | 57/101 [00:15<00:10,  4.09it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.06ms\tremaining: 530ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5555556 (35)\ttotal: 54ms\tremaining: 213ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5555555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 35\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 36 iterations.\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.5555555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.006336199757406834, 'min_data_in_leaf': 19}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.006336199757406834, 'min_data_in_leaf': 19} scored 0.5555555555555556 in 0:00:00.144024\n",
            "Optimization Progress:  57%|█████▋    | 58/101 [00:15<00:09,  4.49it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 1.52ms\tremaining: 761ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5555556\tbest: 0.5763889 (95)\ttotal: 402ms\tremaining: 1.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 95\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 96 iterations.\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.5763888888888888 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.8637224103840083e-05, 'min_data_in_leaf': 8}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.8637224103840083e-05, 'min_data_in_leaf': 8} scored 0.5763888888888888 in 0:00:00.823357\n",
            "Optimization Progress:  58%|█████▊    | 59/101 [00:16<00:17,  2.40it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 4.16ms\tremaining: 2.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.5069444 (23)\ttotal: 274ms\tremaining: 1.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 23\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 24 iterations.\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.5069444444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.642994664261131e-06, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.642994664261131e-06, 'min_data_in_leaf': 15} scored 0.5069444444444444 in 0:00:00.437740\n",
            "Optimization Progress:  59%|█████▉    | 60/101 [00:16<00:17,  2.29it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 4.13ms\tremaining: 2.06s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5000000 (98)\ttotal: 229ms\tremaining: 905ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5208333 (189)\ttotal: 445ms\tremaining: 662ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.5208333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0008387488569813798, 'min_data_in_leaf': 14}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0008387488569813798, 'min_data_in_leaf': 14} scored 0.5208333333333333 in 0:00:00.858105\n",
            "Optimization Progress:  60%|██████    | 61/101 [00:17<00:23,  1.69it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 5.1ms\tremaining: 2.55s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5625000 (92)\ttotal: 384ms\tremaining: 1.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5833333 (114)\ttotal: 605ms\tremaining: 900ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 114\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 115 iterations.\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.317363648396127e-07, 'min_data_in_leaf': 18}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.317363648396127e-07, 'min_data_in_leaf': 18} scored 0.5833333333333333 in 0:00:00.902489\n",
            "Optimization Progress:  61%|██████▏   | 62/101 [00:18<00:27,  1.43it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 958us\tremaining: 478ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5416667 (42)\ttotal: 87.2ms\tremaining: 344ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5208333\tbest: 0.5486111 (129)\ttotal: 196ms\tremaining: 292ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 129\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 130 iterations.\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.548611111111111 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.6361639172041583e-07, 'min_data_in_leaf': 15}. Best is trial 7 with value: 0.6180555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.6361639172041583e-07, 'min_data_in_leaf': 15} scored 0.548611111111111 in 0:00:00.410073\n",
            "Optimization Progress:  62%|██████▏   | 63/101 [00:19<00:23,  1.60it/s, best_trial=7, best_value=0.618]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 4.16ms\tremaining: 2.08s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5277778 (97)\ttotal: 216ms\tremaining: 855ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.6180556\tbest: 0.6250000 (196)\ttotal: 410ms\tremaining: 610ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 196\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 197 iterations.\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12} scored 0.625 in 0:00:00.807368\n",
            "Optimization Progress:  63%|██████▎   | 64/101 [00:19<00:26,  1.41it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4756944\tbest: 0.4756944 (0)\ttotal: 5.58ms\tremaining: 2.78s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5763889 (5)\ttotal: 366ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.576388888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 6.1637636876381684e-06, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 6.1637636876381684e-06, 'min_data_in_leaf': 12} scored 0.576388888888889 in 0:00:00.492489\n",
            "Optimization Progress:  64%|██████▍   | 65/101 [00:20<00:23,  1.52it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.15ms\tremaining: 575ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4652778\tbest: 0.4861111 (49)\ttotal: 138ms\tremaining: 547ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5138889 (148)\ttotal: 316ms\tremaining: 470ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5138888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 148\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 149 iterations.\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.5138888888888888 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.00027545242428155925, 'min_data_in_leaf': 10}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.00027545242428155925, 'min_data_in_leaf': 10} scored 0.5138888888888888 in 0:00:00.529400\n",
            "Optimization Progress:  65%|██████▌   | 66/101 [00:21<00:21,  1.59it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.28ms\tremaining: 1.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (84)\ttotal: 212ms\tremaining: 838ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 84\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 85 iterations.\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.5347222222222222 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.001566845101489e-05, 'min_data_in_leaf': 11}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.001566845101489e-05, 'min_data_in_leaf': 11} scored 0.5347222222222222 in 0:00:00.429499\n",
            "Optimization Progress:  66%|██████▋   | 67/101 [00:21<00:19,  1.72it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.31ms\tremaining: 656ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (89)\ttotal: 189ms\tremaining: 746ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 89\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 90 iterations.\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.844924355846328e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.844924355846328e-06, 'min_data_in_leaf': 13} scored 0.5694444444444444 in 0:00:00.441272\n",
            "Optimization Progress:  67%|██████▋   | 68/101 [00:22<00:18,  1.78it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 1.93ms\tremaining: 962ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5729167 (9)\ttotal: 208ms\tremaining: 820ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5729166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 9\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 10 iterations.\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.5729166666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.34064337539196e-05, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.34064337539196e-05, 'min_data_in_leaf': 12} scored 0.5729166666666667 in 0:00:00.391498\n",
            "Optimization Progress:  68%|██████▊   | 69/101 [00:22<00:16,  1.92it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4131944\tbest: 0.4131944 (0)\ttotal: 2.85ms\tremaining: 1.42s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5486111 (47)\ttotal: 174ms\tremaining: 688ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5486111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 47\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 48 iterations.\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.5486111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.7171647319410317e-06, 'min_data_in_leaf': 9}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.7171647319410317e-06, 'min_data_in_leaf': 9} scored 0.5486111111111112 in 0:00:00.386944\n",
            "Optimization Progress:  69%|██████▉   | 70/101 [00:22<00:15,  2.00it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 9.01ms\tremaining: 4.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4652778\tbest: 0.5069444 (44)\ttotal: 388ms\tremaining: 1.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5069444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 44\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 45 iterations.\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.5069444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.002400027668327387, 'min_data_in_leaf': 7}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.002400027668327387, 'min_data_in_leaf': 7} scored 0.5069444444444444 in 0:00:00.906614\n",
            "Optimization Progress:  70%|███████   | 71/101 [00:23<00:19,  1.52it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 7.29ms\tremaining: 3.64s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5972222\tbest: 0.6111111 (90)\ttotal: 310ms\tremaining: 1.22s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6111111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 90\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 91 iterations.\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.6111111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 6.805150867029861e-07, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 6.805150867029861e-07, 'min_data_in_leaf': 16} scored 0.6111111111111112 in 0:00:00.994579\n",
            "Optimization Progress:  71%|███████▏  | 72/101 [00:24<00:22,  1.28it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 8.5ms\tremaining: 4.24s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.5902778 (72)\ttotal: 339ms\tremaining: 1.34s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 72\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 73 iterations.\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.667701988822335e-07, 'min_data_in_leaf': 19}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.667701988822335e-07, 'min_data_in_leaf': 19} scored 0.5902777777777778 in 0:00:00.905179\n",
            "Optimization Progress:  72%|███████▏  | 73/101 [00:26<00:23,  1.18it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 1.01ms\tremaining: 505ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5694444 (75)\ttotal: 116ms\tremaining: 459ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5416667\tbest: 0.6180556 (128)\ttotal: 306ms\tremaining: 456ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 128\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 129 iterations.\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.1441050927438204e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.1441050927438204e-08, 'min_data_in_leaf': 16} scored 0.6180555555555556 in 0:00:00.649691\n",
            "Optimization Progress:  73%|███████▎  | 74/101 [00:26<00:21,  1.24it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 812us\tremaining: 405ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5555556 (42)\ttotal: 101ms\tremaining: 399ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4861111\tbest: 0.5833333 (136)\ttotal: 183ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 136\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 137 iterations.\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.5833333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.8421318339824555e-08, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.8421318339824555e-08, 'min_data_in_leaf': 17} scored 0.5833333333333333 in 0:00:00.367256\n",
            "Optimization Progress:  74%|███████▍  | 75/101 [00:27<00:17,  1.44it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.02ms\tremaining: 508ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5972222 (82)\ttotal: 132ms\tremaining: 520ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 82\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 83 iterations.\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.116920803564204e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.116920803564204e-08, 'min_data_in_leaf': 14} scored 0.5972222222222222 in 0:00:00.308345\n",
            "Optimization Progress:  75%|███████▌  | 76/101 [00:27<00:14,  1.69it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 3.54ms\tremaining: 1.77s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5208333 (95)\ttotal: 288ms\tremaining: 1.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5555556 (189)\ttotal: 467ms\tremaining: 695ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5555555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 189\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 190 iterations.\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.5555555555555556 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.1697279504247739e-07, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.1697279504247739e-07, 'min_data_in_leaf': 17} scored 0.5555555555555556 in 0:00:00.787619\n",
            "Optimization Progress:  76%|███████▌  | 77/101 [00:28<00:15,  1.51it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 2.32ms\tremaining: 1.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5763889\tbest: 0.5833333 (87)\ttotal: 218ms\tremaining: 863ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5833333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 87\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 88 iterations.\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.5833333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.977701255482796e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.977701255482796e-07, 'min_data_in_leaf': 15} scored 0.5833333333333334 in 0:00:00.476651\n",
            "Optimization Progress:  77%|███████▋  | 78/101 [00:28<00:14,  1.62it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 1.16ms\tremaining: 577ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5694444 (82)\ttotal: 212ms\tremaining: 839ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.5902778 (156)\ttotal: 401ms\tremaining: 596ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:300:\ttest: 0.5625000\tbest: 0.5972222 (209)\ttotal: 537ms\tremaining: 355ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 209\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 210 iterations.\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.448373772204557e-06, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.448373772204557e-06, 'min_data_in_leaf': 16} scored 0.5972222222222222 in 0:00:00.715723\n",
            "Optimization Progress:  78%|███████▊  | 79/101 [00:29<00:14,  1.51it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 945us\tremaining: 472ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5902778 (78)\ttotal: 209ms\tremaining: 825ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 78\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 79 iterations.\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.8199845684305906e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.8199845684305906e-08, 'min_data_in_leaf': 14} scored 0.5902777777777778 in 0:00:00.563091\n",
            "Optimization Progress:  79%|███████▉  | 80/101 [00:30<00:13,  1.54it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 3.52ms\tremaining: 1.76s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4236111\tbest: 0.4722222 (86)\ttotal: 276ms\tremaining: 1.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.4722222\tbest: 0.5277778 (143)\ttotal: 441ms\tremaining: 655ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5277777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 143\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 144 iterations.\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.5277777777777778 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.6803933477827973e-07, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.6803933477827973e-07, 'min_data_in_leaf': 16} scored 0.5277777777777778 in 0:00:00.655068\n",
            "Optimization Progress:  80%|████████  | 81/101 [00:30<00:13,  1.51it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.2ms\tremaining: 597ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5625000 (42)\ttotal: 154ms\tremaining: 608ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5555556\tbest: 0.5763889 (181)\ttotal: 355ms\tremaining: 529ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 181\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 182 iterations.\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.5763888888888888 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.1128499596008148e-08, 'min_data_in_leaf': 14}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.1128499596008148e-08, 'min_data_in_leaf': 14} scored 0.5763888888888888 in 0:00:00.614672\n",
            "Optimization Progress:  81%|████████  | 82/101 [00:31<00:12,  1.52it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.57ms\tremaining: 1.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6041667 (87)\ttotal: 176ms\tremaining: 694ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5972222\tbest: 0.6180556 (141)\ttotal: 251ms\tremaining: 373ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 141\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 142 iterations.\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.574068519593644e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.574068519593644e-08, 'min_data_in_leaf': 15} scored 0.6180555555555556 in 0:00:00.405852\n",
            "Optimization Progress:  82%|████████▏ | 83/101 [00:31<00:10,  1.69it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.13ms\tremaining: 563ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5902778 (78)\ttotal: 102ms\tremaining: 403ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5902777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 78\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 79 iterations.\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.5902777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 7.437174719026668e-08, 'min_data_in_leaf': 18}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 7.437174719026668e-08, 'min_data_in_leaf': 18} scored 0.5902777777777778 in 0:00:00.246696\n",
            "Optimization Progress:  83%|████████▎ | 84/101 [00:32<00:08,  2.01it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 736us\tremaining: 368ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5833333\tbest: 0.6041667 (91)\ttotal: 72.5ms\tremaining: 286ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6041666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 91\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 92 iterations.\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.6041666666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.1476176404251933e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.1476176404251933e-08, 'min_data_in_leaf': 15} scored 0.6041666666666667 in 0:00:00.214504\n",
            "Optimization Progress:  84%|████████▍ | 85/101 [00:32<00:06,  2.37it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.3ms\tremaining: 1.15s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5902778\tbest: 0.6111111 (82)\ttotal: 75.9ms\tremaining: 300ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6111111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 82\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 83 iterations.\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.6111111111111112 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.2999033009059871e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.2999033009059871e-08, 'min_data_in_leaf': 15} scored 0.6111111111111112 in 0:00:00.206245\n",
            "Optimization Progress:  85%|████████▌ | 86/101 [00:32<00:05,  2.73it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.57ms\tremaining: 1.28s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5833333\tbest: 0.6041667 (91)\ttotal: 80.3ms\tremaining: 317ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6041666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 91\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 92 iterations.\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.6041666666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.744686386739921e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.744686386739921e-08, 'min_data_in_leaf': 16} scored 0.6041666666666667 in 0:00:00.226060\n",
            "Optimization Progress:  86%|████████▌ | 87/101 [00:33<00:04,  3.01it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 3.8ms\tremaining: 1.9s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5416667\tbest: 0.5694444 (50)\ttotal: 87.1ms\tremaining: 344ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 50\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 51 iterations.\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.8060535383640392e-08, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.8060535383640392e-08, 'min_data_in_leaf': 17} scored 0.5694444444444444 in 0:00:00.219410\n",
            "Optimization Progress:  87%|████████▋ | 88/101 [00:33<00:03,  3.25it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.3229167\tbest: 0.3229167 (0)\ttotal: 2.12ms\tremaining: 1.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (99)\ttotal: 108ms\tremaining: 428ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5208333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 99\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 100 iterations.\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.5208333333333334 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.0740346901859193e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.0740346901859193e-07, 'min_data_in_leaf': 15} scored 0.5208333333333334 in 0:00:00.299417\n",
            "Optimization Progress:  88%|████████▊ | 89/101 [00:33<00:03,  3.17it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 2.71ms\tremaining: 1.35s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5000000\tbest: 0.5694444 (42)\ttotal: 76.1ms\tremaining: 301ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.0479205155504866e-08, 'min_data_in_leaf': 18}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.0479205155504866e-08, 'min_data_in_leaf': 18} scored 0.5694444444444444 in 0:00:00.184044\n",
            "Optimization Progress:  89%|████████▉ | 90/101 [00:33<00:03,  3.40it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 1.48ms\tremaining: 739ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5208333\tbest: 0.5347222 (50)\ttotal: 89.3ms\tremaining: 353ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5347222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 50\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 51 iterations.\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.5347222222222222 and parameters: {'max_depth': 5, 'l2_leaf_reg': 5.649228140702103e-07, 'min_data_in_leaf': 20}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 5.649228140702103e-07, 'min_data_in_leaf': 20} scored 0.5347222222222222 in 0:00:00.226056\n",
            "Optimization Progress:  90%|█████████ | 91/101 [00:34<00:02,  3.52it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 981us\tremaining: 490ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6041667\tbest: 0.6180556 (85)\ttotal: 97.4ms\tremaining: 385ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5625000\tbest: 0.6250000 (119)\ttotal: 191ms\tremaining: 284ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 119\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 120 iterations.\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.8885898763563533e-08, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.8885898763563533e-08, 'min_data_in_leaf': 15} scored 0.625 in 0:00:00.301382\n",
            "Optimization Progress:  91%|█████████ | 92/101 [00:34<00:02,  3.31it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 987us\tremaining: 493ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5763889 (99)\ttotal: 70.3ms\tremaining: 278ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5833333\tbest: 0.5972222 (172)\ttotal: 142ms\tremaining: 212ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 172\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 173 iterations.\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 5.480675299713325e-08, 'min_data_in_leaf': 16}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 5.480675299713325e-08, 'min_data_in_leaf': 16} scored 0.5972222222222222 in 0:00:00.270988\n",
            "Optimization Progress:  92%|█████████▏| 93/101 [00:34<00:02,  3.31it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 4.01ms\tremaining: 2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5486111\tbest: 0.5694444 (42)\ttotal: 82.1ms\tremaining: 324ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5069444\tbest: 0.5972222 (136)\ttotal: 155ms\tremaining: 231ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 136\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 137 iterations.\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.5972222222222222 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.10820206142718e-08, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.10820206142718e-08, 'min_data_in_leaf': 13} scored 0.5972222222222222 in 0:00:00.256731\n",
            "Optimization Progress:  93%|█████████▎| 94/101 [00:35<00:02,  3.34it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 993us\tremaining: 496ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5625000 (76)\ttotal: 70ms\tremaining: 277ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 76\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 77 iterations.\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.2143622277119386e-07, 'min_data_in_leaf': 15}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.2143622277119386e-07, 'min_data_in_leaf': 15} scored 0.5625 in 0:00:00.202359\n",
            "Optimization Progress:  94%|█████████▍| 95/101 [00:35<00:01,  3.53it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 927us\tremaining: 463ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5625000\tbest: 0.5763889 (88)\ttotal: 66.7ms\tremaining: 263ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5763888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 88\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 89 iterations.\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.576388888888889 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.901833163080404e-07, 'min_data_in_leaf': 17}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.901833163080404e-07, 'min_data_in_leaf': 17} scored 0.576388888888889 in 0:00:00.210960\n",
            "Optimization Progress:  95%|█████████▌| 96/101 [00:35<00:01,  3.68it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 1.01ms\tremaining: 505ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5277778\tbest: 0.5625000 (61)\ttotal: 76ms\tremaining: 300ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 61\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 62 iterations.\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.5625 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.5216990754596996e-08, 'min_data_in_leaf': 12}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.5216990754596996e-08, 'min_data_in_leaf': 12} scored 0.5625 in 0:00:00.208886\n",
            "Optimization Progress:  96%|█████████▌| 97/101 [00:35<00:01,  3.78it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 781us\tremaining: 390ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6041667\tbest: 0.6180556 (75)\ttotal: 86.5ms\tremaining: 342ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6180555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 75\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 76 iterations.\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.6180555555555556 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.6151948215737286e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.6151948215737286e-06, 'min_data_in_leaf': 13} scored 0.6180555555555556 in 0:00:00.224211\n",
            "Optimization Progress:  97%|█████████▋| 98/101 [00:36<00:00,  3.81it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4340278\tbest: 0.4340278 (0)\ttotal: 801us\tremaining: 400ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.4583333\tbest: 0.5104167 (2)\ttotal: 68.9ms\tremaining: 272ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5104166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 2\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 3 iterations.\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.5104166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 8.854786417113306e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 8.854786417113306e-06, 'min_data_in_leaf': 13} scored 0.5104166666666666 in 0:00:00.153167\n",
            "Optimization Progress:  98%|█████████▊| 99/101 [00:36<00:00,  4.13it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4409722\tbest: 0.4409722 (0)\ttotal: 4.28ms\tremaining: 2.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5347222\tbest: 0.5694444 (51)\ttotal: 298ms\tremaining: 1.18s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 51\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 52 iterations.\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.5694444444444444 and parameters: {'max_depth': 5, 'l2_leaf_reg': 3.3114310738937567e-06, 'min_data_in_leaf': 11}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 3.3114310738937567e-06, 'min_data_in_leaf': 11} scored 0.5694444444444444 in 0:00:00.527144\n",
            "Optimization Progress:  99%|█████████▉| 100/101 [00:36<00:00,  2.94it/s, best_trial=63, best_value=0.625]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4618056\tbest: 0.4618056 (0)\ttotal: 1.52ms\tremaining: 758ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5138889\tbest: 0.5208333 (64)\ttotal: 221ms\tremaining: 872ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.5486111\tbest: 0.5694444 (155)\ttotal: 414ms\tremaining: 615ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5694444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 155\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 156 iterations.\n",
            "INFO:optuna.study.study:Trial 100 finished with value: 0.5694444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.969115740725118e-06, 'min_data_in_leaf': 13}. Best is trial 63 with value: 0.625.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 101\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.969115740725118e-06, 'min_data_in_leaf': 13} scored 0.5694444444444444 in 0:00:00.621436\n",
            "Optimization Progress: 100%|██████████| 101/101 [00:37<00:00,  2.70it/s, best_trial=63, best_value=0.625]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:22] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:22] The set of hyperparameters \u001b[1m{'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}\u001b[0m\n",
            " achieve 0.6250 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 4, 'l2_leaf_reg': 5.347108898782771e-06, 'min_data_in_leaf': 12}\u001b[0m\n",
            " achieve 0.6250 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 5.347108898782771e-06, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 4, 'min_data_in_leaf': 12, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:22] ===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4479167\tbest: 0.4479167 (0)\ttotal: 4.43ms\tremaining: 13.3s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5694444\tbest: 0.5972222 (77)\ttotal: 214ms\tremaining: 6.14s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.5972222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:23] ===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5104895\tbest: 0.5104895 (0)\ttotal: 927us\tremaining: 2.78s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7202797\tbest: 0.8741259 (33)\ttotal: 100ms\tremaining: 2.88s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8741258741\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 33\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 34 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:23] ===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8006993\tbest: 0.8006993 (0)\ttotal: 3.48ms\tremaining: 10.4s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7622378\tbest: 0.8321678 (5)\ttotal: 220ms\tremaining: 6.32s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8321678322\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:23] ===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6503497\tbest: 0.6503497 (0)\ttotal: 3.25ms\tremaining: 9.74s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6433566\tbest: 0.7202797 (3)\ttotal: 210ms\tremaining: 6.02s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7202797203\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 3\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 4 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:23] ===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6013986\tbest: 0.6013986 (0)\ttotal: 1.33ms\tremaining: 3.98s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8461538\tbest: 0.8741259 (73)\ttotal: 204ms\tremaining: 5.87s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8461538\tbest: 0.8951049 (169)\ttotal: 325ms\tremaining: 4.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8951048951\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 169\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 170 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7366071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7366071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Time left 529.68 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 529.68 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Blending: optimization starts with equal weights. Score = \u001b[1m0.7123326\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.7123326\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7385603\u001b[0m, weights = \u001b[1m[0.41398153 0.06656854 0.14960875 0.         0.3698412 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7385603\u001b[0m, weights = \u001b[1m[0.41398153 0.06656854 0.14960875 0.         0.3698412 ]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7424665\u001b[0m, weights = \u001b[1m[0.46047238 0.         0.15539142 0.         0.38413626]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7424665\u001b[0m, weights = \u001b[1m[0.46047238 0.         0.15539142 0.         0.38413626]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:24] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7430246\u001b[0m, weights = \u001b[1m[0.5419463  0.         0.09016994 0.         0.36788374]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7430246\u001b[0m, weights = \u001b[1m[0.5419463  0.         0.09016994 0.         0.36788374]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7449777\u001b[0m, weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7449777\u001b[0m, weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Blending: best score = \u001b[1m0.7449777\u001b[0m, best weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.7449777\u001b[0m, best weights = \u001b[1m[0.6163315  0.         0.07662547 0.         0.30704305]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] \u001b[1mAutoml preset training completed in 71.23 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 71.23 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.61633 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07663 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.30704 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.61633 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.07663 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
            "\t 0.30704 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA Default] ROC-AUC: 0.7217 F1: 0.6557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конфигурация 2 — FAST, только lgbm\n",
        "Используем только быстрый LightGBM."
      ],
      "metadata": {
        "id": "k4VBQjtooR7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl2 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=300,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['lgb']]\n",
        "    }\n",
        ")\n",
        "oof_pred2 = automl2.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred2 = automl2.predict(test_LAMA)\n",
        "\n",
        "auc2 = roc_auc_score(y_test, test_pred2.data[:, 0])\n",
        "f1_2 = f1_score(y_test, test_pred2.data[:, 0] > 0.5)\n",
        "print(f'[LAMA FAST (lgb only)] ROC-AUC: {auc2:.4f}  F1: {f1_2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZBHF2-6mOe0",
        "outputId": "0ada393b-9bc9-43a5-a409-37ad06fc90f1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] - time: 300.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 300.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:25] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:26] Layer \u001b[1m1\u001b[0m train process start. Time left 299.46 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 299.46 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:26] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.01, 'num_leaves': 16, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 200, 'random_state': 42, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[198]\tvalid's auc: 0.576389\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.727273\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.734266\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.800699\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.797203\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.811189\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.825175\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.611888\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625874\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[4]\tvalid's auc: 0.65035\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.86014\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.818182\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.867133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:27] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.6541573660714286\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] \u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Time left 297.68 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 297.68 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] \u001b[1mAutoml preset training completed in 2.33 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 2.33 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA FAST (lgb only)] ROC-AUC: 0.7138  F1: 0.6552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Конфигурация 3 - расширенный набор моделей и мощный автотюнинг\n",
        "\n",
        "Включаем сразу несколько ансамблей (XGB, LGBM с тюнингом, CatBoost с тюнингом, MLP нейросеть) + используем продвинутую кросс-валидацию, автотюнинг с разными алгоритмами"
      ],
      "metadata": {
        "id": "5J50gDVcpMiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl3 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['xgb', 'lgb_tuned', 'cb_tuned'], ['mlp']],  # Много моделей\n",
        "    },\n",
        "    reader_params={\n",
        "        'n_jobs': 2,\n",
        "        'cv': 5,\n",
        "        'random_state': 84,\n",
        "        'advanced_roles': True,\n",
        "    },\n",
        "    tuning_params={'max_tuning_iter': \"auto\", 'max_tuning_time': 300},\n",
        "    selection_params={'mode': 1}\n",
        ")\n",
        "\n",
        "oof_pred3 = automl3.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred3 = automl3.predict(test_LAMA)\n",
        "\n",
        "auc3 = roc_auc_score(y_test, test_pred3.data[:, 0])\n",
        "f1_3 = f1_score(y_test, test_pred3.data[:, 0] > 0.5)\n",
        "print(f'[LAMA Advanced] ROC-AUC: {auc3:.4f}  F1: {f1_3:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD1_Hxw4pKrr",
        "outputId": "f36deeeb-f920-4d31-9e1b-7c8b98c3a3ca"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Layer \u001b[1m1\u001b[0m train process start. Time left 599.69 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 599.69 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.784722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.784722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:28] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 83.76 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 83.76 secs\n",
            "Optimization Progress:   0%|          | 0/100 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-c32d1f06-37c0-4b53-97bc-4bb1e40055f4\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125}. Best is trial 0 with value: 0.7916666666666666.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125} scored 0.7916666666666666 in 0:00:00.142699\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:16,  5.93it/s, best_trial=0, best_value=0.792]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.708333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.805556\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.8055555555555556 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547} scored 0.8055555555555556 in 0:00:00.065724\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:16,  5.93it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.680556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.680556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[211]\tvalid's auc: 0.680556\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.6805555555555556 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009} scored 0.6805555555555556 in 0:00:00.185428\n",
            "Optimization Progress:   3%|▎         | 3/100 [00:00<00:14,  6.55it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[7]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.7777777777777778 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254} scored 0.7777777777777778 in 0:00:00.082090\n",
            "Optimization Progress:   4%|▍         | 4/100 [00:00<00:13,  7.31it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.7777777777777777 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957} scored 0.7777777777777777 in 0:00:00.137490\n",
            "Optimization Progress:   5%|▌         | 5/100 [00:00<00:13,  6.92it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112} scored 0.7847222222222223 in 0:00:00.079731\n",
            "Optimization Progress:   6%|▌         | 6/100 [00:00<00:12,  7.53it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.736111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[27]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326} scored 0.7743055555555556 in 0:00:00.094402\n",
            "Optimization Progress:   7%|▋         | 7/100 [00:00<00:12,  7.73it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.7743055555555555 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573}. Best is trial 1 with value: 0.8055555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573} scored 0.7743055555555555 in 0:00:00.094918\n",
            "Optimization Progress:   8%|▊         | 8/100 [00:01<00:11,  7.93it/s, best_trial=1, best_value=0.806]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988}. Best is trial 8 with value: 0.8680555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988} scored 0.8680555555555556 in 0:00:00.182510\n",
            "Optimization Progress:   9%|▉         | 9/100 [00:01<00:13,  6.56it/s, best_trial=8, best_value=0.868]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.826389\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.8263888888888891 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026}. Best is trial 8 with value: 0.8680555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026} scored 0.8263888888888891 in 0:00:00.089746\n",
            "Optimization Progress:  10%|█         | 10/100 [00:01<00:12,  7.08it/s, best_trial=8, best_value=0.868]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655} scored 0.8784722222222222 in 0:00:00.153641\n",
            "Optimization Progress:  11%|█         | 11/100 [00:01<00:13,  6.48it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5072704375811822, 'num_leaves': 112, 'bagging_fraction': 0.993551055264076, 'min_sum_hessian_in_leaf': 1.1073203961638332}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.5072704375811822, 'num_leaves': 112, 'bagging_fraction': 0.993551055264076, 'min_sum_hessian_in_leaf': 1.1073203961638332} scored 0.8784722222222222 in 0:00:00.179743\n",
            "Optimization Progress:  12%|█▏        | 12/100 [00:01<00:14,  5.96it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.5171787317943728, 'num_leaves': 107, 'bagging_fraction': 0.9979227931587143, 'min_sum_hessian_in_leaf': 0.5223599678552181}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.5171787317943728, 'num_leaves': 107, 'bagging_fraction': 0.9979227931587143, 'min_sum_hessian_in_leaf': 0.5223599678552181} scored 0.8645833333333334 in 0:00:00.228557\n",
            "Optimization Progress:  13%|█▎        | 13/100 [00:02<00:16,  5.21it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[86]\tvalid's auc: 0.826389\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.8263888888888888 and parameters: {'feature_fraction': 0.5877549579666643, 'num_leaves': 115, 'bagging_fraction': 0.9289315257325599, 'min_sum_hessian_in_leaf': 0.7984384465398439}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.5877549579666643, 'num_leaves': 115, 'bagging_fraction': 0.9289315257325599, 'min_sum_hessian_in_leaf': 0.7984384465398439} scored 0.8263888888888888 in 0:00:00.236701\n",
            "Optimization Progress:  14%|█▍        | 14/100 [00:02<00:18,  4.67it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.784722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5054066048641503, 'num_leaves': 154, 'bagging_fraction': 0.9162640577515773, 'min_sum_hessian_in_leaf': 5.6029779996253355}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.5054066048641503, 'num_leaves': 154, 'bagging_fraction': 0.9162640577515773, 'min_sum_hessian_in_leaf': 5.6029779996253355} scored 0.8194444444444444 in 0:00:00.109516\n",
            "Optimization Progress:  15%|█▌        | 15/100 [00:02<00:16,  5.21it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.84375\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.84375 and parameters: {'feature_fraction': 0.9559583616089686, 'num_leaves': 88, 'bagging_fraction': 0.7587239087930508, 'min_sum_hessian_in_leaf': 0.40806072881474936}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.9559583616089686, 'num_leaves': 88, 'bagging_fraction': 0.7587239087930508, 'min_sum_hessian_in_leaf': 0.40806072881474936} scored 0.84375 in 0:00:00.227381\n",
            "Optimization Progress:  16%|█▌        | 16/100 [00:02<00:17,  4.75it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[88]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5913239750713354, 'num_leaves': 158, 'bagging_fraction': 0.926364376824244, 'min_sum_hessian_in_leaf': 1.5599854273107514}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.5913239750713354, 'num_leaves': 158, 'bagging_fraction': 0.926364376824244, 'min_sum_hessian_in_leaf': 1.5599854273107514} scored 0.8194444444444444 in 0:00:00.271733\n",
            "Optimization Progress:  17%|█▋        | 17/100 [00:02<00:19,  4.21it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5662238736103287, 'num_leaves': 89, 'bagging_fraction': 0.9996812193207756, 'min_sum_hessian_in_leaf': 0.163517101800661}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.5662238736103287, 'num_leaves': 89, 'bagging_fraction': 0.9996812193207756, 'min_sum_hessian_in_leaf': 0.163517101800661} scored 0.8715277777777778 in 0:00:00.118855\n",
            "Optimization Progress:  18%|█▊        | 18/100 [00:03<00:17,  4.73it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[76]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.798611111111111 and parameters: {'feature_fraction': 0.631402704879503, 'num_leaves': 121, 'bagging_fraction': 0.8926633901832717, 'min_sum_hessian_in_leaf': 0.8914606849331738}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.631402704879503, 'num_leaves': 121, 'bagging_fraction': 0.8926633901832717, 'min_sum_hessian_in_leaf': 0.8914606849331738} scored 0.798611111111111 in 0:00:00.115400\n",
            "Optimization Progress:  19%|█▉        | 19/100 [00:03<00:15,  5.22it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.8649174147658507, 'num_leaves': 173, 'bagging_fraction': 0.8226906749996505, 'min_sum_hessian_in_leaf': 3.2995575446337932}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.8649174147658507, 'num_leaves': 173, 'bagging_fraction': 0.8226906749996505, 'min_sum_hessian_in_leaf': 3.2995575446337932} scored 0.7847222222222223 in 0:00:00.127800\n",
            "Optimization Progress:  20%|██        | 20/100 [00:03<00:14,  5.52it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.836806\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.7067070498463563, 'num_leaves': 85, 'bagging_fraction': 0.9541456411286611, 'min_sum_hessian_in_leaf': 0.04898881695460263}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.7067070498463563, 'num_leaves': 85, 'bagging_fraction': 0.9541456411286611, 'min_sum_hessian_in_leaf': 0.04898881695460263} scored 0.8472222222222221 in 0:00:00.121200\n",
            "Optimization Progress:  21%|██        | 21/100 [00:03<00:13,  5.74it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5559263702359063, 'num_leaves': 84, 'bagging_fraction': 0.9986377482329701, 'min_sum_hessian_in_leaf': 0.17231008353933194}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.5559263702359063, 'num_leaves': 84, 'bagging_fraction': 0.9986377482329701, 'min_sum_hessian_in_leaf': 0.17231008353933194} scored 0.8715277777777778 in 0:00:00.215597\n",
            "Optimization Progress:  22%|██▏       | 22/100 [00:03<00:15,  5.05it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.8368055555555555 and parameters: {'feature_fraction': 0.5054945946218856, 'num_leaves': 130, 'bagging_fraction': 0.94820017621314, 'min_sum_hessian_in_leaf': 0.308295294680854}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.5054945946218856, 'num_leaves': 130, 'bagging_fraction': 0.94820017621314, 'min_sum_hessian_in_leaf': 0.308295294680854} scored 0.8368055555555555 in 0:00:00.116611\n",
            "Optimization Progress:  23%|██▎       | 23/100 [00:04<00:14,  5.46it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.8125 and parameters: {'feature_fraction': 0.6165311953519939, 'num_leaves': 107, 'bagging_fraction': 0.8878524589325703, 'min_sum_hessian_in_leaf': 0.0012124232777004015}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.6165311953519939, 'num_leaves': 107, 'bagging_fraction': 0.8878524589325703, 'min_sum_hessian_in_leaf': 0.0012124232777004015} scored 0.8125 in 0:00:00.129665\n",
            "Optimization Progress:  24%|██▍       | 24/100 [00:04<00:13,  5.64it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[55]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.8541666666666666 and parameters: {'feature_fraction': 0.550617328682166, 'num_leaves': 69, 'bagging_fraction': 0.9779939568530936, 'min_sum_hessian_in_leaf': 1.1819341415222853}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.550617328682166, 'num_leaves': 69, 'bagging_fraction': 0.9779939568530936, 'min_sum_hessian_in_leaf': 1.1819341415222853} scored 0.8541666666666666 in 0:00:00.130633\n",
            "Optimization Progress:  25%|██▌       | 25/100 [00:04<00:12,  5.78it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.5514470366952647, 'num_leaves': 97, 'bagging_fraction': 0.7552952746257338, 'min_sum_hessian_in_leaf': 0.14794207709956203}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.5514470366952647, 'num_leaves': 97, 'bagging_fraction': 0.7552952746257338, 'min_sum_hessian_in_leaf': 0.14794207709956203} scored 0.7986111111111112 in 0:00:00.116931\n",
            "Optimization Progress:  26%|██▌       | 26/100 [00:04<00:12,  6.09it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.8611111111111112 and parameters: {'feature_fraction': 0.5025765627923007, 'num_leaves': 134, 'bagging_fraction': 0.956134907542021, 'min_sum_hessian_in_leaf': 0.5348530477555123}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5025765627923007, 'num_leaves': 134, 'bagging_fraction': 0.956134907542021, 'min_sum_hessian_in_leaf': 0.5348530477555123} scored 0.8611111111111112 in 0:00:00.123391\n",
            "Optimization Progress:  27%|██▋       | 27/100 [00:04<00:11,  6.17it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.8125 and parameters: {'feature_fraction': 0.6123543264875693, 'num_leaves': 211, 'bagging_fraction': 0.8980629373406377, 'min_sum_hessian_in_leaf': 2.4727298255768178}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.6123543264875693, 'num_leaves': 211, 'bagging_fraction': 0.8980629373406377, 'min_sum_hessian_in_leaf': 2.4727298255768178} scored 0.8125 in 0:00:00.205641\n",
            "Optimization Progress:  28%|██▊       | 28/100 [00:04<00:13,  5.42it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.6738492699452632, 'num_leaves': 153, 'bagging_fraction': 0.864344536862268, 'min_sum_hessian_in_leaf': 0.06917430994658696}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.6738492699452632, 'num_leaves': 153, 'bagging_fraction': 0.864344536862268, 'min_sum_hessian_in_leaf': 0.06917430994658696} scored 0.7916666666666666 in 0:00:00.235370\n",
            "Optimization Progress:  29%|██▉       | 29/100 [00:05<00:14,  4.77it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[42]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.754625578626613, 'num_leaves': 72, 'bagging_fraction': 0.6875059696309002, 'min_sum_hessian_in_leaf': 0.21213838524854084}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.754625578626613, 'num_leaves': 72, 'bagging_fraction': 0.6875059696309002, 'min_sum_hessian_in_leaf': 0.21213838524854084} scored 0.7743055555555556 in 0:00:00.284595\n",
            "Optimization Progress:  30%|███       | 30/100 [00:05<00:16,  4.17it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[34]\tvalid's auc: 0.777778\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.7777777777777778 and parameters: {'feature_fraction': 0.5706197351776557, 'num_leaves': 18, 'bagging_fraction': 0.7905237740880466, 'min_sum_hessian_in_leaf': 0.30016067833717425}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.5706197351776557, 'num_leaves': 18, 'bagging_fraction': 0.7905237740880466, 'min_sum_hessian_in_leaf': 0.30016067833717425} scored 0.7777777777777778 in 0:00:00.235302\n",
            "Optimization Progress:  31%|███       | 31/100 [00:05<00:17,  3.97it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.5379401419008798, 'num_leaves': 86, 'bagging_fraction': 0.9986769697861296, 'min_sum_hessian_in_leaf': 0.16987299361785677}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.5379401419008798, 'num_leaves': 86, 'bagging_fraction': 0.9986769697861296, 'min_sum_hessian_in_leaf': 0.16987299361785677} scored 0.8645833333333334 in 0:00:00.274189\n",
            "Optimization Progress:  32%|███▏      | 32/100 [00:06<00:18,  3.70it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5610209440253758, 'num_leaves': 100, 'bagging_fraction': 0.9589402492799868, 'min_sum_hessian_in_leaf': 0.028358643981436456}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.5610209440253758, 'num_leaves': 100, 'bagging_fraction': 0.9589402492799868, 'min_sum_hessian_in_leaf': 0.028358643981436456} scored 0.8472222222222222 in 0:00:00.181600\n",
            "Optimization Progress:  33%|███▎      | 33/100 [00:06<00:16,  4.01it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.5958430177790365, 'num_leaves': 121, 'bagging_fraction': 0.999680415235001, 'min_sum_hessian_in_leaf': 0.6481319077862837}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.5958430177790365, 'num_leaves': 121, 'bagging_fraction': 0.999680415235001, 'min_sum_hessian_in_leaf': 0.6481319077862837} scored 0.861111111111111 in 0:00:00.074072\n",
            "Optimization Progress:  33%|███▎      | 33/100 [00:06<00:16,  4.01it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.5433537233548134, 'num_leaves': 65, 'bagging_fraction': 0.9341787178165374, 'min_sum_hessian_in_leaf': 4.9899201013561765}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.5433537233548134, 'num_leaves': 65, 'bagging_fraction': 0.9341787178165374, 'min_sum_hessian_in_leaf': 4.9899201013561765} scored 0.7986111111111112 in 0:00:00.069193\n",
            "Optimization Progress:  35%|███▌      | 35/100 [00:06<00:11,  5.66it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[56]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5668227347721637, 'num_leaves': 55, 'bagging_fraction': 0.9706485216334223, 'min_sum_hessian_in_leaf': 0.22712233517259567}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.5668227347721637, 'num_leaves': 55, 'bagging_fraction': 0.9706485216334223, 'min_sum_hessian_in_leaf': 0.22712233517259567} scored 0.8680555555555556 in 0:00:00.084857\n",
            "Optimization Progress:  36%|███▌      | 36/100 [00:06<00:10,  6.23it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[77]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.6332395074528491, 'num_leaves': 141, 'bagging_fraction': 0.8619202809672158, 'min_sum_hessian_in_leaf': 0.0859018688565443}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.6332395074528491, 'num_leaves': 141, 'bagging_fraction': 0.8619202809672158, 'min_sum_hessian_in_leaf': 0.0859018688565443} scored 0.7847222222222223 in 0:00:00.074492\n",
            "Optimization Progress:  37%|███▋      | 37/100 [00:06<00:09,  6.90it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.652778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[9]\tvalid's auc: 0.725694\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.7256944444444445 and parameters: {'feature_fraction': 0.525662984573252, 'num_leaves': 83, 'bagging_fraction': 0.9091051222001301, 'min_sum_hessian_in_leaf': 9.074966324558195}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.525662984573252, 'num_leaves': 83, 'bagging_fraction': 0.9091051222001301, 'min_sum_hessian_in_leaf': 9.074966324558195} scored 0.7256944444444445 in 0:00:00.060761\n",
            "Optimization Progress:  37%|███▋      | 37/100 [00:06<00:09,  6.90it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.871528\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.875 and parameters: {'feature_fraction': 0.6794446347966296, 'num_leaves': 170, 'bagging_fraction': 0.9740659628079851, 'min_sum_hessian_in_leaf': 0.026733684234233765}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.6794446347966296, 'num_leaves': 170, 'bagging_fraction': 0.9740659628079851, 'min_sum_hessian_in_leaf': 0.026733684234233765} scored 0.875 in 0:00:00.090816\n",
            "Optimization Progress:  39%|███▉      | 39/100 [00:06<00:07,  7.88it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.732639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.774306\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.7743055555555556 and parameters: {'feature_fraction': 0.682635976821535, 'num_leaves': 194, 'bagging_fraction': 0.5821718262630846, 'min_sum_hessian_in_leaf': 0.012424791659069125}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.682635976821535, 'num_leaves': 194, 'bagging_fraction': 0.5821718262630846, 'min_sum_hessian_in_leaf': 0.012424791659069125} scored 0.7743055555555556 in 0:00:00.128135\n",
            "Optimization Progress:  40%|████      | 40/100 [00:07<00:08,  7.39it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.815972\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.7767062363660705, 'num_leaves': 223, 'bagging_fraction': 0.9418062092055598, 'min_sum_hessian_in_leaf': 0.014294895798843967}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.7767062363660705, 'num_leaves': 223, 'bagging_fraction': 0.9418062092055598, 'min_sum_hessian_in_leaf': 0.014294895798843967} scored 0.8402777777777777 in 0:00:00.212355\n",
            "Optimization Progress:  41%|████      | 41/100 [00:07<00:09,  6.18it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[98]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.8499247626229005, 'num_leaves': 182, 'bagging_fraction': 0.9750268810977849, 'min_sum_hessian_in_leaf': 0.03277529409424081}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.8499247626229005, 'num_leaves': 182, 'bagging_fraction': 0.9750268810977849, 'min_sum_hessian_in_leaf': 0.03277529409424081} scored 0.861111111111111 in 0:00:00.304380\n",
            "Optimization Progress:  42%|████▏     | 42/100 [00:07<00:12,  4.75it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[90]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6543789089315727, 'num_leaves': 164, 'bagging_fraction': 0.9786655830512628, 'min_sum_hessian_in_leaf': 0.1462962355833542}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.6543789089315727, 'num_leaves': 164, 'bagging_fraction': 0.9786655830512628, 'min_sum_hessian_in_leaf': 0.1462962355833542} scored 0.8715277777777778 in 0:00:00.520693\n",
            "Optimization Progress:  43%|████▎     | 43/100 [00:08<00:17,  3.29it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5861241861467555, 'num_leaves': 138, 'bagging_fraction': 0.9971773394062716, 'min_sum_hessian_in_leaf': 0.00848147553770563}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.5861241861467555, 'num_leaves': 138, 'bagging_fraction': 0.9971773394062716, 'min_sum_hessian_in_leaf': 0.00848147553770563} scored 0.8715277777777778 in 0:00:00.130671\n",
            "Optimization Progress:  44%|████▍     | 44/100 [00:08<00:14,  3.79it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.84375\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[101]\tvalid's auc: 0.850694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.8506944444444444 and parameters: {'feature_fraction': 0.7211265629053668, 'num_leaves': 114, 'bagging_fraction': 0.9598293613374059, 'min_sum_hessian_in_leaf': 0.1098334723278787}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.7211265629053668, 'num_leaves': 114, 'bagging_fraction': 0.9598293613374059, 'min_sum_hessian_in_leaf': 0.1098334723278787} scored 0.8506944444444444 in 0:00:00.486066\n",
            "Optimization Progress:  45%|████▌     | 45/100 [00:08<00:18,  2.95it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[69]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.5172546710784042, 'num_leaves': 96, 'bagging_fraction': 0.9223540183376234, 'min_sum_hessian_in_leaf': 0.0407504915948471}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.5172546710784042, 'num_leaves': 96, 'bagging_fraction': 0.9223540183376234, 'min_sum_hessian_in_leaf': 0.0407504915948471} scored 0.7916666666666666 in 0:00:00.144755\n",
            "Optimization Progress:  46%|████▌     | 46/100 [00:09<00:15,  3.41it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.715278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.802083\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.8020833333333333 and parameters: {'feature_fraction': 0.5311547018279753, 'num_leaves': 45, 'bagging_fraction': 0.545663749580285, 'min_sum_hessian_in_leaf': 0.37200808980947503}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.5311547018279753, 'num_leaves': 45, 'bagging_fraction': 0.545663749580285, 'min_sum_hessian_in_leaf': 0.37200808980947503} scored 0.8020833333333333 in 0:00:00.125394\n",
            "Optimization Progress:  47%|████▋     | 47/100 [00:09<00:13,  3.93it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.7847222222222223 and parameters: {'feature_fraction': 0.6134923868822042, 'num_leaves': 145, 'bagging_fraction': 0.8762211024599363, 'min_sum_hessian_in_leaf': 0.025281507072693138}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.6134923868822042, 'num_leaves': 145, 'bagging_fraction': 0.8762211024599363, 'min_sum_hessian_in_leaf': 0.025281507072693138} scored 0.7847222222222223 in 0:00:00.193772\n",
            "Optimization Progress:  48%|████▊     | 48/100 [00:09<00:12,  4.02it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5722847996162369, 'num_leaves': 126, 'bagging_fraction': 0.9390776418240152, 'min_sum_hessian_in_leaf': 1.0125432660178488}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.5722847996162369, 'num_leaves': 126, 'bagging_fraction': 0.9390776418240152, 'min_sum_hessian_in_leaf': 1.0125432660178488} scored 0.8472222222222222 in 0:00:00.155394\n",
            "Optimization Progress:  49%|████▉     | 49/100 [00:09<00:11,  4.31it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[175]\tvalid's auc: 0.770833\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.7708333333333334 and parameters: {'feature_fraction': 0.5972261990523502, 'num_leaves': 172, 'bagging_fraction': 0.7013402470396363, 'min_sum_hessian_in_leaf': 0.003417387460105571}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.5972261990523502, 'num_leaves': 172, 'bagging_fraction': 0.7013402470396363, 'min_sum_hessian_in_leaf': 0.003417387460105571} scored 0.7708333333333334 in 0:00:00.174920\n",
            "Optimization Progress:  50%|█████     | 50/100 [00:09<00:11,  4.36it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[28]\tvalid's auc: 0.791667\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.7916666666666666 and parameters: {'feature_fraction': 0.5012937449274749, 'num_leaves': 76, 'bagging_fraction': 0.6626139126987496, 'min_sum_hessian_in_leaf': 2.0329490956388527}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'feature_fraction': 0.5012937449274749, 'num_leaves': 76, 'bagging_fraction': 0.6626139126987496, 'min_sum_hessian_in_leaf': 2.0329490956388527} scored 0.7916666666666666 in 0:00:00.128775\n",
            "Optimization Progress:  51%|█████     | 51/100 [00:09<00:10,  4.76it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[90]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6571376236191356, 'num_leaves': 166, 'bagging_fraction': 0.9805891412503506, 'min_sum_hessian_in_leaf': 0.13832513532005003}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'feature_fraction': 0.6571376236191356, 'num_leaves': 166, 'bagging_fraction': 0.9805891412503506, 'min_sum_hessian_in_leaf': 0.13832513532005003} scored 0.8715277777777778 in 0:00:00.185307\n",
            "Optimization Progress:  52%|█████▏    | 52/100 [00:10<00:10,  4.59it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[94]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.6942212569799582, 'num_leaves': 185, 'bagging_fraction': 0.9736314101715681, 'min_sum_hessian_in_leaf': 0.4253042151467997}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'feature_fraction': 0.6942212569799582, 'num_leaves': 185, 'bagging_fraction': 0.9736314101715681, 'min_sum_hessian_in_leaf': 0.4253042151467997} scored 0.8784722222222222 in 0:00:00.096979\n",
            "Optimization Progress:  53%|█████▎    | 53/100 [00:10<00:08,  5.26it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.829861\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.829861111111111 and parameters: {'feature_fraction': 0.7535342222529283, 'num_leaves': 189, 'bagging_fraction': 0.9136012901612219, 'min_sum_hessian_in_leaf': 1.3616609408398874}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'feature_fraction': 0.7535342222529283, 'num_leaves': 189, 'bagging_fraction': 0.9136012901612219, 'min_sum_hessian_in_leaf': 1.3616609408398874} scored 0.829861111111111 in 0:00:00.086155\n",
            "Optimization Progress:  54%|█████▍    | 54/100 [00:10<00:07,  5.99it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.8541666666666665 and parameters: {'feature_fraction': 0.6964673846126648, 'num_leaves': 201, 'bagging_fraction': 0.9657861289706489, 'min_sum_hessian_in_leaf': 0.44687560809299187}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'feature_fraction': 0.6964673846126648, 'num_leaves': 201, 'bagging_fraction': 0.9657861289706489, 'min_sum_hessian_in_leaf': 0.44687560809299187} scored 0.8541666666666665 in 0:00:00.071704\n",
            "Optimization Progress:  55%|█████▌    | 55/100 [00:10<00:06,  6.79it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5236182943225349, 'num_leaves': 109, 'bagging_fraction': 0.9887676447861163, 'min_sum_hessian_in_leaf': 0.592272074499006}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'feature_fraction': 0.5236182943225349, 'num_leaves': 109, 'bagging_fraction': 0.9887676447861163, 'min_sum_hessian_in_leaf': 0.592272074499006} scored 0.8784722222222222 in 0:00:00.078897\n",
            "Optimization Progress:  56%|█████▌    | 56/100 [00:10<00:05,  7.44it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.815972\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.8402777777777778 and parameters: {'feature_fraction': 0.7351082836540076, 'num_leaves': 108, 'bagging_fraction': 0.9401179517868793, 'min_sum_hessian_in_leaf': 0.6759488103673505}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'feature_fraction': 0.7351082836540076, 'num_leaves': 108, 'bagging_fraction': 0.9401179517868793, 'min_sum_hessian_in_leaf': 0.6759488103673505} scored 0.8402777777777778 in 0:00:00.083662\n",
            "Optimization Progress:  57%|█████▋    | 57/100 [00:10<00:05,  7.77it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[27]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.7847222222222222 and parameters: {'feature_fraction': 0.5237055790304076, 'num_leaves': 221, 'bagging_fraction': 0.8436238084455718, 'min_sum_hessian_in_leaf': 3.85331757027904}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'feature_fraction': 0.5237055790304076, 'num_leaves': 221, 'bagging_fraction': 0.8436238084455718, 'min_sum_hessian_in_leaf': 3.85331757027904} scored 0.7847222222222222 in 0:00:00.075692\n",
            "Optimization Progress:  58%|█████▊    | 58/100 [00:10<00:05,  8.20it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[101]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.8142634472008576, 'num_leaves': 148, 'bagging_fraction': 0.985242339724052, 'min_sum_hessian_in_leaf': 0.8457199071787568}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'feature_fraction': 0.8142634472008576, 'num_leaves': 148, 'bagging_fraction': 0.985242339724052, 'min_sum_hessian_in_leaf': 0.8457199071787568} scored 0.861111111111111 in 0:00:00.088402\n",
            "Optimization Progress:  59%|█████▉    | 59/100 [00:11<00:04,  8.25it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[61]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.8194444444444443 and parameters: {'feature_fraction': 0.6350698206790558, 'num_leaves': 244, 'bagging_fraction': 0.9016852820415449, 'min_sum_hessian_in_leaf': 1.7882195355586343}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'feature_fraction': 0.6350698206790558, 'num_leaves': 244, 'bagging_fraction': 0.9016852820415449, 'min_sum_hessian_in_leaf': 1.7882195355586343} scored 0.8194444444444443 in 0:00:00.090146\n",
            "Optimization Progress:  60%|██████    | 60/100 [00:11<00:04,  8.33it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.78125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.861111111111111 and parameters: {'feature_fraction': 0.965946308365782, 'num_leaves': 177, 'bagging_fraction': 0.9546853364142939, 'min_sum_hessian_in_leaf': 0.6145281495340091}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'feature_fraction': 0.965946308365782, 'num_leaves': 177, 'bagging_fraction': 0.9546853364142939, 'min_sum_hessian_in_leaf': 0.6145281495340091} scored 0.861111111111111 in 0:00:00.102581\n",
            "Optimization Progress:  61%|██████    | 61/100 [00:11<00:04,  7.90it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5510250073842554, 'num_leaves': 94, 'bagging_fraction': 0.9999477860176184, 'min_sum_hessian_in_leaf': 0.28952978250789846}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'feature_fraction': 0.5510250073842554, 'num_leaves': 94, 'bagging_fraction': 0.9999477860176184, 'min_sum_hessian_in_leaf': 0.28952978250789846} scored 0.8715277777777778 in 0:00:00.099487\n",
            "Optimization Progress:  62%|██████▏   | 62/100 [00:11<00:04,  7.76it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5153933180291268, 'num_leaves': 115, 'bagging_fraction': 0.982324781627865, 'min_sum_hessian_in_leaf': 0.08138363503213634}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'feature_fraction': 0.5153933180291268, 'num_leaves': 115, 'bagging_fraction': 0.982324781627865, 'min_sum_hessian_in_leaf': 0.08138363503213634} scored 0.8680555555555556 in 0:00:00.086620\n",
            "Optimization Progress:  63%|██████▎   | 63/100 [00:11<00:04,  8.09it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[91]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.5442349619847018, 'num_leaves': 104, 'bagging_fraction': 0.9604479897129077, 'min_sum_hessian_in_leaf': 0.21092034714157915}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'feature_fraction': 0.5442349619847018, 'num_leaves': 104, 'bagging_fraction': 0.9604479897129077, 'min_sum_hessian_in_leaf': 0.21092034714157915} scored 0.8402777777777777 in 0:00:00.096556\n",
            "Optimization Progress:  64%|██████▍   | 64/100 [00:11<00:04,  8.06it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[88]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5586546834480711, 'num_leaves': 126, 'bagging_fraction': 0.927894146549521, 'min_sum_hessian_in_leaf': 0.33611463997776175}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'feature_fraction': 0.5586546834480711, 'num_leaves': 126, 'bagging_fraction': 0.927894146549521, 'min_sum_hessian_in_leaf': 0.33611463997776175} scored 0.8194444444444444 in 0:00:00.087010\n",
            "Optimization Progress:  65%|██████▌   | 65/100 [00:11<00:04,  8.01it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5815886339797922, 'num_leaves': 254, 'bagging_fraction': 0.986610252210261, 'min_sum_hessian_in_leaf': 1.1606828375448168}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'feature_fraction': 0.5815886339797922, 'num_leaves': 254, 'bagging_fraction': 0.986610252210261, 'min_sum_hessian_in_leaf': 1.1606828375448168} scored 0.8715277777777778 in 0:00:00.090944\n",
            "Optimization Progress:  66%|██████▌   | 66/100 [00:11<00:04,  8.00it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.84375\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.854167\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.8541666666666665 and parameters: {'feature_fraction': 0.6713728933283478, 'num_leaves': 58, 'bagging_fraction': 0.9666609804344071, 'min_sum_hessian_in_leaf': 0.5292834432355716}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'feature_fraction': 0.6713728933283478, 'num_leaves': 58, 'bagging_fraction': 0.9666609804344071, 'min_sum_hessian_in_leaf': 0.5292834432355716} scored 0.8541666666666665 in 0:00:00.081992\n",
            "Optimization Progress:  67%|██████▋   | 67/100 [00:12<00:03,  8.25it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.743056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.8368055555555556 and parameters: {'feature_fraction': 0.931507762058805, 'num_leaves': 134, 'bagging_fraction': 0.7809488345825834, 'min_sum_hessian_in_leaf': 0.18496191628762115}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'feature_fraction': 0.931507762058805, 'num_leaves': 134, 'bagging_fraction': 0.7809488345825834, 'min_sum_hessian_in_leaf': 0.18496191628762115} scored 0.8368055555555556 in 0:00:00.075996\n",
            "Optimization Progress:  68%|██████▊   | 68/100 [00:12<00:03,  8.58it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.788194\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.857639\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.8576388888888888 and parameters: {'feature_fraction': 0.7060449691047949, 'num_leaves': 79, 'bagging_fraction': 0.9870744538184498, 'min_sum_hessian_in_leaf': 0.021261239895426266}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'feature_fraction': 0.7060449691047949, 'num_leaves': 79, 'bagging_fraction': 0.9870744538184498, 'min_sum_hessian_in_leaf': 0.021261239895426266} scored 0.8576388888888888 in 0:00:00.087108\n",
            "Optimization Progress:  69%|██████▉   | 69/100 [00:12<00:03,  8.71it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.798611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[20]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.8124999999999999 and parameters: {'feature_fraction': 0.5339850838357544, 'num_leaves': 91, 'bagging_fraction': 0.9426034992442726, 'min_sum_hessian_in_leaf': 0.05572916539472105}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'feature_fraction': 0.5339850838357544, 'num_leaves': 91, 'bagging_fraction': 0.9426034992442726, 'min_sum_hessian_in_leaf': 0.05572916539472105} scored 0.8124999999999999 in 0:00:00.093501\n",
            "Optimization Progress:  70%|███████   | 70/100 [00:12<00:03,  8.31it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.819444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.8472222222222222 and parameters: {'feature_fraction': 0.5003974690318663, 'num_leaves': 119, 'bagging_fraction': 0.9502467799137907, 'min_sum_hessian_in_leaf': 2.520446337584062}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'feature_fraction': 0.5003974690318663, 'num_leaves': 119, 'bagging_fraction': 0.9502467799137907, 'min_sum_hessian_in_leaf': 2.520446337584062} scored 0.8472222222222222 in 0:00:00.083372\n",
            "Optimization Progress:  71%|███████   | 71/100 [00:12<00:03,  8.55it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.8645833333333334 and parameters: {'feature_fraction': 0.6587894889025253, 'num_leaves': 162, 'bagging_fraction': 0.971180382458661, 'min_sum_hessian_in_leaf': 0.14602978757477644}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'feature_fraction': 0.6587894889025253, 'num_leaves': 162, 'bagging_fraction': 0.971180382458661, 'min_sum_hessian_in_leaf': 0.14602978757477644} scored 0.8645833333333334 in 0:00:00.097029\n",
            "Optimization Progress:  72%|███████▏  | 72/100 [00:12<00:03,  8.19it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.795139\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[94]\tvalid's auc: 0.864583\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.8645833333333333 and parameters: {'feature_fraction': 0.6435075837012219, 'num_leaves': 150, 'bagging_fraction': 0.9889161762237546, 'min_sum_hessian_in_leaf': 0.42319454689794295}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'feature_fraction': 0.6435075837012219, 'num_leaves': 150, 'bagging_fraction': 0.9889161762237546, 'min_sum_hessian_in_leaf': 0.42319454689794295} scored 0.8645833333333333 in 0:00:00.093318\n",
            "Optimization Progress:  73%|███████▎  | 73/100 [00:12<00:03,  8.19it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.850694\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.802083\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[78]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.6202152842535253, 'num_leaves': 158, 'bagging_fraction': 0.9728853468830154, 'min_sum_hessian_in_leaf': 0.11288427812836782}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'feature_fraction': 0.6202152842535253, 'num_leaves': 158, 'bagging_fraction': 0.9728853468830154, 'min_sum_hessian_in_leaf': 0.11288427812836782} scored 0.8715277777777778 in 0:00:00.090402\n",
            "Optimization Progress:  74%|███████▍  | 74/100 [00:12<00:03,  8.22it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[106]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.9922172299870717, 'num_leaves': 169, 'bagging_fraction': 0.9988626222415926, 'min_sum_hessian_in_leaf': 0.25701821635058275}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'feature_fraction': 0.9922172299870717, 'num_leaves': 169, 'bagging_fraction': 0.9988626222415926, 'min_sum_hessian_in_leaf': 0.25701821635058275} scored 0.8194444444444444 in 0:00:00.100665\n",
            "Optimization Progress:  75%|███████▌  | 75/100 [00:12<00:03,  7.99it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.763889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.756944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.798611\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.7986111111111112 and parameters: {'feature_fraction': 0.715451492634304, 'num_leaves': 186, 'bagging_fraction': 0.7265537839619253, 'min_sum_hessian_in_leaf': 0.7526601328978069}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'feature_fraction': 0.715451492634304, 'num_leaves': 186, 'bagging_fraction': 0.7265537839619253, 'min_sum_hessian_in_leaf': 0.7526601328978069} scored 0.7986111111111112 in 0:00:00.088385\n",
            "Optimization Progress:  76%|███████▌  | 76/100 [00:13<00:03,  7.98it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[67]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.6065607172116827, 'num_leaves': 178, 'bagging_fraction': 0.9505009162445209, 'min_sum_hessian_in_leaf': 0.07127636572932075}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'feature_fraction': 0.6065607172116827, 'num_leaves': 178, 'bagging_fraction': 0.9505009162445209, 'min_sum_hessian_in_leaf': 0.07127636572932075} scored 0.8402777777777777 in 0:00:00.092886\n",
            "Optimization Progress:  77%|███████▋  | 77/100 [00:13<00:02,  8.10it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[57]\tvalid's auc: 0.836806\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.8368055555555555 and parameters: {'feature_fraction': 0.7389545838033889, 'num_leaves': 195, 'bagging_fraction': 0.9199592602613168, 'min_sum_hessian_in_leaf': 0.46347247430826616}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'feature_fraction': 0.7389545838033889, 'num_leaves': 195, 'bagging_fraction': 0.9199592602613168, 'min_sum_hessian_in_leaf': 0.46347247430826616} scored 0.8368055555555555 in 0:00:00.088211\n",
            "Optimization Progress:  78%|███████▊  | 78/100 [00:13<00:02,  8.28it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.875 and parameters: {'feature_fraction': 0.5179991373529929, 'num_leaves': 108, 'bagging_fraction': 0.9809288047802656, 'min_sum_hessian_in_leaf': 0.0968360871455689}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'feature_fraction': 0.5179991373529929, 'num_leaves': 108, 'bagging_fraction': 0.9809288047802656, 'min_sum_hessian_in_leaf': 0.0968360871455689} scored 0.875 in 0:00:00.322712\n",
            "Optimization Progress:  79%|███████▉  | 79/100 [00:13<00:04,  5.05it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[16]\tvalid's auc: 0.784722\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.7847222222222221 and parameters: {'feature_fraction': 0.5165299464802199, 'num_leaves': 111, 'bagging_fraction': 0.880302520353175, 'min_sum_hessian_in_leaf': 0.04417565099296417}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'feature_fraction': 0.5165299464802199, 'num_leaves': 111, 'bagging_fraction': 0.880302520353175, 'min_sum_hessian_in_leaf': 0.04417565099296417} scored 0.7847222222222221 in 0:00:00.302432\n",
            "Optimization Progress:  80%|████████  | 80/100 [00:14<00:04,  4.14it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[89]\tvalid's auc: 0.819444\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.8194444444444444 and parameters: {'feature_fraction': 0.5628662446362218, 'num_leaves': 102, 'bagging_fraction': 0.9308700521231426, 'min_sum_hessian_in_leaf': 0.9865331070727973}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'feature_fraction': 0.5628662446362218, 'num_leaves': 102, 'bagging_fraction': 0.9308700521231426, 'min_sum_hessian_in_leaf': 0.9865331070727973} scored 0.8194444444444444 in 0:00:00.332305\n",
            "Optimization Progress:  81%|████████  | 81/100 [00:14<00:05,  3.60it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.847222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[93]\tvalid's auc: 0.868056\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.8680555555555556 and parameters: {'feature_fraction': 0.5140018302778545, 'num_leaves': 127, 'bagging_fraction': 0.9740461626910843, 'min_sum_hessian_in_leaf': 0.09590094980060127}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'feature_fraction': 0.5140018302778545, 'num_leaves': 127, 'bagging_fraction': 0.9740461626910843, 'min_sum_hessian_in_leaf': 0.09590094980060127} scored 0.8680555555555556 in 0:00:00.147943\n",
            "Optimization Progress:  82%|████████▏ | 82/100 [00:14<00:04,  3.91it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.864583\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5400918146326525, 'num_leaves': 83, 'bagging_fraction': 0.9853035332483234, 'min_sum_hessian_in_leaf': 0.12895664403306506}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'feature_fraction': 0.5400918146326525, 'num_leaves': 83, 'bagging_fraction': 0.9853035332483234, 'min_sum_hessian_in_leaf': 0.12895664403306506} scored 0.8784722222222222 in 0:00:00.668549\n",
            "Optimization Progress:  83%|████████▎ | 83/100 [00:15<00:06,  2.54it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5420241445716252, 'num_leaves': 63, 'bagging_fraction': 0.9891938545376339, 'min_sum_hessian_in_leaf': 0.25186525541049065}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'feature_fraction': 0.5420241445716252, 'num_leaves': 63, 'bagging_fraction': 0.9891938545376339, 'min_sum_hessian_in_leaf': 0.25186525541049065} scored 0.8784722222222222 in 0:00:00.525859\n",
            "Optimization Progress:  84%|████████▍ | 84/100 [00:15<00:07,  2.23it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[91]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.5349821912223266, 'num_leaves': 74, 'bagging_fraction': 0.9597274709248406, 'min_sum_hessian_in_leaf': 0.25402714106672203}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'feature_fraction': 0.5349821912223266, 'num_leaves': 74, 'bagging_fraction': 0.9597274709248406, 'min_sum_hessian_in_leaf': 0.25402714106672203} scored 0.8402777777777777 in 0:00:00.247751\n",
            "Optimization Progress:  85%|████████▌ | 85/100 [00:16<00:06,  2.50it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5453070559042086, 'num_leaves': 34, 'bagging_fraction': 0.988884410319334, 'min_sum_hessian_in_leaf': 0.35907596837917594}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'feature_fraction': 0.5453070559042086, 'num_leaves': 34, 'bagging_fraction': 0.988884410319334, 'min_sum_hessian_in_leaf': 0.35907596837917594} scored 0.8784722222222222 in 0:00:00.144024\n",
            "Optimization Progress:  86%|████████▌ | 86/100 [00:16<00:04,  2.96it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.542442132333216, 'num_leaves': 34, 'bagging_fraction': 0.9891188933084762, 'min_sum_hessian_in_leaf': 0.3478660068639557}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'feature_fraction': 0.542442132333216, 'num_leaves': 34, 'bagging_fraction': 0.9891188933084762, 'min_sum_hessian_in_leaf': 0.3478660068639557} scored 0.8784722222222222 in 0:00:00.330599\n",
            "Optimization Progress:  87%|████████▋ | 87/100 [00:16<00:04,  2.85it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.5456854821829795, 'num_leaves': 36, 'bagging_fraction': 0.9664314125678126, 'min_sum_hessian_in_leaf': 0.3585973783497127}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'feature_fraction': 0.5456854821829795, 'num_leaves': 36, 'bagging_fraction': 0.9664314125678126, 'min_sum_hessian_in_leaf': 0.3585973783497127} scored 0.8472222222222221 in 0:00:00.239215\n",
            "Optimization Progress:  88%|████████▊ | 88/100 [00:17<00:03,  3.01it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.854167\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[49]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5717930395409035, 'num_leaves': 23, 'bagging_fraction': 0.9908438928956786, 'min_sum_hessian_in_leaf': 0.609222270265115}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'feature_fraction': 0.5717930395409035, 'num_leaves': 23, 'bagging_fraction': 0.9908438928956786, 'min_sum_hessian_in_leaf': 0.609222270265115} scored 0.8715277777777778 in 0:00:00.225413\n",
            "Optimization Progress:  89%|████████▉ | 89/100 [00:17<00:03,  3.18it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.829861\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.774306\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[22]\tvalid's auc: 0.840278\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.8402777777777777 and parameters: {'feature_fraction': 0.7700082544907914, 'num_leaves': 63, 'bagging_fraction': 0.9474266656038242, 'min_sum_hessian_in_leaf': 0.8083999595883224}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'feature_fraction': 0.7700082544907914, 'num_leaves': 63, 'bagging_fraction': 0.9474266656038242, 'min_sum_hessian_in_leaf': 0.8083999595883224} scored 0.8402777777777777 in 0:00:00.152292\n",
            "Optimization Progress:  90%|█████████ | 90/100 [00:17<00:02,  3.59it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.791667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.777778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.75\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[117]\tvalid's auc: 0.8125\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.8124999999999999 and parameters: {'feature_fraction': 0.5320991537039005, 'num_leaves': 37, 'bagging_fraction': 0.9342208107794336, 'min_sum_hessian_in_leaf': 1.198898829246122}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'feature_fraction': 0.5320991537039005, 'num_leaves': 37, 'bagging_fraction': 0.9342208107794336, 'min_sum_hessian_in_leaf': 1.198898829246122} scored 0.8124999999999999 in 0:00:00.350708\n",
            "Optimization Progress:  91%|█████████ | 91/100 [00:17<00:02,  3.19it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.861111\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[96]\tvalid's auc: 0.875\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.875 and parameters: {'feature_fraction': 0.5224098975703473, 'num_leaves': 17, 'bagging_fraction': 0.9783128504432712, 'min_sum_hessian_in_leaf': 0.5019710007681817}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'feature_fraction': 0.5224098975703473, 'num_leaves': 17, 'bagging_fraction': 0.9783128504432712, 'min_sum_hessian_in_leaf': 0.5019710007681817} scored 0.875 in 0:00:00.369985\n",
            "Optimization Progress:  92%|█████████▏| 92/100 [00:18<00:02,  2.81it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5126009986632776, 'num_leaves': 30, 'bagging_fraction': 0.991266370279817, 'min_sum_hessian_in_leaf': 0.21372480074150202}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'feature_fraction': 0.5126009986632776, 'num_leaves': 30, 'bagging_fraction': 0.991266370279817, 'min_sum_hessian_in_leaf': 0.21372480074150202} scored 0.8784722222222222 in 0:00:00.150053\n",
            "Optimization Progress:  93%|█████████▎| 93/100 [00:18<00:02,  3.20it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5106006783285167, 'num_leaves': 48, 'bagging_fraction': 0.9920425196319581, 'min_sum_hessian_in_leaf': 0.20651803860434362}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'feature_fraction': 0.5106006783285167, 'num_leaves': 48, 'bagging_fraction': 0.9920425196319581, 'min_sum_hessian_in_leaf': 0.20651803860434362} scored 0.8784722222222222 in 0:00:00.242820\n",
            "Optimization Progress:  94%|█████████▍| 94/100 [00:18<00:01,  3.23it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5420192536871441, 'num_leaves': 31, 'bagging_fraction': 0.986100713715147, 'min_sum_hessian_in_leaf': 0.18655612368210403}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'feature_fraction': 0.5420192536871441, 'num_leaves': 31, 'bagging_fraction': 0.986100713715147, 'min_sum_hessian_in_leaf': 0.18655612368210403} scored 0.8784722222222222 in 0:00:00.240939\n",
            "Optimization Progress:  95%|█████████▌| 95/100 [00:19<00:01,  3.30it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[29]\tvalid's auc: 0.878472\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.8784722222222222 and parameters: {'feature_fraction': 0.5038746542159122, 'num_leaves': 47, 'bagging_fraction': 0.9909038196268936, 'min_sum_hessian_in_leaf': 0.29469233444658083}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'feature_fraction': 0.5038746542159122, 'num_leaves': 47, 'bagging_fraction': 0.9909038196268936, 'min_sum_hessian_in_leaf': 0.29469233444658083} scored 0.8784722222222222 in 0:00:00.198120\n",
            "Optimization Progress:  96%|█████████▌| 96/100 [00:19<00:01,  3.45it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.840278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.805556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[33]\tvalid's auc: 0.861111\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.8611111111111112 and parameters: {'feature_fraction': 0.5092851676877003, 'num_leaves': 43, 'bagging_fraction': 0.9593694934099157, 'min_sum_hessian_in_leaf': 0.4039454900330683}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'feature_fraction': 0.5092851676877003, 'num_leaves': 43, 'bagging_fraction': 0.9593694934099157, 'min_sum_hessian_in_leaf': 0.4039454900330683} scored 0.8611111111111112 in 0:00:00.217308\n",
            "Optimization Progress:  97%|█████████▋| 97/100 [00:19<00:00,  3.52it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.833333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.819444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.847222\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.8472222222222221 and parameters: {'feature_fraction': 0.5282116926663797, 'num_leaves': 31, 'bagging_fraction': 0.9682710276660659, 'min_sum_hessian_in_leaf': 0.12510994860342406}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'feature_fraction': 0.5282116926663797, 'num_leaves': 31, 'bagging_fraction': 0.9682710276660659, 'min_sum_hessian_in_leaf': 0.12510994860342406} scored 0.8472222222222221 in 0:00:00.375907\n",
            "Optimization Progress:  98%|█████████▊| 98/100 [00:20<00:00,  3.07it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.857639\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.809028\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[59]\tvalid's auc: 0.871528\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.8715277777777778 and parameters: {'feature_fraction': 0.5516189818173235, 'num_leaves': 57, 'bagging_fraction': 0.9985176163592306, 'min_sum_hessian_in_leaf': 0.23215060117206943}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'feature_fraction': 0.5516189818173235, 'num_leaves': 57, 'bagging_fraction': 0.9985176163592306, 'min_sum_hessian_in_leaf': 0.23215060117206943} scored 0.8715277777777778 in 0:00:00.540091\n",
            "Optimization Progress:  99%|█████████▉| 99/100 [00:20<00:00,  2.40it/s, best_trial=10, best_value=0.878]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.722222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[2]\tvalid's auc: 0.763889\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.7638888888888888 and parameters: {'feature_fraction': 0.5783502070090707, 'num_leaves': 41, 'bagging_fraction': 0.6252760024086583, 'min_sum_hessian_in_leaf': 0.3600704200690418}. Best is trial 10 with value: 0.8784722222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'feature_fraction': 0.5783502070090707, 'num_leaves': 41, 'bagging_fraction': 0.6252760024086583, 'min_sum_hessian_in_leaf': 0.3600704200690418} scored 0.7638888888888888 in 0:00:00.235723\n",
            "Optimization Progress: 100%|██████████| 100/100 [00:21<00:00,  4.74it/s, best_trial=10, best_value=0.878]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.5102734049121492, 'num_leaves': 129, 'bagging_fraction': 0.9847685553939329, 'min_sum_hessian_in_leaf': 0.689539874561655}\u001b[0m\n",
            " achieve 0.8785 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:49] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 129, 'feature_fraction': 0.5102734049121492, 'bagging_fraction': 0.9847685553939329, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.689539874561655}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.770833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[37]\tvalid's auc: 0.850694\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.881119\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.895105\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685315\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[42]\tvalid's auc: 0.706294\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.685315\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[11]\tvalid's auc: 0.783217\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.769231\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[41]\tvalid's auc: 0.811189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:52] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7660435267857142\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7660435267857142\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:52] \u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:27:52] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ... Time budget is 135.49 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ... Time budget is 135.49 secs\n",
            "Optimization Progress:   0%|          | 0/100 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-f9920959-5d25-46eb-9ff7-6088fb689a89\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.35ms\tremaining: 674ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8819444 (12)\ttotal: 280ms\tremaining: 1.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8819444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.8819444444444444 and parameters: {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15}. Best is trial 0 with value: 0.8819444444444444.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 3.6010467344475403, 'min_data_in_leaf': 15} scored 0.8819444444444444 in 0:00:00.369781\n",
            "Optimization Progress:   1%|          | 1/100 [00:00<00:38,  2.57it/s, best_trial=0, best_value=0.882]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.23ms\tremaining: 615ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8958333 (1)\ttotal: 123ms\tremaining: 486ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 2.5361081166471375e-07, 'min_data_in_leaf': 4} scored 0.8958333333333334 in 0:00:00.215690\n",
            "Optimization Progress:   2%|▏         | 2/100 [00:00<00:29,  3.28it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.13ms\tremaining: 565ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8506944 (0)\ttotal: 80.5ms\tremaining: 318ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.6245760287469893, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.181882\n",
            "Optimization Progress:   3%|▎         | 3/100 [00:00<00:26,  3.71it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 4.21ms\tremaining: 2.1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8576389 (1)\ttotal: 177ms\tremaining: 699ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8576388889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.8576388888888888 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.5320059381854043e-08, 'min_data_in_leaf': 20} scored 0.8576388888888888 in 0:00:00.290102\n",
            "Optimization Progress:   4%|▍         | 4/100 [00:01<00:28,  3.42it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 5.37ms\tremaining: 2.68s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8819444 (4)\ttotal: 587ms\tremaining: 2.32s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8819444444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.8819444444444445 and parameters: {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 8.148018307012941e-07, 'min_data_in_leaf': 4} scored 0.8819444444444445 in 0:00:00.757693\n",
            "Optimization Progress:   5%|▌         | 5/100 [00:02<00:45,  2.07it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.83ms\tremaining: 912ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8923611 (4)\ttotal: 165ms\tremaining: 652ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.472429642032198e-06, 'min_data_in_leaf': 11} scored 0.8923611111111112 in 0:00:00.442094\n",
            "Optimization Progress:   6%|▌         | 6/100 [00:02<00:46,  2.04it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 4.42ms\tremaining: 2.21s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6875000\tbest: 0.8958333 (1)\ttotal: 365ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.17890272377219e-06, 'min_data_in_leaf': 13} scored 0.8958333333333334 in 0:00:00.539193\n",
            "Optimization Progress:   7%|▋         | 7/100 [00:03<00:48,  1.94it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 974us\tremaining: 486ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8923611 (4)\ttotal: 195ms\tremaining: 771ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.258943089524393e-06, 'min_data_in_leaf': 8} scored 0.8923611111111112 in 0:00:00.316785\n",
            "Optimization Progress:   8%|▊         | 8/100 [00:03<00:42,  2.17it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 3.44ms\tremaining: 1.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8958333 (1)\ttotal: 346ms\tremaining: 1.36s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.1165691561324743, 'min_data_in_leaf': 4} scored 0.8958333333333334 in 0:00:00.439626\n",
            "Optimization Progress:   9%|▉         | 9/100 [00:03<00:42,  2.14it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 4.86ms\tremaining: 2.42s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8958333 (1)\ttotal: 260ms\tremaining: 1.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.0021465011216654484, 'min_data_in_leaf': 1} scored 0.8958333333333334 in 0:00:00.387860\n",
            "Optimization Progress:  10%|█         | 10/100 [00:04<00:41,  2.15it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 4.95ms\tremaining: 2.47s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8680556 (4)\ttotal: 369ms\tremaining: 1.46s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8680555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.8680555555555556 and parameters: {'max_depth': 7, 'l2_leaf_reg': 1.1323342574942026e-08, 'min_data_in_leaf': 7}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 1.1323342574942026e-08, 'min_data_in_leaf': 7} scored 0.8680555555555556 in 0:00:00.543682\n",
            "Optimization Progress:  11%|█         | 11/100 [00:04<00:45,  1.97it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 2.27ms\tremaining: 1.13s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8645833 (6)\ttotal: 335ms\tremaining: 1.32s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.8645833333333333 and parameters: {'max_depth': 6, 'l2_leaf_reg': 0.00021189647537044038, 'min_data_in_leaf': 17}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 0.00021189647537044038, 'min_data_in_leaf': 17} scored 0.8645833333333333 in 0:00:00.469544\n",
            "Optimization Progress:  12%|█▏        | 12/100 [00:05<00:44,  1.97it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.16ms\tremaining: 581ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8854167 (5)\ttotal: 97.6ms\tremaining: 386ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.504608987495313e-07, 'min_data_in_leaf': 10}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.504608987495313e-07, 'min_data_in_leaf': 10} scored 0.8854166666666666 in 0:00:00.222988\n",
            "Optimization Progress:  13%|█▎        | 13/100 [00:05<00:37,  2.31it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 5.38ms\tremaining: 2.69s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8645833 (5)\ttotal: 435ms\tremaining: 1.72s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.8645833333333333 and parameters: {'max_depth': 5, 'l2_leaf_reg': 8.77791614314671e-05, 'min_data_in_leaf': 1}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 8.77791614314671e-05, 'min_data_in_leaf': 1} scored 0.8645833333333333 in 0:00:00.571937\n",
            "Optimization Progress:  14%|█▍        | 14/100 [00:06<00:41,  2.06it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 3.99ms\tremaining: 1.99s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.7916667 (42)\ttotal: 356ms\tremaining: 1.41s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7916666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 42\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 43 iterations.\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.7916666666666667 and parameters: {'max_depth': 6, 'l2_leaf_reg': 2.0860170570447388e-05, 'min_data_in_leaf': 6}. Best is trial 1 with value: 0.8958333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 2.0860170570447388e-05, 'min_data_in_leaf': 6} scored 0.7916666666666667 in 0:00:00.710695\n",
            "Optimization Progress:  15%|█▌        | 15/100 [00:07<00:48,  1.76it/s, best_trial=1, best_value=0.896]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.35ms\tremaining: 672ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.9027778 (10)\ttotal: 303ms\tremaining: 1.2s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9027777778\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 10\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 11 iterations.\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.9027777777777778 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232823, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0029151336209232823, 'min_data_in_leaf': 12} scored 0.9027777777777778 in 0:00:00.509800\n",
            "Optimization Progress:  16%|█▌        | 16/100 [00:07<00:47,  1.77it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.15ms\tremaining: 575ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8854167 (5)\ttotal: 161ms\tremaining: 637ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0053223209907244575, 'min_data_in_leaf': 10}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0053223209907244575, 'min_data_in_leaf': 10} scored 0.8854166666666666 in 0:00:00.324553\n",
            "Optimization Progress:  17%|█▋        | 17/100 [00:08<00:42,  1.97it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.08ms\tremaining: 538ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8263889\tbest: 0.8854167 (5)\ttotal: 134ms\tremaining: 528ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.007809132161023211, 'min_data_in_leaf': 4}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.007809132161023211, 'min_data_in_leaf': 4} scored 0.8854166666666666 in 0:00:00.267639\n",
            "Optimization Progress:  18%|█▊        | 18/100 [00:08<00:37,  2.17it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.34ms\tremaining: 671ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8888889 (18)\ttotal: 302ms\tremaining: 1.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 18\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 19 iterations.\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.888888888888889 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.06012007950445106, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.06012007950445106, 'min_data_in_leaf': 18} scored 0.888888888888889 in 0:00:00.477999\n",
            "Optimization Progress:  19%|█▉        | 19/100 [00:08<00:38,  2.08it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 4.64ms\tremaining: 2.31s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8645833 (6)\ttotal: 333ms\tremaining: 1.31s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8645833333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 6\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 7 iterations.\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.8645833333333333 and parameters: {'max_depth': 6, 'l2_leaf_reg': 0.0010749883760899615, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 0.0010749883760899615, 'min_data_in_leaf': 13} scored 0.8645833333333333 in 0:00:00.464127\n",
            "Optimization Progress:  20%|██        | 20/100 [00:09<00:39,  2.01it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.21ms\tremaining: 606ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8854167 (5)\ttotal: 261ms\tremaining: 1.03s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.4400903220306502e-07, 'min_data_in_leaf': 8}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.4400903220306502e-07, 'min_data_in_leaf': 8} scored 0.8854166666666666 in 0:00:00.424276\n",
            "Optimization Progress:  21%|██        | 21/100 [00:09<00:39,  2.02it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.21ms\tremaining: 603ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8958333 (1)\ttotal: 148ms\tremaining: 585ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 4.060726382877094e-05, 'min_data_in_leaf': 13}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 4.060726382877094e-05, 'min_data_in_leaf': 13} scored 0.8958333333333334 in 0:00:00.254025\n",
            "Optimization Progress:  22%|██▏       | 22/100 [00:10<00:33,  2.33it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 3.61ms\tremaining: 1.8s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8958333 (1)\ttotal: 517ms\tremaining: 2.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.4908285328345343e-06, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.4908285328345343e-06, 'min_data_in_leaf': 15} scored 0.8958333333333334 in 0:00:00.674412\n",
            "Optimization Progress:  23%|██▎       | 23/100 [00:10<00:40,  1.90it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 1.32ms\tremaining: 658ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8958333 (1)\ttotal: 485ms\tremaining: 1.92s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 9.390138332052496e-08, 'min_data_in_leaf': 11}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 9.390138332052496e-08, 'min_data_in_leaf': 11} scored 0.8958333333333334 in 0:00:00.651474\n",
            "Optimization Progress:  24%|██▍       | 24/100 [00:11<00:44,  1.70it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7881944\tbest: 0.7881944 (0)\ttotal: 11.8ms\tremaining: 5.91s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8055556 (98)\ttotal: 657ms\tremaining: 2.59s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:200:\ttest: 0.8055556\tbest: 0.8125000 (101)\ttotal: 1.22s\tremaining: 1.81s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8125\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 101\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 102 iterations.\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.8125 and parameters: {'max_depth': 6, 'l2_leaf_reg': 1.209353836699894e-05, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'max_depth': 6, 'l2_leaf_reg': 1.209353836699894e-05, 'min_data_in_leaf': 15} scored 0.8125 in 0:00:01.529514\n",
            "Optimization Progress:  25%|██▌       | 25/100 [00:13<01:06,  1.13it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 4.75ms\tremaining: 2.37s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8854167 (4)\ttotal: 298ms\tremaining: 1.18s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0003252761374770595, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0003252761374770595, 'min_data_in_leaf': 12} scored 0.8854166666666666 in 0:00:00.485934\n",
            "Optimization Progress:  26%|██▌       | 26/100 [00:13<00:57,  1.28it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 4.09ms\tremaining: 2.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8958333 (1)\ttotal: 293ms\tremaining: 1.16s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 0.022355382861496083, 'min_data_in_leaf': 9}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 0.022355382861496083, 'min_data_in_leaf': 9} scored 0.8958333333333334 in 0:00:00.474042\n",
            "Optimization Progress:  27%|██▋       | 27/100 [00:14<00:50,  1.44it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8437500\tbest: 0.8437500 (0)\ttotal: 3.96ms\tremaining: 1.98s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8958333 (1)\ttotal: 233ms\tremaining: 922ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.8958333333333334 and parameters: {'max_depth': 5, 'l2_leaf_reg': 1.5765199750320534e-06, 'min_data_in_leaf': 6}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'max_depth': 5, 'l2_leaf_reg': 1.5765199750320534e-06, 'min_data_in_leaf': 6} scored 0.8958333333333334 in 0:00:00.388809\n",
            "Optimization Progress:  28%|██▊       | 28/100 [00:14<00:44,  1.62it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 942us\tremaining: 470ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8993056 (1)\ttotal: 74.8ms\tremaining: 296ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.442518943575423e-08, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.442518943575423e-08, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.212152\n",
            "Optimization Progress:  29%|██▉       | 29/100 [00:15<00:36,  1.93it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.02ms\tremaining: 510ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 227ms\tremaining: 898ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.4134699879705236e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.4134699879705236e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.384927\n",
            "Optimization Progress:  30%|███       | 30/100 [00:15<00:34,  2.00it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 999us\tremaining: 499ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8541667 (10)\ttotal: 180ms\tremaining: 710ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8541666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 10\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 11 iterations.\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.8541666666666666 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.188488835785422, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.188488835785422, 'min_data_in_leaf': 17} scored 0.8541666666666666 in 0:00:00.308474\n",
            "Optimization Progress:  31%|███       | 31/100 [00:15<00:31,  2.16it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 3.13ms\tremaining: 1.56s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.8993056 (1)\ttotal: 157ms\tremaining: 621ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.650542623766143e-08, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.650542623766143e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.340545\n",
            "Optimization Progress:  32%|███▏      | 32/100 [00:16<00:29,  2.29it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.99ms\tremaining: 1.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 254ms\tremaining: 1s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.1823409220603664e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.1823409220603664e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.426768\n",
            "Optimization Progress:  33%|███▎      | 33/100 [00:16<00:30,  2.20it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 4.54ms\tremaining: 2.27s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7152778\tbest: 0.8993056 (1)\ttotal: 186ms\tremaining: 734ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.159000694120228e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.159000694120228e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.384717\n",
            "Optimization Progress:  34%|███▍      | 34/100 [00:17<00:30,  2.16it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.01ms\tremaining: 504ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7083333\tbest: 0.8993056 (1)\ttotal: 198ms\tremaining: 780ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.720192828080591e-08, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.720192828080591e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.367775\n",
            "Optimization Progress:  35%|███▌      | 35/100 [00:17<00:29,  2.19it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 4.23ms\tremaining: 2.11s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 238ms\tremaining: 941ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.28170520176123e-07, 'min_data_in_leaf': 20}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.28170520176123e-07, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.394584\n",
            "Optimization Progress:  36%|███▌      | 36/100 [00:18<00:28,  2.22it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 752us\tremaining: 375ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8993056 (1)\ttotal: 89.4ms\tremaining: 353ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.095856531971167e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.095856531971167e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.191604\n",
            "Optimization Progress:  37%|███▋      | 37/100 [00:18<00:23,  2.64it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.51ms\tremaining: 752ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7152778\tbest: 0.8993056 (1)\ttotal: 74ms\tremaining: 292ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.1508585197425347e-08, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.1508585197425347e-08, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.138757\n",
            "Optimization Progress:  38%|███▊      | 38/100 [00:18<00:19,  3.20it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.37ms\tremaining: 685ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8958333 (4)\ttotal: 81.9ms\tremaining: 323ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.8958333333333334 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.45483427335788185, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.45483427335788185, 'min_data_in_leaf': 14} scored 0.8958333333333334 in 0:00:00.164239\n",
            "Optimization Progress:  39%|███▉      | 39/100 [00:18<00:16,  3.61it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 764us\tremaining: 382ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 63.3ms\tremaining: 250ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.2208662558040907e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.2208662558040907e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.133889\n",
            "Optimization Progress:  40%|████      | 40/100 [00:18<00:14,  4.12it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 970us\tremaining: 484ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8854167 (5)\ttotal: 79.3ms\tremaining: 313ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 2.7820441408904687e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 2.7820441408904687e-08, 'min_data_in_leaf': 19} scored 0.8854166666666666 in 0:00:00.145325\n",
            "Optimization Progress:  41%|████      | 41/100 [00:18<00:12,  4.54it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 822us\tremaining: 410ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8993056 (1)\ttotal: 72.5ms\tremaining: 286ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.9623862411537926e-08, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.9623862411537926e-08, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.148095\n",
            "Optimization Progress:  42%|████▏     | 42/100 [00:19<00:11,  4.86it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 750us\tremaining: 375ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 92.2ms\tremaining: 364ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.1406372409997107e-07, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.1406372409997107e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.157714\n",
            "Optimization Progress:  43%|████▎     | 43/100 [00:19<00:11,  5.04it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 790us\tremaining: 394ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8993056 (1)\ttotal: 75.9ms\tremaining: 300ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.6249437881459255e-08, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.6249437881459255e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.147248\n",
            "Optimization Progress:  44%|████▍     | 44/100 [00:19<00:10,  5.22it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 702us\tremaining: 351ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 65.8ms\tremaining: 260ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0055062426520163e-08, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0055062426520163e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.136347\n",
            "Optimization Progress:  45%|████▌     | 45/100 [00:19<00:10,  5.50it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 760us\tremaining: 379ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 60.9ms\tremaining: 241ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.9976972846690276e-07, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.9976972846690276e-07, 'min_data_in_leaf': 12} scored 0.8993055555555556 in 0:00:00.133094\n",
            "Optimization Progress:  46%|████▌     | 46/100 [00:19<00:09,  5.70it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.09ms\tremaining: 546ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8854167 (5)\ttotal: 81.6ms\tremaining: 322ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.86297740047586e-06, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.86297740047586e-06, 'min_data_in_leaf': 17} scored 0.8854166666666666 in 0:00:00.172381\n",
            "Optimization Progress:  47%|████▋     | 47/100 [00:20<00:09,  5.46it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 714us\tremaining: 357ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8506944 (0)\ttotal: 71.9ms\tremaining: 284ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0018943984158954804, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0018943984158954804, 'min_data_in_leaf': 18} scored 0.8506944444444444 in 0:00:00.143855\n",
            "Optimization Progress:  48%|████▊     | 48/100 [00:20<00:09,  5.57it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 952us\tremaining: 475ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8854167 (4)\ttotal: 109ms\tremaining: 432ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0004935798242156365, 'min_data_in_leaf': 12}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0004935798242156365, 'min_data_in_leaf': 12} scored 0.8854166666666666 in 0:00:00.198584\n",
            "Optimization Progress:  49%|████▉     | 49/100 [00:20<00:09,  5.21it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 753us\tremaining: 376ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7083333\tbest: 0.8993056 (1)\ttotal: 81.5ms\tremaining: 322ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.661020987044852e-08, 'min_data_in_leaf': 16}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.661020987044852e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.167089\n",
            "Optimization Progress:  50%|█████     | 50/100 [00:20<00:09,  5.21it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 782us\tremaining: 390ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8993056 (1)\ttotal: 65ms\tremaining: 257ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 50 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.232758972489976e-07, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 51\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.232758972489976e-07, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.133233\n",
            "Optimization Progress:  51%|█████     | 51/100 [00:20<00:08,  5.47it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 679us\tremaining: 339ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7291667\tbest: 0.8993056 (1)\ttotal: 67.2ms\tremaining: 266ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 51 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.4462826848165575e-08, 'min_data_in_leaf': 20}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 52\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.4462826848165575e-08, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.146867\n",
            "Optimization Progress:  52%|█████▏    | 52/100 [00:20<00:08,  5.52it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 772us\tremaining: 386ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 67ms\tremaining: 265ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 52 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 6.3769681675165e-08, 'min_data_in_leaf': 19}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 53\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 6.3769681675165e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.146618\n",
            "Optimization Progress:  53%|█████▎    | 53/100 [00:21<00:08,  5.59it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 767us\tremaining: 383ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8993056 (1)\ttotal: 66.2ms\tremaining: 262ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 53 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.2558664260896004e-08, 'min_data_in_leaf': 18}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 54\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.2558664260896004e-08, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.137091\n",
            "Optimization Progress:  54%|█████▍    | 54/100 [00:21<00:08,  5.75it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.21ms\tremaining: 601ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (5)\ttotal: 124ms\tremaining: 490ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 54 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.235512222698528e-07, 'min_data_in_leaf': 14}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 55\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.235512222698528e-07, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.193168\n",
            "Optimization Progress:  55%|█████▌    | 55/100 [00:21<00:08,  5.37it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 854us\tremaining: 426ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8854167 (5)\ttotal: 79.6ms\tremaining: 315ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 55 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.389245257455328e-06, 'min_data_in_leaf': 15}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 56\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.389245257455328e-06, 'min_data_in_leaf': 15} scored 0.8854166666666666 in 0:00:00.158609\n",
            "Optimization Progress:  56%|█████▌    | 56/100 [00:21<00:08,  5.37it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 758us\tremaining: 379ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8993056 (1)\ttotal: 71.9ms\tremaining: 284ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 56 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3124247660133686e-07, 'min_data_in_leaf': 17}. Best is trial 15 with value: 0.9027777777777778.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 57\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3124247660133686e-07, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.153403\n",
            "Optimization Progress:  57%|█████▋    | 57/100 [00:21<00:08,  5.37it/s, best_trial=15, best_value=0.903]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 760us\tremaining: 380ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.9236111 (17)\ttotal: 60.5ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9236111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 17\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 18 iterations.\n",
            "INFO:optuna.study.study:Trial 57 finished with value: 0.9236111111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00011427914857502921, 'min_data_in_leaf': 19}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 58\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00011427914857502921, 'min_data_in_leaf': 19} scored 0.9236111111111112 in 0:00:00.140989\n",
            "Optimization Progress:  58%|█████▊    | 58/100 [00:22<00:07,  5.50it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8194444\tbest: 0.8194444 (0)\ttotal: 2.19ms\tremaining: 1.09s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8888889 (4)\ttotal: 177ms\tremaining: 697ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 58 finished with value: 0.888888888888889 and parameters: {'max_depth': 7, 'l2_leaf_reg': 7.76351174092854e-05, 'min_data_in_leaf': 16}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 59\u001b[0m with hyperparameters {'max_depth': 7, 'l2_leaf_reg': 7.76351174092854e-05, 'min_data_in_leaf': 16} scored 0.888888888888889 in 0:00:00.255711\n",
            "Optimization Progress:  59%|█████▉    | 59/100 [00:22<00:08,  4.70it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.35ms\tremaining: 674ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8854167 (5)\ttotal: 106ms\tremaining: 419ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 59 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.00969553246325887, 'min_data_in_leaf': 11}. Best is trial 57 with value: 0.9236111111111112.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 60\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.00969553246325887, 'min_data_in_leaf': 11} scored 0.8854166666666666 in 0:00:00.188247\n",
            "Optimization Progress:  60%|██████    | 60/100 [00:22<00:08,  4.64it/s, best_trial=57, best_value=0.924]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.08ms\tremaining: 541ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8819444\tbest: 0.9305556 (18)\ttotal: 61.4ms\tremaining: 243ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9305555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 18\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 19 iterations.\n",
            "INFO:optuna.study.study:Trial 60 finished with value: 0.9305555555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 61\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13} scored 0.9305555555555556 in 0:00:00.148249\n",
            "Optimization Progress:  61%|██████    | 61/100 [00:22<00:07,  4.89it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 709us\tremaining: 354ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7361111\tbest: 0.8506944 (0)\ttotal: 59.7ms\tremaining: 236ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 61 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00014297368512434865, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 62\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00014297368512434865, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.123782\n",
            "Optimization Progress:  62%|██████▏   | 62/100 [00:22<00:07,  5.30it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 798us\tremaining: 398ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.9166667 (39)\ttotal: 58.1ms\tremaining: 229ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9166666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 62 finished with value: 0.9166666666666667 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0985096705459318e-05, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 63\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0985096705459318e-05, 'min_data_in_leaf': 14} scored 0.9166666666666667 in 0:00:00.161992\n",
            "Optimization Progress:  63%|██████▎   | 63/100 [00:23<00:07,  5.28it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 944us\tremaining: 471ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8923611 (4)\ttotal: 77.9ms\tremaining: 308ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 63 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0967284650253425e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 64\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0967284650253425e-05, 'min_data_in_leaf': 13} scored 0.8923611111111112 in 0:00:00.158269\n",
            "Optimization Progress:  64%|██████▍   | 64/100 [00:23<00:06,  5.29it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 702us\tremaining: 350ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8680556 (59)\ttotal: 63.4ms\tremaining: 250ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8680555556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 59\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 60 iterations.\n",
            "INFO:optuna.study.study:Trial 64 finished with value: 0.8680555555555555 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.8032558846650763e-05, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 65\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.8032558846650763e-05, 'min_data_in_leaf': 12} scored 0.8680555555555555 in 0:00:00.171491\n",
            "Optimization Progress:  65%|██████▌   | 65/100 [00:23<00:06,  5.19it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 807us\tremaining: 403ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8958333 (11)\ttotal: 71.3ms\tremaining: 282ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 11\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 12 iterations.\n",
            "INFO:optuna.study.study:Trial 65 finished with value: 0.8958333333333333 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.797618576000362e-06, 'min_data_in_leaf': 10}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 66\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.797618576000362e-06, 'min_data_in_leaf': 10} scored 0.8958333333333333 in 0:00:00.172305\n",
            "Optimization Progress:  66%|██████▌   | 66/100 [00:23<00:06,  5.10it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.04ms\tremaining: 519ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (4)\ttotal: 78.4ms\tremaining: 310ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 66 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.0006267299025268735, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 67\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.0006267299025268735, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.160040\n",
            "Optimization Progress:  67%|██████▋   | 67/100 [00:23<00:06,  5.14it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 822us\tremaining: 410ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8611111\tbest: 0.8888889 (46)\ttotal: 73.3ms\tremaining: 290ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8888888889\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 46\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 47 iterations.\n",
            "INFO:optuna.study.study:Trial 67 finished with value: 0.8888888888888888 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.3264621125681148e-05, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 68\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.3264621125681148e-05, 'min_data_in_leaf': 15} scored 0.8888888888888888 in 0:00:00.195324\n",
            "Optimization Progress:  68%|██████▊   | 68/100 [00:24<00:06,  4.91it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 697us\tremaining: 348ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8541667 (39)\ttotal: 70.7ms\tremaining: 279ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8541666667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 39\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 40 iterations.\n",
            "INFO:optuna.study.study:Trial 68 finished with value: 0.8541666666666666 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.002354278893510329, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 69\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.002354278893510329, 'min_data_in_leaf': 14} scored 0.8541666666666666 in 0:00:00.171458\n",
            "Optimization Progress:  69%|██████▉   | 69/100 [00:24<00:06,  4.84it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.26ms\tremaining: 628ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8854167 (4)\ttotal: 215ms\tremaining: 848ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 69 finished with value: 0.8854166666666667 and parameters: {'max_depth': 4, 'l2_leaf_reg': 0.00017522862089164933, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 70\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 0.00017522862089164933, 'min_data_in_leaf': 12} scored 0.8854166666666667 in 0:00:00.328535\n",
            "Optimization Progress:  70%|███████   | 70/100 [00:24<00:07,  3.96it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 901us\tremaining: 450ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8506944 (0)\ttotal: 192ms\tremaining: 757ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 70 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.954655866173518e-05, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 71\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.954655866173518e-05, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.287852\n",
            "Optimization Progress:  71%|███████   | 71/100 [00:24<00:07,  3.67it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 3.58ms\tremaining: 1.78s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7986111\tbest: 0.8923611 (4)\ttotal: 202ms\tremaining: 796ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 71 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.708528754471435e-06, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 72\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.708528754471435e-06, 'min_data_in_leaf': 15} scored 0.8923611111111112 in 0:00:00.290883\n",
            "Optimization Progress:  72%|███████▏  | 72/100 [00:25<00:08,  3.49it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 906us\tremaining: 452ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8993056 (1)\ttotal: 183ms\tremaining: 723ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 72 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0017403982001171e-06, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 73\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0017403982001171e-06, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.264678\n",
            "Optimization Progress:  73%|███████▎  | 73/100 [00:25<00:07,  3.44it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.22ms\tremaining: 607ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8506944 (0)\ttotal: 200ms\tremaining: 791ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 73 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.03451772479612021, 'min_data_in_leaf': 2}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 74\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.03451772479612021, 'min_data_in_leaf': 2} scored 0.8506944444444444 in 0:00:00.320642\n",
            "Optimization Progress:  74%|███████▍  | 74/100 [00:25<00:08,  3.17it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.08ms\tremaining: 1.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8506944 (0)\ttotal: 193ms\tremaining: 763ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 74 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.7467971562387907e-05, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 75\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.7467971562387907e-05, 'min_data_in_leaf': 16} scored 0.8506944444444444 in 0:00:00.284888\n",
            "Optimization Progress:  75%|███████▌  | 75/100 [00:26<00:07,  3.18it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.73ms\tremaining: 1.36s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 190ms\tremaining: 751ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 75 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.641624404951669e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 76\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.641624404951669e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.273352\n",
            "Optimization Progress:  76%|███████▌  | 76/100 [00:26<00:07,  3.22it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.75ms\tremaining: 874ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8506944 (0)\ttotal: 213ms\tremaining: 841ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 76 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0011880893230096533, 'min_data_in_leaf': 9}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 77\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0011880893230096533, 'min_data_in_leaf': 9} scored 0.8506944444444444 in 0:00:00.323838\n",
            "Optimization Progress:  77%|███████▋  | 77/100 [00:26<00:07,  3.03it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 717us\tremaining: 358ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8506944 (0)\ttotal: 139ms\tremaining: 548ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 77 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.0002602491028654061, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 78\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.0002602491028654061, 'min_data_in_leaf': 18} scored 0.8506944444444444 in 0:00:00.261558\n",
            "Optimization Progress:  78%|███████▊  | 78/100 [00:27<00:07,  3.14it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 3.43ms\tremaining: 1.71s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7708333\tbest: 0.8854167 (5)\ttotal: 236ms\tremaining: 934ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 78 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 4.3931921030086025e-08, 'min_data_in_leaf': 11}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 79\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 4.3931921030086025e-08, 'min_data_in_leaf': 11} scored 0.8854166666666666 in 0:00:00.339846\n",
            "Optimization Progress:  79%|███████▉  | 79/100 [00:27<00:07,  2.96it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.37ms\tremaining: 1.18s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8055556\tbest: 0.8506944 (0)\ttotal: 96ms\tremaining: 379ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 79 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.010571814412111384, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 80\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.010571814412111384, 'min_data_in_leaf': 17} scored 0.8506944444444444 in 0:00:00.188589\n",
            "Optimization Progress:  80%|████████  | 80/100 [00:27<00:06,  3.25it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 859us\tremaining: 429ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8958333 (12)\ttotal: 120ms\tremaining: 472ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8958333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 12\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 13 iterations.\n",
            "INFO:optuna.study.study:Trial 80 finished with value: 0.8958333333333334 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.12265494738583436, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 81\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.12265494738583436, 'min_data_in_leaf': 16} scored 0.8958333333333334 in 0:00:00.229449\n",
            "Optimization Progress:  81%|████████  | 81/100 [00:28<00:05,  3.31it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 880us\tremaining: 439ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7638889\tbest: 0.8993056 (1)\ttotal: 134ms\tremaining: 531ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 81 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 7.006507216470076e-08, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 82\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 7.006507216470076e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.227137\n",
            "Optimization Progress:  82%|████████▏ | 82/100 [00:28<00:05,  3.40it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 895us\tremaining: 447ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 66.4ms\tremaining: 262ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 82 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.5997884243913893e-07, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 83\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.5997884243913893e-07, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.136761\n",
            "Optimization Progress:  83%|████████▎ | 83/100 [00:28<00:04,  3.89it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.33ms\tremaining: 665ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8472222\tbest: 0.8993056 (1)\ttotal: 66.3ms\tremaining: 262ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 83 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.319522631972632e-08, 'min_data_in_leaf': 20}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 84\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.319522631972632e-08, 'min_data_in_leaf': 20} scored 0.8993055555555556 in 0:00:00.142513\n",
            "Optimization Progress:  84%|████████▍ | 84/100 [00:28<00:03,  4.33it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 771us\tremaining: 385ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8611111 (31)\ttotal: 60ms\tremaining: 237ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8611111111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 31\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 32 iterations.\n",
            "INFO:optuna.study.study:Trial 84 finished with value: 0.861111111111111 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.004371275312998932, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 85\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.004371275312998932, 'min_data_in_leaf': 18} scored 0.861111111111111 in 0:00:00.151418\n",
            "Optimization Progress:  85%|████████▌ | 85/100 [00:28<00:03,  4.61it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.08ms\tremaining: 538ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.8993056 (1)\ttotal: 69.9ms\tremaining: 276ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 85 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.5903399973819104e-08, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 86\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.5903399973819104e-08, 'min_data_in_leaf': 13} scored 0.8993055555555556 in 0:00:00.161705\n",
            "Optimization Progress:  86%|████████▌ | 86/100 [00:29<00:02,  4.77it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 753us\tremaining: 376ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7777778\tbest: 0.8993056 (1)\ttotal: 65.6ms\tremaining: 259ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 86 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 4.946396663764725e-07, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 87\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 4.946396663764725e-07, 'min_data_in_leaf': 17} scored 0.8993055555555556 in 0:00:00.148608\n",
            "Optimization Progress:  87%|████████▋ | 87/100 [00:29<00:02,  4.96it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 732us\tremaining: 365ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 60.5ms\tremaining: 239ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 87 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.070207940399716e-07, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 88\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.070207940399716e-07, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.129506\n",
            "Optimization Progress:  88%|████████▊ | 88/100 [00:29<00:02,  5.26it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.11ms\tremaining: 554ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7430556\tbest: 0.8854167 (5)\ttotal: 77.9ms\tremaining: 308ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8854166667\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 5\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 6 iterations.\n",
            "INFO:optuna.study.study:Trial 88 finished with value: 0.8854166666666666 and parameters: {'max_depth': 4, 'l2_leaf_reg': 9.021772738882567e-08, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 89\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 9.021772738882567e-08, 'min_data_in_leaf': 14} scored 0.8854166666666666 in 0:00:00.170867\n",
            "Optimization Progress:  89%|████████▉ | 89/100 [00:29<00:02,  5.15it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 669us\tremaining: 334ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8194444\tbest: 0.8923611 (4)\ttotal: 63.1ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO:optuna.study.study:Trial 89 finished with value: 0.8923611111111112 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.6716061986961368e-06, 'min_data_in_leaf': 20}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 90\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.6716061986961368e-06, 'min_data_in_leaf': 20} scored 0.8923611111111112 in 0:00:00.137588\n",
            "Optimization Progress:  90%|█████████ | 90/100 [00:29<00:01,  5.33it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 738us\tremaining: 369ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8402778\tbest: 0.8993056 (1)\ttotal: 67.1ms\tremaining: 265ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 90 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8085746015379232e-08, 'min_data_in_leaf': 19}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 91\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8085746015379232e-08, 'min_data_in_leaf': 19} scored 0.8993055555555556 in 0:00:00.136338\n",
            "Optimization Progress:  91%|█████████ | 91/100 [00:30<00:01,  5.35it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 2.88ms\tremaining: 1.44s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8541667\tbest: 0.9097222 (57)\ttotal: 73.8ms\tremaining: 291ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9097222222\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 57\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 58 iterations.\n",
            "INFO:optuna.study.study:Trial 91 finished with value: 0.9097222222222221 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.437840574423421e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 92\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.437840574423421e-08, 'min_data_in_leaf': 15} scored 0.9097222222222221 in 0:00:00.209227\n",
            "Optimization Progress:  92%|█████████▏| 92/100 [00:30<00:01,  4.95it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 772us\tremaining: 385ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7916667\tbest: 0.8993056 (1)\ttotal: 63.2ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 92 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0046393741347246e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 93\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0046393741347246e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.151695\n",
            "Optimization Progress:  93%|█████████▎| 93/100 [00:30<00:01,  5.09it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 686us\tremaining: 343ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 62.9ms\tremaining: 249ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 93 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 5.57946305853902e-08, 'min_data_in_leaf': 14}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 94\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 5.57946305853902e-08, 'min_data_in_leaf': 14} scored 0.8993055555555556 in 0:00:00.130186\n",
            "Optimization Progress:  94%|█████████▍| 94/100 [00:30<00:01,  5.34it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1ms\tremaining: 499ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8993056 (1)\ttotal: 88.3ms\tremaining: 349ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 94 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.0355501846551036e-07, 'min_data_in_leaf': 18}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 95\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.0355501846551036e-07, 'min_data_in_leaf': 18} scored 0.8993055555555556 in 0:00:00.184730\n",
            "Optimization Progress:  95%|█████████▌| 95/100 [00:30<00:01,  4.94it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.01ms\tremaining: 506ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8993056 (1)\ttotal: 84ms\tremaining: 332ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 95 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 2.33560027136623e-08, 'min_data_in_leaf': 16}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 96\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 2.33560027136623e-08, 'min_data_in_leaf': 16} scored 0.8993055555555556 in 0:00:00.180141\n",
            "Optimization Progress:  96%|█████████▌| 96/100 [00:31<00:00,  4.93it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 3.29ms\tremaining: 1.64s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8993056 (1)\ttotal: 117ms\tremaining: 461ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 96 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 3.11172783540778e-08, 'min_data_in_leaf': 15}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 97\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 3.11172783540778e-08, 'min_data_in_leaf': 15} scored 0.8993055555555556 in 0:00:00.203462\n",
            "Optimization Progress:  97%|█████████▋| 97/100 [00:31<00:00,  4.66it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 1.03ms\tremaining: 515ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8125000\tbest: 0.8506944 (0)\ttotal: 69.7ms\tremaining: 275ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8506944444\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 0\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 1 iterations.\n",
            "INFO:optuna.study.study:Trial 97 finished with value: 0.8506944444444444 and parameters: {'max_depth': 3, 'l2_leaf_reg': 0.00011966526621705177, 'min_data_in_leaf': 13}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 98\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 0.00011966526621705177, 'min_data_in_leaf': 13} scored 0.8506944444444444 in 0:00:00.137691\n",
            "Optimization Progress:  98%|█████████▊| 98/100 [00:31<00:00,  4.98it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.7534722\tbest: 0.7534722 (0)\ttotal: 1.3ms\tremaining: 649ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7847222\tbest: 0.8333333 (25)\ttotal: 82.3ms\tremaining: 325ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8333333333\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 25\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 26 iterations.\n",
            "INFO:optuna.study.study:Trial 98 finished with value: 0.8333333333333333 and parameters: {'max_depth': 4, 'l2_leaf_reg': 1.597868329377265e-05, 'min_data_in_leaf': 17}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 99\u001b[0m with hyperparameters {'max_depth': 4, 'l2_leaf_reg': 1.597868329377265e-05, 'min_data_in_leaf': 17} scored 0.8333333333333333 in 0:00:00.178854\n",
            "Optimization Progress:  99%|█████████▉| 99/100 [00:31<00:00,  4.89it/s, best_trial=60, best_value=0.931]INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 830us\tremaining: 414ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7500000\tbest: 0.8993056 (1)\ttotal: 64.2ms\tremaining: 254ms\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8993055556\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 1\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 2 iterations.\n",
            "INFO:optuna.study.study:Trial 99 finished with value: 0.8993055555555556 and parameters: {'max_depth': 3, 'l2_leaf_reg': 1.8768050814480855e-07, 'min_data_in_leaf': 12}. Best is trial 60 with value: 0.9305555555555556.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 100\u001b[0m with hyperparameters {'max_depth': 3, 'l2_leaf_reg': 1.8768050814480855e-07, 'min_data_in_leaf': 12} scored 0.8993055555555556 in 0:00:00.143641\n",
            "Optimization Progress: 100%|██████████| 100/100 [00:31<00:00,  3.13it/s, best_trial=60, best_value=0.931]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:24] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'max_depth': 3, 'l2_leaf_reg': 1.4142208298719828e-05, 'min_data_in_leaf': 13}\u001b[0m\n",
            " achieve 0.9306 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task_type': 'CPU', 'thread_count': 2, 'random_seed': 42, 'num_trees': 3000, 'learning_rate': 0.03, 'l2_leaf_reg': 1.4142208298719828e-05, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'max_depth': 3, 'min_data_in_leaf': 13, 'one_hot_max_size': 10, 'fold_permutation_block': 1, 'boosting_type': 'Plain', 'boost_from_average': True, 'od_type': 'Iter', 'od_wait': 100, 'max_bin': 32, 'feature_border_type': 'GreedyLogSum', 'nan_mode': 'Min', 'verbose': 100, 'allow_writing_files': False, 'verbose_eval': 100}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.8506944\tbest: 0.8506944 (0)\ttotal: 840us\tremaining: 2.52s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.7569444\tbest: 0.8923611 (4)\ttotal: 88.2ms\tremaining: 2.53s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.8923611111\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.6783217\tbest: 0.6783217 (0)\ttotal: 978us\tremaining: 2.94s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.8321678\tbest: 0.9230769 (4)\ttotal: 86.9ms\tremaining: 2.49s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.9230769231\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 4\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 5 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.4300699\tbest: 0.4300699 (0)\ttotal: 751us\tremaining: 2.25s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5174825\tbest: 0.6993007 (7)\ttotal: 95.7ms\tremaining: 2.75s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.6993006993\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 7\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 8 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5384615\tbest: 0.5384615 (0)\ttotal: 682us\tremaining: 2.05s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.5874126\tbest: 0.7552448 (3)\ttotal: 71.2ms\tremaining: 2.04s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7552447552\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 3\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 4 iterations.\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_cb:0:\ttest: 0.5909091\tbest: 0.5909091 (0)\ttotal: 1.22ms\tremaining: 3.67s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:100:\ttest: 0.6853147\tbest: 0.7482517 (77)\ttotal: 76.2ms\tremaining: 2.19s\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Stopped by overfitting detector  (100 iterations wait)\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestTest = 0.7482517483\n",
            "INFO3:lightautoml.ml_algo.boost_cb:bestIteration = 77\n",
            "INFO3:lightautoml.ml_algo.boost_cb:Shrink model to first 78 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:24] Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7657645089285713\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7657645089285713\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:24] \u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_1_Tuned_CatBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'n_estimators': 3000, 'early_stopping_rounds': 100, 'seed': 42, 'verbose_eval': 100, 'nthread': 2}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.76042\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.77778\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[104]\tvalid-auc:0.77778\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.75524\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.82517\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[112]\tvalid-auc:0.82517\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.81469\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[99]\tvalid-auc:0.67832\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.70629\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[99]\tvalid-auc:0.58741\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[0]\tvalid-auc:0.66434\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[100]\tvalid-auc:0.72028\n",
            "INFO3:lightautoml.ml_algo.boost_xgb:[105]\tvalid-auc:0.72028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.7287946428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m finished. score = \u001b[1m0.7287946428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] \u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_2_XGBoost\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] Time left 543.09 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 543.09 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] Layer \u001b[1m2\u001b[0m train process start. Time left 543.07 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m2\u001b[0m train process start. Time left 543.07 secs\n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of text features: 0 \n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of categorical features: 0 \n",
            "DEBUG:lightautoml.ml_algo.dl_model:number of continuous features: 22 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:25] Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'num_workers': 0, 'pin_memory': False, 'max_length': 256, 'is_snap': False, 'input_bn': False, 'max_emb_size': 256, 'bert_name': None, 'pooling': 'cls', 'device': device(type='cpu'), 'use_cont': True, 'use_cat': True, 'use_text': False, 'lang': 'en', 'deterministic': True, 'multigpu': False, 'random_state': 42, 'model': 'mlp', 'model_with_emb': False, 'path_to_save': None, 'verbose_inside': None, 'verbose': 1, 'n_epochs': 50, 'snap_params': {'k': 3, 'early_stopping': True, 'patience': 10, 'swa': True}, 'bs': 256, 'emb_dropout': 0.1, 'emb_ratio': 3, 'opt': 'Adam', 'opt_params': {'lr': 0.0003, 'weight_decay': 0}, 'sch': 'ReduceLROnPlateau', 'scheduler_params': {'patience': 5, 'factor': 0.5, 'min_lr': 1e-05}, 'loss': None, 'loss_params': {}, 'loss_on_logits': True, 'clip_grad': False, 'clip_grad_params': {}, 'init_bias': True, 'dataset': 'UniversalDataset', 'tuned': False, 'optimization_search_space': None, 'verbose_bar': False, 'freeze_defaults': False, 'n_out': 1, 'hid_factor': [2, 2], 'hidden_size': [512, 256], 'block_config': [2, 2], 'compression': 0.5, 'growth_size': 256, 'bn_factor': 2, 'drop_rate': 0.1, 'noise_std': 0.05, 'num_init_features': None, 'act_fun': 'LeakyReLU', 'use_noise': False, 'use_bn': True, 'share_training_batches': True, 'embedding_size': 10, 'cat_embedder': 'cat', 'cont_embedder': 'cont', 'stop_by_metric': False, 'tuning_params': {'fit_on_holdout': True, 'max_tuning_iter': 25, 'max_tuning_time': 3600}, 'device_ids': None, 'num_dims': 22, 'text_features': [], 'bias': array([-0.13353139])}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6966314911842346, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898890137672424, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m =====\n",
            "INFO3:lightautoml.text.trainer:Epoch: 0, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 1, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 2, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 3, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 4, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 5, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 6, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 7, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 8, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 9, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 10, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 11, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Epoch: 12, train loss: nan, val loss: 0.6898889541625977, val metric: 0.5\n",
            "INFO3:lightautoml.text.trainer:Early stopping: val loss: 0.6898889541625977, val metric: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.4866071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.4866071428571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] \u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_1_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] Time left 539.83 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 539.83 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] \u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 2 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] \u001b[1mAutoml preset training completed in 60.17 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 60.17 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:28] Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_2_XGBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 1.00000 * (5 averaged models Lvl_1_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Models on level 0:\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_0_Tuned_LightGBM\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_1_Tuned_CatBoost\n",
            "\t 5 averaged models Lvl_0_Pipe_0_Mod_2_XGBoost\n",
            "\n",
            "Final prediction for new objects (level 1) = \n",
            "\t 1.00000 * (5 averaged models Lvl_1_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA Advanced] ROC-AUC: 0.5000  F1: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### конфигурация 4 - с feature selection и ограниченным набором моделей\n",
        "Только LGBM (c hyperparameter tuning) и линейная регрессия; включён feature selection (оставляем 80% лучших признаков); гиперпараметры подбираются на holdout-валидации.\n"
      ],
      "metadata": {
        "id": "SceXiK-JppB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl4 = TabularAutoML(\n",
        "    task=task,\n",
        "    timeout=600,\n",
        "    cpu_limit=2,\n",
        "    general_params={\n",
        "        'use_algos': [['lgb_tuned', 'linear_l2']]  # Только LGBM + Linear\n",
        "    },\n",
        "    selection_params={\n",
        "        'select_algos': ['gbm', 'linear_l2'],\n",
        "        'selection_feats_rate': 0.8,\n",
        "        'max_features_cnt_in_result': None,\n",
        "    },\n",
        "    tuning_params={\n",
        "        'fit_on_holdout': True,\n",
        "        'max_tuning_iter': 50,\n",
        "        'max_tuning_time': 200,\n",
        "    }\n",
        ")\n",
        "\n",
        "oof_pred4 = automl4.fit_predict(train_LAMA, roles=roles, verbose=1)\n",
        "test_pred4 = automl4.predict(test_LAMA)\n",
        "\n",
        "auc4 = roc_auc_score(y_test, test_pred4.data[:, 0])\n",
        "f1_4 = f1_score(y_test, test_pred4.data[:, 0] > 0.5)\n",
        "print(f'[LAMA FS+LGBM/Linear] ROC-AUC: {auc4:.4f}  F1: {f1_4:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdbO621ipxWL",
        "outputId": "e110ea27-1541-4579-ea2f-33b3cd771e23"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Stdout logging level is INFO.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Task: binary\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Start automl preset with listed constraints:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] - time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- time: 600.00 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] - CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- CPU: 2 cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] - memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:- memory: 16 GB\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] \u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.reader.base:\u001b[1mTrain data shape: (120, 20)\u001b[0m\n",
            "\n",
            "INFO3:lightautoml.reader.base:Feats was rejected during automatic roles guess: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] Layer \u001b[1m1\u001b[0m train process start. Time left 599.82 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Layer \u001b[1m1\u001b[0m train process start. Time left 599.82 secs\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.569444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:30] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'tol': 1e-06, 'max_iter': 100, 'cs': [1e-05, 5e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000], 'early_stopping': 2, 'categorical_idx': [0], 'embed_sizes': array([11], dtype=int32), 'data_size': 17}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5625\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5555555555555556\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0005 score = 0.5555555555555556\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.6923076923076923\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.6923076923076923\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.6923076923076923\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.8111888111888111\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.8111888111888111\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.8111888111888111\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.5174825174825175\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.5174825174825175\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.5174825174825175\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 1e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 5e-05 score = 0.951048951048951\n",
            "INFO3:lightautoml.ml_algo.torch_based.linear_model:Linear model: C = 0.0001 score = 0.951048951048951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:31] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.5680803571428571\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:31] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:31] Time left 598.52 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 598.52 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:32] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 200.00 secs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.tuning.optuna:Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ... Time budget is 200.00 secs\n",
            "Optimization Progress:   0%|          | 0/50 [00:00<?, ?it/s]INFO:optuna.storages._in_memory:A new study created in memory with name: no-name-c19ac6ac-d1df-4ced-841a-3b2e3a123a43\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[50]\tvalid's auc: 0.520833\n",
            "INFO:optuna.study.study:Trial 0 finished with value: 0.5208333333333334 and parameters: {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125}. Best is trial 0 with value: 0.5208333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125} scored 0.5208333333333334 in 0:00:00.090491\n",
            "Optimization Progress:   2%|▏         | 1/50 [00:00<00:05,  8.82it/s, best_trial=0, best_value=0.521]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 1 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547}. Best is trial 1 with value: 0.5763888888888888.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5780093202212182, 'num_leaves': 53, 'bagging_fraction': 0.5290418060840998, 'min_sum_hessian_in_leaf': 2.9154431891537547} scored 0.5763888888888888 in 0:00:00.103434\n",
            "Optimization Progress:   4%|▍         | 2/50 [00:00<00:05,  8.47it/s, best_trial=1, best_value=0.576]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.458333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[139]\tvalid's auc: 0.555556\n",
            "INFO:optuna.study.study:Trial 2 finished with value: 0.5416666666666667 and parameters: {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009}. Best is trial 1 with value: 0.5763888888888888.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 3\u001b[0m with hyperparameters {'feature_fraction': 0.8005575058716043, 'num_leaves': 185, 'bagging_fraction': 0.5102922471479012, 'min_sum_hessian_in_leaf': 7.579479953348009} scored 0.5416666666666667 in 0:00:00.109915\n",
            "Optimization Progress:   6%|▌         | 3/50 [00:00<00:05,  8.06it/s, best_trial=1, best_value=0.576]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[402]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 3 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254}. Best is trial 3 with value: 0.5833333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 4\u001b[0m with hyperparameters {'feature_fraction': 0.9162213204002109, 'num_leaves': 66, 'bagging_fraction': 0.5909124836035503, 'min_sum_hessian_in_leaf': 0.00541524411940254} scored 0.5833333333333334 in 0:00:00.207415\n",
            "Optimization Progress:   8%|▊         | 4/50 [00:00<00:07,  6.07it/s, best_trial=3, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[12]\tvalid's auc: 0.565972\n",
            "INFO:optuna.study.study:Trial 4 finished with value: 0.5659722222222222 and parameters: {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957}. Best is trial 3 with value: 0.5833333333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 5\u001b[0m with hyperparameters {'feature_fraction': 0.6521211214797689, 'num_leaves': 141, 'bagging_fraction': 0.7159725093210578, 'min_sum_hessian_in_leaf': 0.014618962793704957} scored 0.5659722222222222 in 0:00:00.180547\n",
            "Optimization Progress:  10%|█         | 5/50 [00:00<00:07,  5.63it/s, best_trial=3, best_value=0.583]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[16]\tvalid's auc: 0.59375\n",
            "INFO:optuna.study.study:Trial 5 finished with value: 0.59375 and parameters: {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112}. Best is trial 5 with value: 0.59375.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 6\u001b[0m with hyperparameters {'feature_fraction': 0.8059264473611898, 'num_leaves': 49, 'bagging_fraction': 0.6460723242676091, 'min_sum_hessian_in_leaf': 0.029204338471814112} scored 0.59375 in 0:00:00.092046\n",
            "Optimization Progress:  12%|█▏        | 6/50 [00:00<00:07,  6.27it/s, best_trial=5, best_value=0.594]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[227]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 6 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 7\u001b[0m with hyperparameters {'feature_fraction': 0.728034992108518, 'num_leaves': 204, 'bagging_fraction': 0.5998368910791798, 'min_sum_hessian_in_leaf': 0.11400863701127326} scored 0.5972222222222222 in 0:00:00.143856\n",
            "Optimization Progress:  14%|█▍        | 7/50 [00:01<00:06,  6.19it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[100]\tvalid's auc: 0.569444\n",
            "INFO:optuna.study.study:Trial 7 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 8\u001b[0m with hyperparameters {'feature_fraction': 0.7962072844310213, 'num_leaves': 27, 'bagging_fraction': 0.8037724259507192, 'min_sum_hessian_in_leaf': 0.004809461967501573} scored 0.5694444444444444 in 0:00:00.177113\n",
            "Optimization Progress:  16%|█▌        | 8/50 [00:01<00:07,  5.74it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[7]\tvalid's auc: 0.53125\n",
            "INFO:optuna.study.study:Trial 8 finished with value: 0.53125 and parameters: {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 9\u001b[0m with hyperparameters {'feature_fraction': 0.5325257964926398, 'num_leaves': 243, 'bagging_fraction': 0.9828160165372797, 'min_sum_hessian_in_leaf': 1.7123375973163988} scored 0.53125 in 0:00:00.091786\n",
            "Optimization Progress:  18%|█▊        | 9/50 [00:01<00:06,  6.46it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.520833\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.527778\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[427]\tvalid's auc: 0.541667\n",
            "INFO:optuna.study.study:Trial 9 finished with value: 0.5416666666666666 and parameters: {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 10\u001b[0m with hyperparameters {'feature_fraction': 0.6523068845866853, 'num_leaves': 39, 'bagging_fraction': 0.8421165132560784, 'min_sum_hessian_in_leaf': 0.057624872164786026} scored 0.5416666666666666 in 0:00:00.219981\n",
            "Optimization Progress:  20%|██        | 10/50 [00:01<00:07,  5.49it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[51]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 10 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9725682721151934, 'num_leaves': 185, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.36240382475490457}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 11\u001b[0m with hyperparameters {'feature_fraction': 0.9725682721151934, 'num_leaves': 185, 'bagging_fraction': 0.6843643863605486, 'min_sum_hessian_in_leaf': 0.36240382475490457} scored 0.5902777777777778 in 0:00:00.117193\n",
            "Optimization Progress:  22%|██▏       | 11/50 [00:01<00:06,  5.83it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 11 finished with value: 0.5833333333333333 and parameters: {'feature_fraction': 0.8575848060983975, 'num_leaves': 98, 'bagging_fraction': 0.6277217293825994, 'min_sum_hessian_in_leaf': 0.04513723813064542}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 12\u001b[0m with hyperparameters {'feature_fraction': 0.8575848060983975, 'num_leaves': 98, 'bagging_fraction': 0.6277217293825994, 'min_sum_hessian_in_leaf': 0.04513723813064542} scored 0.5833333333333333 in 0:00:00.125759\n",
            "Optimization Progress:  24%|██▍       | 12/50 [00:01<00:06,  5.97it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 12 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7421560723588667, 'num_leaves': 142, 'bagging_fraction': 0.6254362249366492, 'min_sum_hessian_in_leaf': 0.001236260708045277}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 13\u001b[0m with hyperparameters {'feature_fraction': 0.7421560723588667, 'num_leaves': 142, 'bagging_fraction': 0.6254362249366492, 'min_sum_hessian_in_leaf': 0.001236260708045277} scored 0.5833333333333334 in 0:00:00.235726\n",
            "Optimization Progress:  26%|██▌       | 13/50 [00:02<00:07,  5.17it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[103]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 13 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7320725411691559, 'num_leaves': 194, 'bagging_fraction': 0.6836109219932778, 'min_sum_hessian_in_leaf': 0.21884560252976312}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 14\u001b[0m with hyperparameters {'feature_fraction': 0.7320725411691559, 'num_leaves': 194, 'bagging_fraction': 0.6836109219932778, 'min_sum_hessian_in_leaf': 0.21884560252976312} scored 0.5902777777777778 in 0:00:00.075958\n",
            "Optimization Progress:  26%|██▌       | 13/50 [00:02<00:07,  5.17it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[64]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 14 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.8482867273170794, 'num_leaves': 102, 'bagging_fraction': 0.5733270423472366, 'min_sum_hessian_in_leaf': 0.022895661493813613}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 15\u001b[0m with hyperparameters {'feature_fraction': 0.8482867273170794, 'num_leaves': 102, 'bagging_fraction': 0.5733270423472366, 'min_sum_hessian_in_leaf': 0.022895661493813613} scored 0.5902777777777778 in 0:00:00.057274\n",
            "Optimization Progress:  30%|███       | 15/50 [00:02<00:05,  6.95it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[19]\tvalid's auc: 0.559028\n",
            "INFO:optuna.study.study:Trial 15 finished with value: 0.5590277777777778 and parameters: {'feature_fraction': 0.8957346661249761, 'num_leaves': 98, 'bagging_fraction': 0.7630489631580071, 'min_sum_hessian_in_leaf': 0.9258339016713287}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 16\u001b[0m with hyperparameters {'feature_fraction': 0.8957346661249761, 'num_leaves': 98, 'bagging_fraction': 0.7630489631580071, 'min_sum_hessian_in_leaf': 0.9258339016713287} scored 0.5590277777777778 in 0:00:00.065391\n",
            "Optimization Progress:  30%|███       | 15/50 [00:02<00:05,  6.95it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[45]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 16 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.7894295884659824, 'num_leaves': 205, 'bagging_fraction': 0.6510316760083694, 'min_sum_hessian_in_leaf': 0.09841756758357928}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 17\u001b[0m with hyperparameters {'feature_fraction': 0.7894295884659824, 'num_leaves': 205, 'bagging_fraction': 0.6510316760083694, 'min_sum_hessian_in_leaf': 0.09841756758357928} scored 0.5902777777777778 in 0:00:00.082921\n",
            "Optimization Progress:  34%|███▍      | 17/50 [00:02<00:04,  7.98it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[444]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 17 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6029735171388793, 'num_leaves': 157, 'bagging_fraction': 0.5634924220005435, 'min_sum_hessian_in_leaf': 0.010900752652193337}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 18\u001b[0m with hyperparameters {'feature_fraction': 0.6029735171388793, 'num_leaves': 157, 'bagging_fraction': 0.5634924220005435, 'min_sum_hessian_in_leaf': 0.010900752652193337} scored 0.5972222222222222 in 0:00:00.122581\n",
            "Optimization Progress:  36%|███▌      | 18/50 [00:02<00:04,  7.76it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[189]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 18 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.5841593416403906, 'num_leaves': 159, 'bagging_fraction': 0.5547583595525817, 'min_sum_hessian_in_leaf': 0.007868553528824849}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 19\u001b[0m with hyperparameters {'feature_fraction': 0.5841593416403906, 'num_leaves': 159, 'bagging_fraction': 0.5547583595525817, 'min_sum_hessian_in_leaf': 0.007868553528824849} scored 0.5694444444444444 in 0:00:00.075701\n",
            "Optimization Progress:  36%|███▌      | 18/50 [00:02<00:04,  7.76it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[800]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[608]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 19 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.5065701578589041, 'num_leaves': 223, 'bagging_fraction': 0.5104677846825332, 'min_sum_hessian_in_leaf': 0.0013214932238275125}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 20\u001b[0m with hyperparameters {'feature_fraction': 0.5065701578589041, 'num_leaves': 223, 'bagging_fraction': 0.5104677846825332, 'min_sum_hessian_in_leaf': 0.0013214932238275125} scored 0.5902777777777778 in 0:00:00.145944\n",
            "Optimization Progress:  40%|████      | 20/50 [00:02<00:03,  7.78it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.513889\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[18]\tvalid's auc: 0.527778\n",
            "INFO:optuna.study.study:Trial 20 finished with value: 0.5277777777777778 and parameters: {'feature_fraction': 0.615426845535755, 'num_leaves': 170, 'bagging_fraction': 0.9264342202471387, 'min_sum_hessian_in_leaf': 0.5709831496754405}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 21\u001b[0m with hyperparameters {'feature_fraction': 0.615426845535755, 'num_leaves': 170, 'bagging_fraction': 0.9264342202471387, 'min_sum_hessian_in_leaf': 0.5709831496754405} scored 0.5277777777777778 in 0:00:00.067345\n",
            "Optimization Progress:  40%|████      | 20/50 [00:03<00:03,  7.78it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[159]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 21 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7105633352072851, 'num_leaves': 126, 'bagging_fraction': 0.596609562772596, 'min_sum_hessian_in_leaf': 0.027724933928716656}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 22\u001b[0m with hyperparameters {'feature_fraction': 0.7105633352072851, 'num_leaves': 126, 'bagging_fraction': 0.596609562772596, 'min_sum_hessian_in_leaf': 0.027724933928716656} scored 0.5833333333333334 in 0:00:00.087161\n",
            "Optimization Progress:  44%|████▍     | 22/50 [00:03<00:03,  8.47it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[144]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 22 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.6819187188748133, 'num_leaves': 218, 'bagging_fraction': 0.6665654273844691, 'min_sum_hessian_in_leaf': 0.10334219428052598}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 23\u001b[0m with hyperparameters {'feature_fraction': 0.6819187188748133, 'num_leaves': 218, 'bagging_fraction': 0.6665654273844691, 'min_sum_hessian_in_leaf': 0.10334219428052598} scored 0.5902777777777778 in 0:00:00.089103\n",
            "Optimization Progress:  46%|████▌     | 23/50 [00:03<00:03,  8.60it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.534722\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[109]\tvalid's auc: 0.569444\n",
            "INFO:optuna.study.study:Trial 23 finished with value: 0.5694444444444444 and parameters: {'feature_fraction': 0.8352725713024433, 'num_leaves': 73, 'bagging_fraction': 0.7333246876448902, 'min_sum_hessian_in_leaf': 0.012255253606587906}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 24\u001b[0m with hyperparameters {'feature_fraction': 0.8352725713024433, 'num_leaves': 73, 'bagging_fraction': 0.7333246876448902, 'min_sum_hessian_in_leaf': 0.012255253606587906} scored 0.5694444444444444 in 0:00:00.074656\n",
            "Optimization Progress:  46%|████▌     | 23/50 [00:03<00:03,  8.60it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 24 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.7776039056849715, 'num_leaves': 122, 'bagging_fraction': 0.6100808232291592, 'min_sum_hessian_in_leaf': 0.0034347001966147355}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 25\u001b[0m with hyperparameters {'feature_fraction': 0.7776039056849715, 'num_leaves': 122, 'bagging_fraction': 0.6100808232291592, 'min_sum_hessian_in_leaf': 0.0034347001966147355} scored 0.5972222222222222 in 0:00:00.068853\n",
            "Optimization Progress:  50%|█████     | 25/50 [00:03<00:02,  9.46it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[700]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[502]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 25 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6258082362855537, 'num_leaves': 130, 'bagging_fraction': 0.5743338109094763, 'min_sum_hessian_in_leaf': 0.0027565261382618876}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 26\u001b[0m with hyperparameters {'feature_fraction': 0.6258082362855537, 'num_leaves': 130, 'bagging_fraction': 0.5743338109094763, 'min_sum_hessian_in_leaf': 0.0027565261382618876} scored 0.5972222222222222 in 0:00:00.139047\n",
            "Optimization Progress:  52%|█████▏    | 26/50 [00:03<00:02,  8.52it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[65]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 26 finished with value: 0.576388888888889 and parameters: {'feature_fraction': 0.5592743997151934, 'num_leaves': 160, 'bagging_fraction': 0.5463668247936341, 'min_sum_hessian_in_leaf': 0.0022719680169641728}. Best is trial 6 with value: 0.5972222222222222.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 27\u001b[0m with hyperparameters {'feature_fraction': 0.5592743997151934, 'num_leaves': 160, 'bagging_fraction': 0.5463668247936341, 'min_sum_hessian_in_leaf': 0.0022719680169641728} scored 0.576388888888889 in 0:00:00.063667\n",
            "Optimization Progress:  52%|█████▏    | 26/50 [00:03<00:02,  8.52it/s, best_trial=6, best_value=0.597]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[61]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 27 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.7486261419689739, 'num_leaves': 114, 'bagging_fraction': 0.6084906475348004, 'min_sum_hessian_in_leaf': 0.08704658595003716}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 28\u001b[0m with hyperparameters {'feature_fraction': 0.7486261419689739, 'num_leaves': 114, 'bagging_fraction': 0.6084906475348004, 'min_sum_hessian_in_leaf': 0.08704658595003716} scored 0.6041666666666667 in 0:00:00.061129\n",
            "Optimization Progress:  56%|█████▌    | 28/50 [00:03<00:02,  9.63it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.541667\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[21]\tvalid's auc: 0.552083\n",
            "INFO:optuna.study.study:Trial 28 finished with value: 0.5520833333333333 and parameters: {'feature_fraction': 0.7590534849545673, 'num_leaves': 173, 'bagging_fraction': 0.7752847229001598, 'min_sum_hessian_in_leaf': 0.10695607255524689}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 29\u001b[0m with hyperparameters {'feature_fraction': 0.7590534849545673, 'num_leaves': 173, 'bagging_fraction': 0.7752847229001598, 'min_sum_hessian_in_leaf': 0.10695607255524689} scored 0.5520833333333333 in 0:00:00.065242\n",
            "Optimization Progress:  56%|█████▌    | 28/50 [00:03<00:02,  9.63it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[15]\tvalid's auc: 0.579861\n",
            "INFO:optuna.study.study:Trial 29 finished with value: 0.5798611111111112 and parameters: {'feature_fraction': 0.6948223695310548, 'num_leaves': 239, 'bagging_fraction': 0.7096324540883361, 'min_sum_hessian_in_leaf': 0.23161630959792906}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 30\u001b[0m with hyperparameters {'feature_fraction': 0.6948223695310548, 'num_leaves': 239, 'bagging_fraction': 0.7096324540883361, 'min_sum_hessian_in_leaf': 0.23161630959792906} scored 0.5798611111111112 in 0:00:00.066178\n",
            "Optimization Progress:  60%|██████    | 30/50 [00:03<00:01, 10.37it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[500]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[600]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[435]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 30 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.6720822529159559, 'num_leaves': 112, 'bagging_fraction': 0.560678768673456, 'min_sum_hessian_in_leaf': 0.010068157024166188}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 31\u001b[0m with hyperparameters {'feature_fraction': 0.6720822529159559, 'num_leaves': 112, 'bagging_fraction': 0.560678768673456, 'min_sum_hessian_in_leaf': 0.010068157024166188} scored 0.5972222222222222 in 0:00:00.135408\n",
            "Optimization Progress:  60%|██████    | 30/50 [00:04<00:01, 10.37it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[60]\tvalid's auc: 0.604167\n",
            "INFO:optuna.study.study:Trial 31 finished with value: 0.6041666666666667 and parameters: {'feature_fraction': 0.7644346131217467, 'num_leaves': 114, 'bagging_fraction': 0.6080173945084689, 'min_sum_hessian_in_leaf': 0.004136664781485284}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 32\u001b[0m with hyperparameters {'feature_fraction': 0.7644346131217467, 'num_leaves': 114, 'bagging_fraction': 0.6080173945084689, 'min_sum_hessian_in_leaf': 0.004136664781485284} scored 0.6041666666666667 in 0:00:00.096141\n",
            "Optimization Progress:  64%|██████▍   | 32/50 [00:04<00:01,  9.15it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 32 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.7268302678751436, 'num_leaves': 84, 'bagging_fraction': 0.542692684485182, 'min_sum_hessian_in_leaf': 0.050255687475452886}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 33\u001b[0m with hyperparameters {'feature_fraction': 0.7268302678751436, 'num_leaves': 84, 'bagging_fraction': 0.542692684485182, 'min_sum_hessian_in_leaf': 0.050255687475452886} scored 0.5763888888888888 in 0:00:00.069768\n",
            "Optimization Progress:  64%|██████▍   | 32/50 [00:04<00:01,  9.15it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.548611\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 33 finished with value: 0.5972222222222223 and parameters: {'feature_fraction': 0.7546200918058636, 'num_leaves': 151, 'bagging_fraction': 0.5075106058128436, 'min_sum_hessian_in_leaf': 0.17539299952349766}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 34\u001b[0m with hyperparameters {'feature_fraction': 0.7546200918058636, 'num_leaves': 151, 'bagging_fraction': 0.5075106058128436, 'min_sum_hessian_in_leaf': 0.17539299952349766} scored 0.5972222222222223 in 0:00:00.063876\n",
            "Optimization Progress:  68%|██████▊   | 34/50 [00:04<00:01,  9.75it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[400]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[205]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 34 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.7630899510439957, 'num_leaves': 82, 'bagging_fraction': 0.51398332300743, 'min_sum_hessian_in_leaf': 1.0048323354929665}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 35\u001b[0m with hyperparameters {'feature_fraction': 0.7630899510439957, 'num_leaves': 82, 'bagging_fraction': 0.51398332300743, 'min_sum_hessian_in_leaf': 1.0048323354929665} scored 0.5833333333333334 in 0:00:00.078743\n",
            "Optimization Progress:  68%|██████▊   | 34/50 [00:04<00:01,  9.75it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 35 finished with value: 0.5555555555555556 and parameters: {'feature_fraction': 0.7023788576881956, 'num_leaves': 115, 'bagging_fraction': 0.6037910445825557, 'min_sum_hessian_in_leaf': 6.362583979504018}. Best is trial 27 with value: 0.6041666666666667.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 36\u001b[0m with hyperparameters {'feature_fraction': 0.7023788576881956, 'num_leaves': 115, 'bagging_fraction': 0.6037910445825557, 'min_sum_hessian_in_leaf': 6.362583979504018} scored 0.5555555555555556 in 0:00:00.053850\n",
            "Optimization Progress:  72%|███████▏  | 36/50 [00:04<00:01, 10.13it/s, best_trial=27, best_value=0.604]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 36 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 37\u001b[0m with hyperparameters {'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531} scored 0.6145833333333334 in 0:00:00.076814\n",
            "Optimization Progress:  72%|███████▏  | 36/50 [00:04<00:01, 10.13it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 37 finished with value: 0.5972222222222223 and parameters: {'feature_fraction': 0.8218539073651699, 'num_leaves': 142, 'bagging_fraction': 0.5073308534027855, 'min_sum_hessian_in_leaf': 0.3474846140961544}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 38\u001b[0m with hyperparameters {'feature_fraction': 0.8218539073651699, 'num_leaves': 142, 'bagging_fraction': 0.5073308534027855, 'min_sum_hessian_in_leaf': 0.3474846140961544} scored 0.5972222222222223 in 0:00:00.066123\n",
            "Optimization Progress:  76%|███████▌  | 38/50 [00:04<00:01, 10.25it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.576389\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 38 finished with value: 0.6006944444444445 and parameters: {'feature_fraction': 0.9147579597726889, 'num_leaves': 148, 'bagging_fraction': 0.5312125692578071, 'min_sum_hessian_in_leaf': 3.1233887286501005}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 39\u001b[0m with hyperparameters {'feature_fraction': 0.9147579597726889, 'num_leaves': 148, 'bagging_fraction': 0.5312125692578071, 'min_sum_hessian_in_leaf': 3.1233887286501005} scored 0.6006944444444445 in 0:00:00.060895\n",
            "Optimization Progress:  76%|███████▌  | 38/50 [00:04<00:01, 10.25it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 39 finished with value: 0.6006944444444444 and parameters: {'feature_fraction': 0.9851899024509025, 'num_leaves': 108, 'bagging_fraction': 0.5337337739945639, 'min_sum_hessian_in_leaf': 4.149213776758782}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 40\u001b[0m with hyperparameters {'feature_fraction': 0.9851899024509025, 'num_leaves': 108, 'bagging_fraction': 0.5337337739945639, 'min_sum_hessian_in_leaf': 4.149213776758782} scored 0.6006944444444444 in 0:00:00.059071\n",
            "Optimization Progress:  80%|████████  | 40/50 [00:04<00:00, 10.79it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.572917\n",
            "INFO:optuna.study.study:Trial 40 finished with value: 0.5729166666666666 and parameters: {'feature_fraction': 0.889137025130443, 'num_leaves': 59, 'bagging_fraction': 0.6349130370364919, 'min_sum_hessian_in_leaf': 2.2842483223278864}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 41\u001b[0m with hyperparameters {'feature_fraction': 0.889137025130443, 'num_leaves': 59, 'bagging_fraction': 0.6349130370364919, 'min_sum_hessian_in_leaf': 2.2842483223278864} scored 0.5729166666666666 in 0:00:00.072865\n",
            "Optimization Progress:  80%|████████  | 40/50 [00:05<00:00, 10.79it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.614583\n",
            "INFO:optuna.study.study:Trial 41 finished with value: 0.6145833333333334 and parameters: {'feature_fraction': 0.9958026270163949, 'num_leaves': 109, 'bagging_fraction': 0.5335861598398993, 'min_sum_hessian_in_leaf': 5.570202963554855}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 42\u001b[0m with hyperparameters {'feature_fraction': 0.9958026270163949, 'num_leaves': 109, 'bagging_fraction': 0.5335861598398993, 'min_sum_hessian_in_leaf': 5.570202963554855} scored 0.6145833333333334 in 0:00:00.063696\n",
            "Optimization Progress:  84%|████████▍ | 42/50 [00:05<00:00, 10.86it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.590278\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[97]\tvalid's auc: 0.590278\n",
            "INFO:optuna.study.study:Trial 42 finished with value: 0.5902777777777778 and parameters: {'feature_fraction': 0.9553879335277939, 'num_leaves': 133, 'bagging_fraction': 0.5812032091253919, 'min_sum_hessian_in_leaf': 4.912873224706649}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 43\u001b[0m with hyperparameters {'feature_fraction': 0.9553879335277939, 'num_leaves': 133, 'bagging_fraction': 0.5812032091253919, 'min_sum_hessian_in_leaf': 4.912873224706649} scored 0.5902777777777778 in 0:00:00.119201\n",
            "Optimization Progress:  84%|████████▍ | 42/50 [00:05<00:00, 10.86it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[1]\tvalid's auc: 0.5\n",
            "INFO:optuna.study.study:Trial 43 finished with value: 0.5 and parameters: {'feature_fraction': 0.9416860695555195, 'num_leaves': 90, 'bagging_fraction': 0.5327319139478942, 'min_sum_hessian_in_leaf': 9.686596290655332}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 44\u001b[0m with hyperparameters {'feature_fraction': 0.9416860695555195, 'num_leaves': 90, 'bagging_fraction': 0.5327319139478942, 'min_sum_hessian_in_leaf': 9.686596290655332} scored 0.5 in 0:00:00.059443\n",
            "Optimization Progress:  88%|████████▊ | 44/50 [00:05<00:00, 10.26it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.600694\n",
            "INFO:optuna.study.study:Trial 44 finished with value: 0.6006944444444445 and parameters: {'feature_fraction': 0.9232857389532847, 'num_leaves': 117, 'bagging_fraction': 0.5293864727524185, 'min_sum_hessian_in_leaf': 1.2716775603487556}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 45\u001b[0m with hyperparameters {'feature_fraction': 0.9232857389532847, 'num_leaves': 117, 'bagging_fraction': 0.5293864727524185, 'min_sum_hessian_in_leaf': 1.2716775603487556} scored 0.6006944444444445 in 0:00:00.073914\n",
            "Optimization Progress:  88%|████████▊ | 44/50 [00:05<00:00, 10.26it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[71]\tvalid's auc: 0.597222\n",
            "INFO:optuna.study.study:Trial 45 finished with value: 0.5972222222222222 and parameters: {'feature_fraction': 0.9979426475884785, 'num_leaves': 138, 'bagging_fraction': 0.5873366638078265, 'min_sum_hessian_in_leaf': 2.3778366648996148}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 46\u001b[0m with hyperparameters {'feature_fraction': 0.9979426475884785, 'num_leaves': 138, 'bagging_fraction': 0.5873366638078265, 'min_sum_hessian_in_leaf': 2.3778366648996148} scored 0.5972222222222222 in 0:00:00.081765\n",
            "Optimization Progress:  92%|█████████▏| 46/50 [00:05<00:00, 10.05it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 46 finished with value: 0.5763888888888888 and parameters: {'feature_fraction': 0.8744908342367126, 'num_leaves': 16, 'bagging_fraction': 0.618368145908441, 'min_sum_hessian_in_leaf': 3.5644793534748884}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 47\u001b[0m with hyperparameters {'feature_fraction': 0.8744908342367126, 'num_leaves': 16, 'bagging_fraction': 0.618368145908441, 'min_sum_hessian_in_leaf': 3.5644793534748884} scored 0.5763888888888888 in 0:00:00.076377\n",
            "Optimization Progress:  92%|█████████▏| 46/50 [00:05<00:00, 10.05it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.493056\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.506944\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[58]\tvalid's auc: 0.53125\n",
            "INFO:optuna.study.study:Trial 47 finished with value: 0.53125 and parameters: {'feature_fraction': 0.9133806114646719, 'num_leaves': 149, 'bagging_fraction': 0.8870525704755607, 'min_sum_hessian_in_leaf': 0.020526616410047247}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 48\u001b[0m with hyperparameters {'feature_fraction': 0.9133806114646719, 'num_leaves': 149, 'bagging_fraction': 0.8870525704755607, 'min_sum_hessian_in_leaf': 0.020526616410047247} scored 0.53125 in 0:00:00.070356\n",
            "Optimization Progress:  96%|█████████▌| 48/50 [00:05<00:00, 10.15it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.583333\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.583333\n",
            "INFO:optuna.study.study:Trial 48 finished with value: 0.5833333333333334 and parameters: {'feature_fraction': 0.8162620264600886, 'num_leaves': 74, 'bagging_fraction': 0.5022755128714155, 'min_sum_hessian_in_leaf': 0.5104593639993887}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 49\u001b[0m with hyperparameters {'feature_fraction': 0.8162620264600886, 'num_leaves': 74, 'bagging_fraction': 0.5022755128714155, 'min_sum_hessian_in_leaf': 0.5104593639993887} scored 0.5833333333333334 in 0:00:00.075354\n",
            "Optimization Progress:  96%|█████████▌| 48/50 [00:05<00:00, 10.15it/s, best_trial=36, best_value=0.615]INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 200 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.5625\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[200]\tvalid's auc: 0.569444\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[300]\tvalid's auc: 0.555556\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[127]\tvalid's auc: 0.576389\n",
            "INFO:optuna.study.study:Trial 49 finished with value: 0.576388888888889 and parameters: {'feature_fraction': 0.9576703429462708, 'num_leaves': 103, 'bagging_fraction': 0.6499298499734096, 'min_sum_hessian_in_leaf': 1.6250927229845524}. Best is trial 36 with value: 0.6145833333333334.\n",
            "INFO3:lightautoml.ml_algo.tuning.optuna:\u001b[1mTrial 50\u001b[0m with hyperparameters {'feature_fraction': 0.9576703429462708, 'num_leaves': 103, 'bagging_fraction': 0.6499298499734096, 'min_sum_hessian_in_leaf': 1.6250927229845524} scored 0.576388888888889 in 0:00:00.087269\n",
            "Optimization Progress: 100%|██████████| 50/50 [00:05<00:00,  8.44it/s, best_trial=36, best_value=0.615]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:37] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "INFO:lightautoml.ml_algo.tuning.optuna:Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m completed\n",
            "INFO2:lightautoml.ml_algo.tuning.optuna:The set of hyperparameters \u001b[1m{'feature_fraction': 0.8124527509966039, 'num_leaves': 144, 'bagging_fraction': 0.5086792017528844, 'min_sum_hessian_in_leaf': 0.17837062520581531}\u001b[0m\n",
            " achieve 0.6146 auc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m ...\n",
            "DEBUG:lightautoml.ml_algo.base:Training params: {'task': 'train', 'learning_rate': 0.05, 'num_leaves': 144, 'feature_fraction': 0.8124527509966039, 'bagging_fraction': 0.5086792017528844, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'reg_alpha': 1, 'reg_lambda': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'num_threads': 2, 'max_bin': 255, 'min_data_in_bin': 3, 'num_trees': 3000, 'early_stopping_rounds': 100, 'random_state': 42, 'verbose_eval': 100, 'min_sum_hessian_in_leaf': 0.17837062520581531}\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 0\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.597222\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.614583\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 1\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.594406\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.723776\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 2\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.755245\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[66]\tvalid's auc: 0.818182\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 3\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.597902\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[17]\tvalid's auc: 0.685315\n",
            "INFO2:lightautoml.ml_algo.base:===== Start working with \u001b[1mfold 4\u001b[0m for \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m =====\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Training until validation scores don't improve for 100 rounds\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:[100]\tvalid's auc: 0.909091\n",
            "INFO3:lightautoml.ml_algo.boost_lgbm:Early stopping, best iteration is:\n",
            "[6]\tvalid's auc: 0.940559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6868024553571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.6868024553571428\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] \u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.ml_algo.base:\u001b[1mLvl_0_Pipe_1_Mod_0_Tuned_LightGBM\u001b[0m fitting and predicting completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Time left 592.30 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:Time left 592.30 secs\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] \u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.base:\u001b[1mLayer 1 training completed.\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Blending: optimization starts with equal weights. Score = \u001b[1m0.6939174\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: optimization starts with equal weights. Score = \u001b[1m0.6939174\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7134487\u001b[0m, weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7134487\u001b[0m, weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: no improvements for score. Terminated.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Blending: best score = \u001b[1m0.7134487\u001b[0m, best weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.blend:Blending: best score = \u001b[1m0.7134487\u001b[0m, best weights = \u001b[1m[0.6623374  0.33766258]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] \u001b[1mAutoml preset training completed in 7.82 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:\u001b[1mAutoml preset training completed in 7.82 seconds\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:28:38] Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.66234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.33766 * (5 averaged models Lvl_0_Pipe_1_Mod_0_Tuned_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightautoml.automl.presets.base:Model description:\n",
            "Final prediction for new objects (level 0) = \n",
            "\t 0.66234 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
            "\t 0.33766 * (5 averaged models Lvl_0_Pipe_1_Mod_0_Tuned_LightGBM) \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LAMA FS+LGBM/Linear] ROC-AUC: 0.7217  F1: 0.4082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Выбор лучшего"
      ],
      "metadata": {
        "id": "w5_DMUZzqaXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "results['LAMA_DEFAULT'] = (auc1, f1_1)\n",
        "results['LAMA_FAST'] = (auc2, f1_2)\n",
        "results['LAMA_ADVANCED'] = (auc3, f1_3)\n",
        "results['LAMA_FS'] = (auc4, f1_4)\n",
        "for k, v in results.items():\n",
        "    print(f'{k:15}| ROC-AUC: {v[0]:.4f} | F1: {v[1]:.4f}')\n",
        "\n",
        "best_lama_name = max(results, key=lambda k: results[k][0])\n",
        "print(f'--> Лучший бэйзлайн: {best_lama_name}, ROC-AUC = {results[best_lama_name][0]:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cJ_g-LmooB",
        "outputId": "ed17cf61-822d-4386-c53c-e92c6bd51f07"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LAMA_DEFAULT   | ROC-AUC: 0.7217 | F1: 0.6557\n",
            "LAMA_FAST      | ROC-AUC: 0.7138 | F1: 0.6552\n",
            "LAMA_ADVANCED  | ROC-AUC: 0.5000 | F1: 0.0000\n",
            "LAMA_FS        | ROC-AUC: 0.7217 | F1: 0.4082\n",
            "--> Лучший бэйзлайн: LAMA_DEFAULT, ROC-AUC = 0.7217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Классическая конфигурация LAMA, несмотря на консерватизм, дала лучший результат среди тестируемых."
      ],
      "metadata": {
        "id": "-34OVh9Dq55-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 1"
      ],
      "metadata": {
        "id": "o1lzPSo_rP9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 1: LightGBM + scale + auto feature selection\n",
        "\n",
        "# PIPELINE 1A: только scaling + LGBM (без фичер селекции)\n",
        "pipe_lgbm_base = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "pipe_lgbm_base.fit(X_train, y_train)\n",
        "pred_lgbm_base = pipe_lgbm_base.predict_proba(X_test)[:, 1]\n",
        "auc_lgbm_base = roc_auc_score(y_test, pred_lgbm_base)\n",
        "print(f'[Pipeline LGBM basic] ROC-AUC: {auc_lgbm_base:.4f}')\n",
        "\n",
        "# PIPELINE 1B: scaling + feature selection + LGBM\n",
        "# Селектор тренируется внутри пайплайна по cross-val на train (без data leakage)\n",
        "pipe_lgbm_fs = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectFromModel(LGBMClassifier(n_estimators=100, random_state=42), threshold=\"median\")),\n",
        "    ('lgbm', LGBMClassifier(n_estimators=100, random_state=42))\n",
        "])\n",
        "pipe_lgbm_fs.fit(X_train, y_train)\n",
        "pred_lgbm_fs = pipe_lgbm_fs.predict_proba(X_test)[:, 1]\n",
        "auc_lgbm_fs = roc_auc_score(y_test, pred_lgbm_fs)\n",
        "print(f'[Pipeline LGBM + feature selection] ROC-AUC: {auc_lgbm_fs:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBczjODitxHr",
        "outputId": "1a0129bc-740d-4ce7-ecfd-3a2e58548185"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SelectFromModel was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline LGBM basic] ROC-AUC: 0.6980\n",
            "[Pipeline LGBM + feature selection] ROC-AUC: 0.6742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SelectFromModel was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 2"
      ],
      "metadata": {
        "id": "8t-JPEQOrc1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 2: CatBoost + простая обработка пропусков\n",
        "pipe_catboost = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('catboost', CatBoostClassifier(iterations=200,\n",
        "                                    learning_rate=0.05,\n",
        "                                    eval_metric='AUC',\n",
        "                                    random_state=42,\n",
        "                                    verbose=0))\n",
        "])\n",
        "\n",
        "pipe_catboost.fit(X_train, y_train)\n",
        "pred_cat = pipe_catboost.predict_proba(X_test)[:, 1]\n",
        "auc_cat = roc_auc_score(y_test, pred_cat)\n",
        "print(f'[Pipeline CatBoost] ROC-AUC: {auc_cat:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mIVIPpQrmlO",
        "outputId": "18543a25-98ea-496b-cb41-0a5bd65c966f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline CatBoost] ROC-AUC: 0.7048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Собственное решение 3"
      ],
      "metadata": {
        "id": "9ieCUGhPrrqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PIPELINE 3: Logistic Regression + StandardScaler + гиперпараметры GridSearch\n",
        "pipe_logreg = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logreg', LogisticRegression(max_iter=300))\n",
        "])\n",
        "\n",
        "param_grid = {'logreg__C': [0.01, 0.1, 1, 3, 10]}\n",
        "grid = GridSearchCV(pipe_logreg, param_grid, scoring='roc_auc', cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"[Pipeline LogReg] Лучшее C: {grid.best_params_}\")\n",
        "best_logreg = grid.best_estimator_\n",
        "preds_lr = best_logreg.predict_proba(X_test)[:, 1]\n",
        "auc_lr = roc_auc_score(y_test, preds_lr)\n",
        "print(f'[Pipeline LogReg tuned] ROC-AUC: {auc_lr:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYneA9o1rqKD",
        "outputId": "bbd8932f-4217-497c-ea6d-3804f8a0e41f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline LogReg] Лучшее C: {'logreg__C': 0.1}\n",
            "[Pipeline LogReg tuned] ROC-AUC: 0.7455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод\n",
        "Свое решение оказалось лучше LAMA baseline: максимум ROC-AUC своего решения: 0.7455 (пайплайн 3), лучшего baseline: 0.7217\n"
      ],
      "metadata": {
        "id": "Aaec6QLkr2eR"
      }
    }
  ]
}